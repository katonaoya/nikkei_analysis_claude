#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çµ‚å€¤ãƒ™ãƒ¼ã‚¹æ¨å¥¨éŠ˜æŸ„ã‚·ã‚¹ãƒ†ãƒ 
æœ€æ–°å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æŒ‡æ¨™ã«åŒæœŸ
"""

import pandas as pd
import numpy as np
import logging
from pathlib import Path
from datetime import datetime, timedelta
import joblib
import argparse
import json
import sys

sys.path.append(str(Path(__file__).parent.parent))
from utils.market_calendar import JapanMarketCalendar
from systems.enhanced_close_return_system_v1 import CloseReturnPrecisionSystemV1

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

class DailyStockRecommendationCloseV1:
    """çµ‚å€¤ãƒ™ãƒ¼ã‚¹æ¨å¥¨éŠ˜æŸ„ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, target_return: float = 0.01, imbalance_boost: float = 1.0, min_probability: float = None, max_per_sector: int = None, config_path: str = "config/close_recommendation_config.json"):
        self.model_dir = Path("models")
        self.data_dir = Path("data")
        self.results_dir = Path("production_reports")
        self.results_dir.mkdir(parents=True, exist_ok=True)

        self.config = self._load_config(config_path)
        if target_return is None:
            target_return = self.config.get("target_return", 0.01)
        if min_probability is None:
            min_probability = self.config.get("min_probability", 0.60)
        if max_per_sector is None:
            max_per_sector = self.config.get("max_per_sector", 3)

        # ãƒ¢ãƒ‡ãƒ«ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.model = None
        self.scaler = None
        self.selector = None
        self.feature_names = None
        self.model_accuracy = None
        self.pipeline = CloseReturnPrecisionSystemV1(target_return=target_return, imbalance_boost=imbalance_boost)
        
        # ä¼šç¤¾åãƒãƒƒãƒ”ãƒ³ã‚°
        self.company_names = {}
        self.company_sectors = {}
        self.calibration = None
        self.imbalance_strategy = getattr(self.pipeline, 'imbalance_strategy', 'scale_pos')
        self.focal_gamma = getattr(self.pipeline, 'focal_gamma', 2.0)
        self.positive_oversample_ratio = getattr(self.pipeline, 'positive_oversample_ratio', 1.0)
        self._load_company_names()
        self._load_close_model()
        self.target_return = target_return
        self.imbalance_boost = imbalance_boost
        self.min_probability = min_probability
        self.max_per_sector = max_per_sector

    def _load_config(self, path: str) -> dict:
        cfg_path = Path(path)
        if cfg_path.exists():
            try:
                return json.loads(cfg_path.read_text())
            except Exception as exc:
                logger.warning(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {exc}")
        return {}

    def _load_company_names(self):
        """ä¼šç¤¾åãƒãƒƒãƒ”ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¼šç¤¾åã‚’èª­ã¿è¾¼ã¿
            csv_file = Path("docment/ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±/nikkei225_matched_companies_20250909_230026.csv")
            if csv_file.exists():
                df = pd.read_csv(csv_file, encoding='utf-8-sig')
                for _, row in df.iterrows():
                    code = str(row['target_code'])
                    name = row['target_name'].replace('ï¼ˆæ ªï¼‰', '').replace('(æ ª)', '')
                    self.company_names[code] = name
                    sector = row.get('sector') if 'sector' in row else None
                    if isinstance(sector, str) and sector:
                        self.company_sectors[code] = sector
                    else:
                        self.company_sectors[code] = 'Unknown'
                logger.info(f"âœ… ä¼šç¤¾åãƒãƒƒãƒ”ãƒ³ã‚°èª­ã¿è¾¼ã¿å®Œäº†: {len(self.company_names)}ç¤¾")
            else:
                logger.warning("ä¼šç¤¾åCSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        except Exception as e:
            logger.error(f"ä¼šç¤¾åèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _get_company_name(self, code):
        """éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ä¼šç¤¾åã‚’å–å¾—"""
        return self.company_names.get(str(code), f"éŠ˜æŸ„{code}")
    
    def _load_close_model(self):
        """çµ‚å€¤ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # çµ‚å€¤ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
            model_files = list(self.model_dir.glob("enhanced_close_v1/*close_model_v1*.joblib"))
            if not model_files:
                raise FileNotFoundError("çµ‚å€¤ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            # æœ€æ–°ã®çµ‚å€¤ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            latest_model = max(model_files, key=lambda x: x.stat().st_mtime)
            model_data = joblib.load(latest_model)
            
            self.model = model_data['model']
            self.scaler = model_data.get('scaler')
            self.selector = model_data.get('selector')
            self.feature_names = model_data['feature_cols']
            self.model_accuracy = model_data.get('accuracy')
            self.calibration = model_data.get('calibration')
            model_target_return = model_data.get('target_return')
            if model_target_return is not None and abs(model_target_return - self.pipeline.target_return) > 1e-6:
                logger.info(f"target_return updated from model: {model_target_return:.4f}")
                self.pipeline.target_return = model_target_return
                self.target_return = model_target_return

            model_imbalance_boost = model_data.get('imbalance_boost')
            if model_imbalance_boost is not None:
                if abs(model_imbalance_boost - self.pipeline.imbalance_boost) > 1e-6:
                    logger.info(f"imbalance_boost updated from model: {model_imbalance_boost:.3f}")
                self.pipeline.imbalance_boost = model_imbalance_boost
                self.imbalance_boost = model_imbalance_boost

            for attr in ("imbalance_strategy", "focal_gamma", "positive_oversample_ratio"):
                model_value = model_data.get(attr)
                if model_value is not None:
                    setattr(self.pipeline, attr, model_value)
                    setattr(self, attr, model_value)

            logger.info(f"âœ… çµ‚å€¤ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {latest_model.name}")
            logger.info(f"ğŸ“Š ç‰¹å¾´é‡æ•°: {len(self.feature_names)}")
            if self.model_accuracy is not None:
                logger.info(f"ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«ç²¾åº¦: {self.model_accuracy:.4f}")
            
        except Exception as e:
            logger.error(f"çµ‚å€¤ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _prepare_feature_frame(self, target_date: pd.Timestamp) -> pd.DataFrame:
        """å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨åŒä¸€ãƒ­ã‚¸ãƒƒã‚¯ã§ç‰¹å¾´é‡ã‚’å–å¾—"""
        try:
            df = self.pipeline.load_and_integrate_data()
            df['Date'] = pd.to_datetime(df['Date'])
            df = df[df['Date'] <= target_date].copy()
            logger.info(
                "âœ… ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: %sä»¶ (æœ€æ–°: %s)",
                f"{len(df):,}",
                df['Date'].max().strftime('%Y-%m-%d') if not df.empty else 'N/A'
            )
            return df
        except Exception as e:
            logger.error(f"ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def generate_recommendations(self, target_date_str=None, top_n=5):
        """æ¨å¥¨éŠ˜æŸ„ã‚’ç”Ÿæˆ"""
        try:
            if target_date_str is None:
                # å–¶æ¥­æ—¥ãƒ™ãƒ¼ã‚¹ã§åˆ†æå¯¾è±¡æ—¥ã‚’æ±ºå®š
                target_date = JapanMarketCalendar.get_target_date_for_analysis()
                target_date_str = str(target_date)
                logger.info(f"ğŸ—“ï¸ è‡ªå‹•é¸æŠã•ã‚ŒãŸåˆ†æå¯¾è±¡æ—¥: {target_date_str}")
            
            target_date = pd.to_datetime(target_date_str)
            next_date = JapanMarketCalendar.get_next_market_day(target_date)
            
            logger.info(f"ğŸš€ {target_date_str}ã®æ¨å¥¨éŠ˜æŸ„åˆ†æé–‹å§‹...")
            
            feature_df = self._prepare_feature_frame(target_date)
            target_data = feature_df[feature_df['Date'] == target_date].copy()
            
            if len(target_data) == 0:
                logger.warning(f"å¯¾è±¡æ—¥ {target_date_str} ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return []

            logger.info(f"ğŸ“Š å¯¾è±¡æ—¥ã®éŠ˜æŸ„æ•°: {len(target_data)}éŠ˜æŸ„")

            target_data = target_data.replace([np.inf, -np.inf], np.nan)
            target_data = target_data.ffill().fillna(0)
            
            recommendations = []
            
            for _, row in target_data.iterrows():
                try:
                    code = row['Code']
                    
                    # çµ‚å€¤ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡ã‚’æŠ½å‡ºï¼ˆæ¬ æåˆ—ã¯0ã§è£œå®Œï¼‰
                    feature_values = []
                    missing_cols = []
                    for col in self.feature_names:
                        if col in row:
                            feature_values.append(row[col])
                        else:
                            feature_values.append(0.0)
                            missing_cols.append(col)

                    if missing_cols:
                        logger.debug(
                            "éŠ˜æŸ„ %s: æ¬ æç‰¹å¾´é‡ %s ã‚’0ã§è£œå®Œ",
                            code,
                            ", ".join(missing_cols)
                        )

                    features = pd.DataFrame([feature_values], columns=self.feature_names)

                    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
                    if self.scaler is not None:
                        features = self.scaler.transform(features)

                    # ç‰¹å¾´é‡é¸æŠ
                    if self.selector is not None:
                        features = self.selector.transform(features)
                    
                    # äºˆæ¸¬
                    prediction_proba = self.model.predict_proba(features)[0][1]
                    if self.calibration is not None:
                        coef = self.calibration.get('coef', 0.0)
                        intercept = self.calibration.get('intercept', 0.0)
                        linear = coef * prediction_proba + intercept
                        prediction_proba = 1 / (1 + np.exp(-linear))
                    
                    # æ¨å¥¨æ¡ä»¶ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ60%ä»¥ä¸Šï¼‰
                    if prediction_proba >= self.min_probability:
                        target_return = float(getattr(self.pipeline, 'target_return', 0.01))
                        recommendations.append({
                            'code': code,
                            'company_name': self._get_company_name(code),
                            'prediction_probability': prediction_proba,
                            'current_price': row['Close'],
                            'volume': row['Volume'],
                            'target_price': row['Close'] * (1 + target_return),
                            'stop_loss_price': row['Close'] * (1 - target_return),
                            'expected_return': target_return * 100,
                            'holding_period': 1,
                            'sector': self.company_sectors.get(str(code), 'Unknown')
                        })
                
                except Exception as e:
                    logger.debug(f"éŠ˜æŸ„ {code} ã®äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            # ç¢ºä¿¡åº¦ã§ã‚½ãƒ¼ãƒˆ
            recommendations.sort(key=lambda x: x['prediction_probability'], reverse=True)

            selected = []
            sector_counts = {}
            for rec in recommendations:
                sector = rec.get('sector', 'Unknown')
                if sector_counts.get(sector, 0) >= self.max_per_sector:
                    continue
                selected.append(rec)
                sector_counts[sector] = sector_counts.get(sector, 0) + 1
                if len(selected) >= top_n:
                    break
            recommendations = selected
            
            logger.info(f"âœ… æ¨å¥¨éŠ˜æŸ„ç”Ÿæˆå®Œäº†: {len(recommendations)}éŠ˜æŸ„")
            return recommendations
        
        except Exception as e:
            logger.error(f"æ¨å¥¨éŠ˜æŸ„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def create_report(self, target_date_str=None, top_n=None):
        """ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"""
        if target_date_str is None:
            # å–¶æ¥­æ—¥ãƒ™ãƒ¼ã‚¹ã§åˆ†æå¯¾è±¡æ—¥ã‚’æ±ºå®š
            target_date = JapanMarketCalendar.get_target_date_for_analysis()
            target_date_str = str(target_date)
            logger.info(f"ğŸ—“ï¸ è‡ªå‹•é¸æŠã•ã‚ŒãŸåˆ†æå¯¾è±¡æ—¥: {target_date_str}")
        
        target_date = pd.to_datetime(target_date_str)
        next_date = JapanMarketCalendar.get_next_market_day(target_date)
        if top_n is None:
            top_n = self.config.get('top_n', 5)
        
        recommendations = self.generate_recommendations(target_date_str, top_n)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        model_accuracy_display = "N/A"
        if self.model_accuracy is not None:
            model_accuracy_display = f"{self.model_accuracy * 100:.2f}%"

        report = f"""ğŸ“ˆ æ—¥æ¬¡æ ªä¾¡äºˆæ¸¬ãƒ¬ãƒãƒ¼ãƒˆï¼ˆçµ‚å€¤ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«å¯¾å¿œï¼‰
=====================================

ğŸ“… åŸºæº–æ—¥ä»˜: {target_date_str}
ğŸ“… æ¨å¥¨å–å¼•æ—¥: {next_date.strftime('%Y-%m-%d')}
ğŸ† æ¨å¥¨éŠ˜æŸ„æ•°: {len(recommendations)}éŠ˜æŸ„ (TOP {top_n})
âš™ï¸ ãƒ¢ãƒ‡ãƒ«ç²¾åº¦: {model_accuracy_display} (Close-to-Close Precision System V1)
ğŸ“ˆ åˆ¤å®šé–¾å€¤: {getattr(self.pipeline, 'target_return', 0.01)*100:.1f}% (çµ‚å€¤â†’çµ‚å€¤)
ğŸ¯ æ¨å¥¨é–¾å€¤: ç¿Œå–¶æ¥­æ—¥çµ‚å€¤ãŒ+{getattr(self.pipeline, 'target_return', 0.01)*100:.1f}%ä»¥ä¸Šã«ãªã‚‹ç¢ºç‡ {self.min_probability*100:.0f}%ä»¥ä¸Š

=====================================
ğŸ¯ æ¨å¥¨éŠ˜æŸ„ä¸€è¦§
=====================================
"""
        
        if not recommendations:
            report += "\nâŒ æ¨å¥¨æ¡ä»¶ã‚’æº€ãŸã™éŠ˜æŸ„ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n"
        else:
            for i, rec in enumerate(recommendations, 1):
                report += f"""
{i}ä½: {rec['company_name']} ({rec['code']})
  ğŸ’° ç¾åœ¨ä¾¡æ ¼: Â¥{rec['current_price']:,.0f}
  ğŸ“ˆ ç›®æ¨™ä¾¡æ ¼: Â¥{rec['target_price']:,.0f} (+{rec['expected_return']:.1f}%)
  ğŸ“‰ æåˆ‡ä¾¡æ ¼: Â¥{rec['stop_loss_price']:,.0f} (-{rec['expected_return']:.1f}%)
  ğŸ¯ äºˆæ¸¬ç¢ºç‡: {rec['prediction_probability']:.1%}
  ğŸ¢ ã‚»ã‚¯ã‚¿ãƒ¼: {rec.get('sector', 'Unknown')}
  ğŸ“Š å‡ºæ¥é«˜: {rec['volume']:,}æ ª
  â° æ¨å¥¨ä¿æœ‰: {rec['holding_period']}æ—¥é–“
"""
        
        report += f"""
=====================================
ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
=====================================
ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: Close-to-Close Precision System V1
ğŸ•’ åˆ¤å®šæ¡ä»¶: å‰æ—¥çµ‚å€¤â†’ç¿Œæ—¥çµ‚å€¤ã§+{self.pipeline.target_return*100:.1f}%
ğŸ¯ ãƒ¢ãƒ‡ãƒ«ç²¾åº¦: {model_accuracy_display}
ğŸ“Š ç‰¹å¾´é‡æ•°: {len(self.feature_names)}å€‹
ğŸ“… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        # æœˆåˆ¥ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆã¨ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        target_month = target_date.strftime('%Y-%m')
        month_dir = self.results_dir / target_month
        month_dir.mkdir(parents=True, exist_ok=True)
        
        report_file = month_dir / f"{target_date_str}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")
        return report

def main():
    parser = argparse.ArgumentParser(description="çµ‚å€¤ãƒ™ãƒ¼ã‚¹æ¨å¥¨éŠ˜æŸ„ã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument("--date", type=str, help="å¯¾è±¡æ—¥ä»˜ (YYYY-MM-DD)")
    parser.add_argument("--top", type=int, default=None, help="ä¸Šä½NéŠ˜æŸ„")
    parser.add_argument("--target-return", type=float, default=None, help="çµ‚å€¤ãƒ™ãƒ¼ã‚¹åˆ¤å®šé–¾å€¤ (ä¾‹: 0.8%â†’0.008)")
    parser.add_argument("--imbalance-boost", type=float, default=1.0, help="scale_pos_weight ã«æ›ã‘ã‚‹å€ç‡")
    parser.add_argument("--min-probability", type=float, default=None, help="æ¨å¥¨ã«ç”¨ã„ã‚‹æœ€ä½äºˆæ¸¬ç¢ºç‡")
    parser.add_argument("--max-per-sector", type=int, default=None, help="ã‚»ã‚¯ã‚¿ãƒ¼ã‚ãŸã‚Šã®ä¸Šé™éŠ˜æŸ„æ•°")

    args = parser.parse_args()

    system = DailyStockRecommendationCloseV1(target_return=args.target_return, imbalance_boost=args.imbalance_boost, min_probability=args.min_probability, max_per_sector=args.max_per_sector)
    report = system.create_report(args.date, args.top)
    print(report)

if __name__ == "__main__":
    main()
