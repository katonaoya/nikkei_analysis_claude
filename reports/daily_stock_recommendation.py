#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¥ä»˜æŒ‡å®šã«ã‚ˆã‚‹ç¿Œæ—¥æ¨å¥¨éŠ˜æŸ„ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚·ã‚¹ãƒ†ãƒ 

ä½¿ç”¨æ–¹æ³•:
    python daily_stock_recommendation.py --date 2025-09-05
    python daily_stock_recommendation.py --date 2025-09-05 --top 10
"""

import pandas as pd
import numpy as np
import argparse
import logging
from pathlib import Path
from datetime import datetime, timedelta
import joblib
from typing import List, Dict, Tuple, Optional
import json

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

class DailyStockRecommendation:
    """æ—¥ä»˜æŒ‡å®šã«ã‚ˆã‚‹ç¿Œæ—¥æ¨å¥¨éŠ˜æŸ„ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, model_dir: str = "models", data_dir: str = "data"):
        self.model_dir = Path(model_dir)
        self.data_dir = Path(data_dir)
        self.results_dir = Path("results/daily_reports")
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä¸¦åˆ—æœ€é©åŒ–çµæœã‚ˆã‚Šï¼‰
        self.optimal_params = {
            'holding_days': 10,
            'profit_target': 0.07,  # 7%
            'stop_loss': 0.05       # 5%
        }
        
        # éŠ˜æŸ„åãƒãƒƒãƒ”ãƒ³ã‚°èª­ã¿è¾¼ã¿
        self.company_names = self._load_company_names()
        
        # ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’èª­ã¿è¾¼ã¿
        self.model = None
        self.scaler = None
        self.feature_names = None
        self._load_model_components()
    
    def _load_company_names(self) -> Dict[str, str]:
        """éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã¨ä¼šç¤¾åã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã¿"""
        try:
            csv_path = self.data_dir / "nikkei225_codes.csv"
            if csv_path.exists():
                df = pd.read_csv(csv_path)
                return dict(zip(df['code'].astype(str).str.zfill(4), df['name']))
            else:
                logger.warning("éŠ˜æŸ„åãƒãƒƒãƒ”ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {}
        except Exception as e:
            logger.warning(f"éŠ˜æŸ„åãƒãƒƒãƒ”ãƒ³ã‚°ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
            return {}
    
    def _load_model_components(self):
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã€ç‰¹å¾´é‡åã‚’èª­ã¿è¾¼ã¿"""
        try:
            # Enhanced V3ãƒ¢ãƒ‡ãƒ«ã‚’å„ªå…ˆçš„ã«æ¢ã™
            model_files = list(self.model_dir.glob("enhanced_v3/*enhanced_model_v3*.joblib"))
            if not model_files:
                model_files = list(self.model_dir.glob("*final_model*.pkl"))
                model_files.extend(list(self.model_dir.glob("*model*.joblib")))
            
            scaler_files = list(self.model_dir.glob("enhanced_v3/*scaler*.pkl"))
            scaler_files.extend(list(self.model_dir.glob("*scaler*.pkl")))
            scaler_files.extend(list(self.model_dir.glob("*scaler*.joblib")))
            
            if not model_files:
                logger.error("å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return
            
            if not scaler_files:
                logger.warning("ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãªã—ã§å®Ÿè¡Œã—ã¾ã™ã€‚")
                self.scaler = None
            else:
                # æœ€æ–°ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ä½¿ç”¨
                latest_scaler = max(scaler_files, key=lambda x: x.stat().st_mtime)
                self.scaler = joblib.load(latest_scaler)
                logger.info(f"âœ… ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼èª­ã¿è¾¼ã¿å®Œäº†: {latest_scaler.name}")
            
            # æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
            latest_model = max(model_files, key=lambda x: x.stat().st_mtime)
            model_dict = joblib.load(latest_model)
            
            # ãƒ¢ãƒ‡ãƒ«ãŒè¾æ›¸å½¢å¼ã®å ´åˆ
            if isinstance(model_dict, dict):
                self.model = model_dict.get('model')
                if self.scaler is None and 'scaler' in model_dict:
                    self.scaler = model_dict.get('scaler')
                if 'feature_cols' in model_dict:
                    self.feature_names = model_dict.get('feature_cols')
            else:
                self.model = model_dict
            
            # ç‰¹å¾´é‡åã‚’èª­ã¿è¾¼ã¿ï¼ˆã‚ã‚Œã°ï¼‰
            feature_file = self.model_dir / "feature_names.json"
            if feature_file.exists():
                with open(feature_file, 'r', encoding='utf-8') as f:
                    self.feature_names = json.load(f)
            
            logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {latest_model.name}")
            
        except Exception as e:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    def load_historical_data(self, target_date: str) -> pd.DataFrame:
        """æŒ‡å®šæ—¥ä»˜ã¾ã§ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        logger.info(f"ğŸ“Š {target_date}ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™ï¼ˆè¤‡æ•°ã®å ´æ‰€ã‚’ãƒã‚§ãƒƒã‚¯ï¼‰
        parquet_files = list(self.data_dir.glob("*nikkei225*.parquet"))
        parquet_files.extend(list(self.data_dir.glob("**/*nikkei225*.parquet")))
        
        if not parquet_files:
            logger.error("å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
        
        # æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
        latest_file = max(parquet_files, key=lambda x: x.stat().st_mtime)
        df = pd.read_parquet(latest_file)
        
        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿
        df['Date'] = pd.to_datetime(df['Date'])
        target_datetime = pd.to_datetime(target_date)
        df = df[df['Date'] <= target_datetime]
        
        logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df):,}ä»¶ (æœ€æ–°: {df['Date'].max().date()})")
        return df
    
    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æŠ€è¡“æŒ‡æ¨™ç‰¹å¾´é‡ã‚’ç”Ÿæˆ"""
        logger.info("ğŸ”§ æŠ€è¡“æŒ‡æ¨™ç”Ÿæˆä¸­...")
        
        if df.empty:
            return df
        
        df = df.copy()
        df = df.sort_values(['Code', 'Date'])
        
        enhanced_df_list = []
        
        for code in df['Code'].unique():
            code_df = df[df['Code'] == code].copy()
            
            if len(code_df) < 50:  # æœ€ä½é™å¿…è¦ãªãƒ‡ãƒ¼ã‚¿æ•°
                continue
            
            # åŸºæœ¬ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            code_df['Returns'] = code_df['Close'].pct_change()
            code_df['Volume_MA_20'] = code_df['Volume'].rolling(20).mean()
            code_df['Price_Volume_Trend'] = code_df['Returns'] * code_df['Volume']
            
            # ç§»å‹•å¹³å‡ï¼ˆå¤šæœŸé–“ï¼‰
            for window in [5, 10, 20, 50]:
                code_df[f'MA_{window}'] = code_df['Close'].rolling(window).mean()
                code_df[f'MA_{window}_ratio'] = code_df['Close'] / code_df[f'MA_{window}']
            
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå¤šæœŸé–“ï¼‰
            for window in [5, 10, 20]:
                code_df[f'Volatility_{window}'] = code_df['Returns'].rolling(window).std()
            
            # RSIï¼ˆå¤šæœŸé–“ï¼‰
            for window in [7, 14, 21]:
                delta = code_df['Close'].diff()
                gain = (delta.where(delta > 0, 0)).rolling(window).mean()
                loss = (-delta.where(delta < 0, 0)).rolling(window).mean()
                rs = gain / loss
                code_df[f'RSI_{window}'] = 100 - (100 / (1 + rs))
            
            # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
            for window in [20]:
                rolling_mean = code_df['Close'].rolling(window).mean()
                rolling_std = code_df['Close'].rolling(window).std()
                code_df[f'BB_upper_{window}'] = rolling_mean + (rolling_std * 2)
                code_df[f'BB_lower_{window}'] = rolling_mean - (rolling_std * 2)
                code_df[f'BB_ratio_{window}'] = (code_df['Close'] - code_df[f'BB_lower_{window}']) / (code_df[f'BB_upper_{window}'] - code_df[f'BB_lower_{window}'])
            
            # MACD
            exp1 = code_df['Close'].ewm(span=12, adjust=False).mean()
            exp2 = code_df['Close'].ewm(span=26, adjust=False).mean()
            code_df['MACD'] = exp1 - exp2
            code_df['MACD_signal'] = code_df['MACD'].ewm(span=9, adjust=False).mean()
            code_df['MACD_histogram'] = code_df['MACD'] - code_df['MACD_signal']
            
            # ã‚ªãƒ³ãƒãƒ©ãƒ³ã‚¹ãƒœãƒªãƒ¥ãƒ¼ãƒ 
            code_df['OBV'] = (code_df['Volume'] * np.where(code_df['Close'] > code_df['Close'].shift(1), 1, 
                             np.where(code_df['Close'] < code_df['Close'].shift(1), -1, 0))).cumsum()
            
            # ã‚¹ãƒˆã‚­ãƒ£ã‚¹ãƒ†ã‚£ã‚¯ã‚¹
            for window in [14]:
                low_min = code_df['Low'].rolling(window).min()
                high_max = code_df['High'].rolling(window).max()
                code_df[f'Stoch_K_{window}'] = 100 * (code_df['Close'] - low_min) / (high_max - low_min)
                code_df[f'Stoch_D_{window}'] = code_df[f'Stoch_K_{window}'].rolling(3).mean()
            
            # ATR (Average True Range)
            high_low = code_df['High'] - code_df['Low']
            high_close = np.abs(code_df['High'] - code_df['Close'].shift())
            low_close = np.abs(code_df['Low'] - code_df['Close'].shift())
            true_range = np.maximum(high_low, np.maximum(high_close, low_close))
            code_df['ATR_14'] = true_range.rolling(14).mean()
            
            enhanced_df_list.append(code_df)
        
        if not enhanced_df_list:
            logger.error("ç‰¹å¾´é‡ç”Ÿæˆå¯èƒ½ãªéŠ˜æŸ„ãŒã‚ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
        
        enhanced_df = pd.concat(enhanced_df_list, ignore_index=True)
        enhanced_df = enhanced_df.dropna()
        
        logger.info(f"âœ… ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {len(enhanced_df):,}ä»¶")
        return enhanced_df
    
    def predict_recommendations(self, df: pd.DataFrame, target_date: str, top_n: int = 5) -> List[Dict]:
        """ç¿Œæ—¥ã®æ¨å¥¨éŠ˜æŸ„ã‚’äºˆæ¸¬"""
        logger.info(f"ğŸ”® {target_date}ç¿Œæ—¥ã®æ¨å¥¨éŠ˜æŸ„äºˆæ¸¬ä¸­...")
        
        if self.model is None:
            logger.error("ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return []
        
        # æŒ‡å®šæ—¥ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        target_datetime = pd.to_datetime(target_date)
        latest_df = df[df['Date'] == target_datetime]
        
        if latest_df.empty:
            logger.warning(f"{target_date}ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç›´è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            latest_df = df[df['Date'] == df['Date'].max()]
        
        recommendations = []
        
        # ç‰¹å¾´é‡ã‚«ãƒ©ãƒ ã‚’ç‰¹å®šï¼ˆãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å–å¾—ã™ã‚‹ã‹ã€è‡ªå‹•æ¤œå‡ºï¼‰
        if self.feature_names:
            feature_cols = self.feature_names
        else:
            feature_cols = [col for col in latest_df.columns 
                           if col not in ['Code', 'Date', 'CompanyName', 'Target', 'Open', 'High', 'Low', 'Close', 'Volume']]
        
        for _, row in latest_df.iterrows():
            try:
                code = row['Code']
                company_name = self.company_names.get(str(code), f"éŠ˜æŸ„{code}")
                
                # ç‰¹å¾´é‡ã‚’æº–å‚™
                features = row[feature_cols].values.reshape(1, -1)
                
                # æ¬ æå€¤ãƒã‚§ãƒƒã‚¯
                if pd.isna(features).any():
                    continue
                
                # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
                if self.scaler is not None:
                    features_scaled = self.scaler.transform(features)
                else:
                    features_scaled = features
                
                # äºˆæ¸¬
                prediction = self.model.predict(features_scaled)[0]
                prediction_proba = self.model.predict_proba(features_scaled)[0][1]  # æ­£ä¾‹ç¢ºç‡
                
                # æ¨å¥¨æ¡ä»¶ï¼ˆç¢ºç‡é–¾å€¤ï¼‰- 78.6%ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ã«åˆã‚ã›ã¦èª¿æ•´
                if prediction_proba >= 0.60:  # 60%ä»¥ä¸Šã®ä¿¡é ¼åº¦
                    recommendations.append({
                        'code': code,
                        'company_name': company_name,
                        'prediction_probability': prediction_proba,
                        'current_price': row['Close'],
                        'target_price': row['Close'] * (1 + self.optimal_params['profit_target']),
                        'stop_loss_price': row['Close'] * (1 - self.optimal_params['stop_loss']),
                        'expected_return': self.optimal_params['profit_target'] * 100,
                        'holding_period': self.optimal_params['holding_days'],
                        'volume': row['Volume'],
                        'rsi_14': row.get('RSI_14', None),
                        'macd_histogram': row.get('MACD_histogram', None)
                    })
                    
            except Exception as e:
                logger.warning(f"éŠ˜æŸ„{code}ã®äºˆæ¸¬å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        # ç¢ºç‡é †ã§ã‚½ãƒ¼ãƒˆ
        recommendations.sort(key=lambda x: x['prediction_probability'], reverse=True)
        
        logger.info(f"âœ… æ¨å¥¨éŠ˜æŸ„æŠ½å‡ºå®Œäº†: {len(recommendations)}éŠ˜æŸ„")
        return recommendations[:top_n]
    
    def generate_report(self, recommendations: List[Dict], target_date: str, top_n: int) -> str:
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        next_date = (pd.to_datetime(target_date) + timedelta(days=1)).strftime('%Y-%m-%d')
        
        report = f"""
ğŸ“ˆ æ—¥æ¬¡æ ªä¾¡äºˆæ¸¬ãƒ¬ãƒãƒ¼ãƒˆ
=====================================

ğŸ“… åŸºæº–æ—¥ä»˜: {target_date}
ğŸ“… æ¨å¥¨å–å¼•æ—¥: {next_date}
ğŸ† æ¨å¥¨éŠ˜æŸ„æ•°: {len(recommendations)}éŠ˜æŸ„ (TOP {top_n})
âš™ï¸  æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: ä¿æœ‰{self.optimal_params['holding_days']}æ—¥ãƒ»åˆ©ç¢º{self.optimal_params['profit_target']*100:.1f}%ãƒ»æåˆ‡{self.optimal_params['stop_loss']*100:.1f}%

=====================================
ğŸ¯ æ¨å¥¨éŠ˜æŸ„ä¸€è¦§
=====================================
"""
        
        if not recommendations:
            report += "\nâŒ æ¨å¥¨æ¡ä»¶ã‚’æº€ãŸã™éŠ˜æŸ„ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n"
            return report
        
        for i, rec in enumerate(recommendations, 1):
            report += f"""
{i}ä½: {rec['company_name']} ({rec['code']})
  ğŸ’° ç¾åœ¨ä¾¡æ ¼: Â¥{rec['current_price']:,.0f}
  ğŸ“ˆ ç›®æ¨™ä¾¡æ ¼: Â¥{rec['target_price']:,.0f} (+{rec['expected_return']:.1f}%)
  ğŸ“‰ æåˆ‡ä¾¡æ ¼: Â¥{rec['stop_loss_price']:,.0f} (-{self.optimal_params['stop_loss']*100:.1f}%)
  ğŸ¯ äºˆæ¸¬ç¢ºç‡: {rec['prediction_probability']:.1%}
  ğŸ“Š å‡ºæ¥é«˜: {rec['volume']:,}æ ª
  ğŸ“ˆ RSI(14): {rec['rsi_14']:.1f if rec['rsi_14'] is not None else 'N/A'}
  ğŸ“Š MACD: {'ä¸Šæ˜‡' if rec['macd_histogram'] and rec['macd_histogram'] > 0 else 'ä¸‹é™' if rec['macd_histogram'] and rec['macd_histogram'] < 0 else 'N/A'}
  â° æ¨å¥¨ä¿æœ‰: {rec['holding_period']}æ—¥é–“
"""
        
        report += f"""
=====================================
ğŸ“Š æŠ•è³‡æˆ¦ç•¥ã‚µãƒãƒªãƒ¼
=====================================

ğŸ’¡ é‹ç”¨æ–¹é‡:
  â€¢ å„éŠ˜æŸ„ã¸ã®æŠ•è³‡ä¸Šé™: 20ä¸‡å††æ¨å¥¨
  â€¢ æœ€å¤§åŒæ™‚ä¿æœ‰: 5éŠ˜æŸ„
  â€¢ åˆ©ç¢ºç›®æ¨™: +{self.optimal_params['profit_target']*100:.1f}%
  â€¢ æåˆ‡è¨­å®š: -{self.optimal_params['stop_loss']*100:.1f}%
  â€¢ æœ€å¤§ä¿æœ‰æœŸé–“: {self.optimal_params['holding_days']}æ—¥

âš ï¸  ãƒªã‚¹ã‚¯ç®¡ç†:
  â€¢ å¿…ãšæåˆ‡ã‚Šãƒ©ã‚¤ãƒ³ã‚’è¨­å®šã—ã¦ãã ã•ã„
  â€¢ å¸‚å ´æ€¥å¤‰æ™‚ã¯æ—©æœŸæ’¤é€€ã‚’æ¤œè¨
  â€¢ åˆ†æ•£æŠ•è³‡ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„

ğŸ“ˆ æœŸå¾…ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:
  â€¢ å¹´é–“æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³: 114.63%
  â€¢ æ¨å®šå‹ç‡: 54.1%
  â€¢ éå»æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: æ—¥çµŒ225ãƒ»10å¹´é–“

=====================================
âš ï¸  å…è²¬äº‹é …: æœ¬ãƒ¬ãƒãƒ¼ãƒˆã¯éå»ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãäºˆæ¸¬ã§ã‚ã‚Šã€
æŠ•è³‡æˆæœã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
æŠ•è³‡ã¯è‡ªå·±è²¬ä»»ã§è¡Œã£ã¦ãã ã•ã„ã€‚
=====================================
"""
        
        return report
    
    def save_report(self, report: str, target_date: str) -> str:
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        timestamp = datetime.now().strftime('%H%M%S')
        filename = f"stock_recommendation_{target_date}_{timestamp}.txt"
        filepath = self.results_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {filepath}")
        return str(filepath)
    
    def run_daily_analysis(self, target_date: str, top_n: int = 5) -> str:
        """æ—¥æ¬¡åˆ†æã‚’å®Ÿè¡Œ"""
        logger.info(f"ğŸš€ {target_date}ã®æ—¥æ¬¡åˆ†æé–‹å§‹...")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            df = self.load_historical_data(target_date)
            if df.empty:
                raise Exception("å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            # ç‰¹å¾´é‡ç”Ÿæˆ
            enhanced_df = self.create_features(df)
            if enhanced_df.empty:
                raise Exception("ç‰¹å¾´é‡ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            # æ¨å¥¨éŠ˜æŸ„äºˆæ¸¬
            recommendations = self.predict_recommendations(enhanced_df, target_date, top_n)
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report = self.generate_report(recommendations, target_date, top_n)
            
            # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
            filepath = self.save_report(report, target_date)
            
            # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
            print(report)
            
            logger.info("âœ… æ—¥æ¬¡åˆ†æå®Œäº†")
            return filepath
            
        except Exception as e:
            logger.error(f"âŒ æ—¥æ¬¡åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return ""

def main():
    parser = argparse.ArgumentParser(description='æ—¥ä»˜æŒ‡å®šã«ã‚ˆã‚‹ç¿Œæ—¥æ¨å¥¨éŠ˜æŸ„ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ')
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä»Šæ—¥ã®æ—¥ä»˜ã«ã™ã‚‹
    today = datetime.now().strftime('%Y-%m-%d')
    parser.add_argument('--date', default=today, help=f'åŸºæº–æ—¥ä»˜ (YYYY-MM-DD, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {today})')
    parser.add_argument('--top', type=int, default=5, help='æ¨å¥¨éŠ˜æŸ„æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5)')
    
    args = parser.parse_args()
    
    # æ—¥ä»˜æ¤œè¨¼
    try:
        pd.to_datetime(args.date)
    except:
        logger.error("âŒ æ—¥ä»˜å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ (YYYY-MM-DD)")
        return
    
    # åˆ†æå®Ÿè¡Œ
    analyzer = DailyStockRecommendation()
    result_file = analyzer.run_daily_analysis(args.date, args.top)
    
    if result_file:
        logger.info(f"ğŸ‰ åˆ†æå®Œäº†: {result_file}")
    else:
        logger.error("âŒ åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()