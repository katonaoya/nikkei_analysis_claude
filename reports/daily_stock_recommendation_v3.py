#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
V3ãƒ¢ãƒ‡ãƒ«å¯¾å¿œæ¨å¥¨éŠ˜æŸ„ã‚·ã‚¹ãƒ†ãƒ 
78.6%ç²¾åº¦ã®Enhanced Precision System V3ã«å®Œå…¨å¯¾å¿œ
"""

import pandas as pd
import numpy as np
import logging
from pathlib import Path
from datetime import datetime, timedelta
import joblib
import argparse
import json
import sys
sys.path.append(str(Path(__file__).parent.parent))
from utils.market_calendar import JapanMarketCalendar

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

class DailyStockRecommendationV3:
    """V3ãƒ¢ãƒ‡ãƒ«å¯¾å¿œæ¨å¥¨éŠ˜æŸ„ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.model_dir = Path("models")
        self.data_dir = Path("data")
        self.results_dir = Path("production_reports")
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # ãƒ¢ãƒ‡ãƒ«ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.model = None
        self.scaler = None
        self.selector = None
        self.feature_names = None
        
        # ä¼šç¤¾åãƒãƒƒãƒ”ãƒ³ã‚°
        self.company_names = {}
        self._load_company_names()
        self._load_v3_model()
    
    def _load_company_names(self):
        """ä¼šç¤¾åãƒãƒƒãƒ”ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¼šç¤¾åã‚’èª­ã¿è¾¼ã¿
            csv_file = Path("docment/ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±/nikkei225_matched_companies_20250909_230026.csv")
            if csv_file.exists():
                df = pd.read_csv(csv_file, encoding='utf-8-sig')
                for _, row in df.iterrows():
                    code = str(row['target_code'])
                    name = row['target_name'].replace('ï¼ˆæ ªï¼‰', '').replace('(æ ª)', '')
                    self.company_names[code] = name
                logger.info(f"âœ… ä¼šç¤¾åãƒãƒƒãƒ”ãƒ³ã‚°èª­ã¿è¾¼ã¿å®Œäº†: {len(self.company_names)}ç¤¾")
            else:
                logger.warning("ä¼šç¤¾åCSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        except Exception as e:
            logger.error(f"ä¼šç¤¾åèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _get_company_name(self, code):
        """éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ä¼šç¤¾åã‚’å–å¾—"""
        return self.company_names.get(str(code), f"éŠ˜æŸ„{code}")
    
    def _load_v3_model(self):
        """V3ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # V3ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
            model_files = list(self.model_dir.glob("enhanced_v3/*enhanced_model_v3*.joblib"))
            if not model_files:
                raise FileNotFoundError("V3ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            # æœ€æ–°ã®V3ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            latest_model = max(model_files, key=lambda x: x.stat().st_mtime)
            model_data = joblib.load(latest_model)
            
            self.model = model_data['model']
            self.scaler = model_data.get('scaler')
            self.selector = model_data.get('selector')
            self.feature_names = model_data['feature_cols']
            
            logger.info(f"âœ… V3ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {latest_model.name}")
            logger.info(f"ğŸ“Š ç‰¹å¾´é‡æ•°: {len(self.feature_names)}")
            
        except Exception as e:
            logger.error(f"V3ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _load_stock_data(self, target_date):
        """æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # æœ€æ–°ã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
            data_files = list(self.data_dir.glob("processed/nikkei225_complete_*.parquet"))
            if not data_files:
                raise FileNotFoundError("æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            latest_data = max(data_files, key=lambda x: x.stat().st_mtime)
            df = pd.read_parquet(latest_data)
            df['Date'] = pd.to_datetime(df['Date'])
            
            # å¯¾è±¡æ—¥ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿
            df = df[df['Date'] <= target_date].copy()
            
            logger.info(f"âœ… æ ªä¾¡ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df):,}ä»¶ (æœ€æ–°: {df['Date'].max().strftime('%Y-%m-%d')})")
            return df
        
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _create_v3_features(self, df):
        """V3ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ç‰¹å¾´é‡ã‚’ä½œæˆ"""
        df = df.copy()
        df = df.sort_values(['Code', 'Date'])
        
        enhanced_df_list = []
        
        for code in df['Code'].unique():
            code_df = df[df['Code'] == code].copy()
            
            if len(code_df) < 30:
                continue
            
            # V3ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡ã‚’æ­£ç¢ºã«å†ç¾
            code_df['Returns'] = code_df['Close'].pct_change(fill_method=None)
            code_df['MA_5'] = code_df['Close'].rolling(5).mean()
            code_df['MA_20'] = code_df['Close'].rolling(20).mean()
            code_df['Volatility'] = code_df['Returns'].rolling(20).std()
            
            # RSI
            delta = code_df['Close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
            rs = gain / loss
            code_df['RSI'] = 100 - (100 / (1 + rs))
            
            enhanced_df_list.append(code_df)
        
        if not enhanced_df_list:
            raise ValueError("å‡¦ç†å¯èƒ½ãªéŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        
        enhanced_df = pd.concat(enhanced_df_list, ignore_index=True)
        
        # ç„¡é™å€¤ãƒ»æ¬ æå€¤å‡¦ç†
        enhanced_df = enhanced_df.replace([np.inf, -np.inf], np.nan)
        enhanced_df = enhanced_df.fillna(method='ffill').fillna(0)
        
        logger.info(f"âœ… V3ç‰¹å¾´é‡ä½œæˆå®Œäº†: {len(enhanced_df):,}ä»¶")
        return enhanced_df
    
    def generate_recommendations(self, target_date_str=None, top_n=5):
        """æ¨å¥¨éŠ˜æŸ„ã‚’ç”Ÿæˆ"""
        try:
            if target_date_str is None:
                # å–¶æ¥­æ—¥ãƒ™ãƒ¼ã‚¹ã§åˆ†æå¯¾è±¡æ—¥ã‚’æ±ºå®š
                target_date = JapanMarketCalendar.get_target_date_for_analysis()
                target_date_str = str(target_date)
                logger.info(f"ğŸ—“ï¸ è‡ªå‹•é¸æŠã•ã‚ŒãŸåˆ†æå¯¾è±¡æ—¥: {target_date_str}")
            
            target_date = pd.to_datetime(target_date_str)
            next_date = JapanMarketCalendar.get_next_market_day(target_date)
            
            logger.info(f"ğŸš€ {target_date_str}ã®æ¨å¥¨éŠ˜æŸ„åˆ†æé–‹å§‹...")
            
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            df = self._load_stock_data(target_date)
            
            # V3ç‰¹å¾´é‡ä½œæˆ
            enhanced_df = self._create_v3_features(df)
            
            # å¯¾è±¡æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            target_data = enhanced_df[enhanced_df['Date'] == target_date].copy()
            
            if len(target_data) == 0:
                logger.warning(f"å¯¾è±¡æ—¥ {target_date_str} ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return []
            
            logger.info(f"ğŸ“Š å¯¾è±¡æ—¥ã®éŠ˜æŸ„æ•°: {len(target_data)}éŠ˜æŸ„")
            
            recommendations = []
            
            for _, row in target_data.iterrows():
                try:
                    code = row['Code']
                    
                    # V3ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡ã®ã¿ã‚’æŠ½å‡º
                    features = row[self.feature_names].values.reshape(1, -1)
                    
                    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
                    if self.scaler is not None:
                        features = self.scaler.transform(features)
                    
                    # ç‰¹å¾´é‡é¸æŠ
                    if self.selector is not None:
                        features = self.selector.transform(features)
                    
                    # äºˆæ¸¬
                    prediction_proba = self.model.predict_proba(features)[0][1]
                    
                    # æ¨å¥¨æ¡ä»¶ï¼ˆ60%ä»¥ä¸Šï¼‰
                    if prediction_proba >= 0.60:
                        recommendations.append({
                            'code': code,
                            'company_name': self._get_company_name(code),
                            'prediction_probability': prediction_proba,
                            'current_price': row['Close'],
                            'volume': row['Volume'],
                            'target_price': row['Close'] * 1.07,
                            'stop_loss_price': row['Close'] * 0.95,
                            'expected_return': 7.0,
                            'holding_period': 10,
                        })
                
                except Exception as e:
                    logger.debug(f"éŠ˜æŸ„ {code} ã®äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            # ç¢ºä¿¡åº¦ã§ã‚½ãƒ¼ãƒˆ
            recommendations.sort(key=lambda x: x['prediction_probability'], reverse=True)
            recommendations = recommendations[:top_n]
            
            logger.info(f"âœ… æ¨å¥¨éŠ˜æŸ„ç”Ÿæˆå®Œäº†: {len(recommendations)}éŠ˜æŸ„")
            return recommendations
        
        except Exception as e:
            logger.error(f"æ¨å¥¨éŠ˜æŸ„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def create_report(self, target_date_str=None, top_n=5):
        """ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"""
        if target_date_str is None:
            # å–¶æ¥­æ—¥ãƒ™ãƒ¼ã‚¹ã§åˆ†æå¯¾è±¡æ—¥ã‚’æ±ºå®š
            target_date = JapanMarketCalendar.get_target_date_for_analysis()
            target_date_str = str(target_date)
            logger.info(f"ğŸ—“ï¸ è‡ªå‹•é¸æŠã•ã‚ŒãŸåˆ†æå¯¾è±¡æ—¥: {target_date_str}")
        
        target_date = pd.to_datetime(target_date_str)
        next_date = JapanMarketCalendar.get_next_market_day(target_date)
        
        recommendations = self.generate_recommendations(target_date_str, top_n)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = f"""ğŸ“ˆ æ—¥æ¬¡æ ªä¾¡äºˆæ¸¬ãƒ¬ãƒãƒ¼ãƒˆï¼ˆV3ãƒ¢ãƒ‡ãƒ«å¯¾å¿œï¼‰
=====================================

ğŸ“… åŸºæº–æ—¥ä»˜: {target_date_str}
ğŸ“… æ¨å¥¨å–å¼•æ—¥: {next_date.strftime('%Y-%m-%d')}
ğŸ† æ¨å¥¨éŠ˜æŸ„æ•°: {len(recommendations)}éŠ˜æŸ„ (TOP {top_n})
âš™ï¸ ãƒ¢ãƒ‡ãƒ«ç²¾åº¦: 78.6% (Enhanced Precision System V3)
ğŸ¯ æ¨å¥¨é–¾å€¤: 60%ä»¥ä¸Šã®äºˆæ¸¬ç¢ºä¿¡åº¦

=====================================
ğŸ¯ æ¨å¥¨éŠ˜æŸ„ä¸€è¦§
=====================================
"""
        
        if not recommendations:
            report += "\nâŒ æ¨å¥¨æ¡ä»¶ã‚’æº€ãŸã™éŠ˜æŸ„ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n"
        else:
            for i, rec in enumerate(recommendations, 1):
                report += f"""
{i}ä½: {rec['company_name']} ({rec['code']})
  ğŸ’° ç¾åœ¨ä¾¡æ ¼: Â¥{rec['current_price']:,.0f}
  ğŸ“ˆ ç›®æ¨™ä¾¡æ ¼: Â¥{rec['target_price']:,.0f} (+{rec['expected_return']:.1f}%)
  ğŸ“‰ æåˆ‡ä¾¡æ ¼: Â¥{rec['stop_loss_price']:,.0f} (-5.0%)
  ğŸ¯ äºˆæ¸¬ç¢ºç‡: {rec['prediction_probability']:.1%}
  ğŸ“Š å‡ºæ¥é«˜: {rec['volume']:,}æ ª
  â° æ¨å¥¨ä¿æœ‰: {rec['holding_period']}æ—¥é–“
"""
        
        report += f"""
=====================================
ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
=====================================
ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: Enhanced Precision System V3
ğŸ¯ ãƒ¢ãƒ‡ãƒ«ç²¾åº¦: 78.6%
ğŸ“Š ç‰¹å¾´é‡æ•°: {len(self.feature_names)}å€‹
ğŸ“… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        # æœˆåˆ¥ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆã¨ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        target_month = target_date.strftime('%Y-%m')
        month_dir = self.results_dir / target_month
        month_dir.mkdir(parents=True, exist_ok=True)
        
        report_file = month_dir / f"{target_date_str}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")
        return report

def main():
    parser = argparse.ArgumentParser(description="V3ãƒ¢ãƒ‡ãƒ«å¯¾å¿œæ¨å¥¨éŠ˜æŸ„ã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument("--date", type=str, help="å¯¾è±¡æ—¥ä»˜ (YYYY-MM-DD)")
    parser.add_argument("--top", type=int, default=5, help="ä¸Šä½NéŠ˜æŸ„")
    
    args = parser.parse_args()
    
    system = DailyStockRecommendationV3()
    report = system.create_report(args.date, args.top)
    print(report)

if __name__ == "__main__":
    main()