"""
æœˆå˜ä½ã§ã®ç²¾å¯†æœŸé–“ãƒ†ã‚¹ãƒˆ
8.5å¹´ã‹ã‚‰1ãƒ¶æœˆãšã¤æœŸé–“ã‚’å»¶é•·ã—ã¦æœ€å¤§å–å¾—å¯èƒ½æœŸé–“ã‚’ç‰¹å®š
"""

import os
import time
import json
from typing import Dict, List, Optional, Tuple
from datetime import datetime, date, timedelta
from pathlib import Path
import logging

import pandas as pd
import requests
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# APIè¨­å®š
JQUANTS_BASE_URL = "https://api.jquants.com/v1"


class MonthlyPrecisionTester:
    """æœˆå˜ä½ã§ã®ç²¾å¯†æœŸé–“ãƒ†ã‚¹ãƒˆç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.mail_address = os.getenv("JQUANTS_MAIL_ADDRESS")
        self.password = os.getenv("JQUANTS_PASSWORD")
        self.id_token: Optional[str] = None
        self.token_expires_at: Optional[datetime] = None
        
        if not self.mail_address or not self.password:
            raise ValueError("JQuantsã®èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ (.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„)")
        
        logger.info("æœˆå˜ä½ç²¾å¯†ãƒ†ã‚¹ãƒˆç”¨J-Quantsã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
    
    def _get_id_token(self) -> str:
        """IDãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—"""
        # ãƒˆãƒ¼ã‚¯ãƒ³ãŒæœ‰åŠ¹ãªå ´åˆã¯ãã®ã¾ã¾è¿”ã™
        if self.id_token and self.token_expires_at and datetime.now() < self.token_expires_at:
            return self.id_token
        
        logger.info("JQuantsèªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ä¸­...")
        time.sleep(3)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
        
        try:
            # ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            auth_payload = {
                "mailaddress": self.mail_address,
                "password": self.password
            }
            
            resp = requests.post(
                f"{JQUANTS_BASE_URL}/token/auth_user",
                data=json.dumps(auth_payload),
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            
            if resp.status_code == 429:
                logger.warning("ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã‚ˆã‚Š2åˆ†å¾…æ©Ÿ...")
                time.sleep(120)
                return self._get_id_token()
                
            resp.raise_for_status()
            refresh_token = resp.json().get("refreshToken")
            
            if not refresh_token:
                raise RuntimeError("ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            time.sleep(1)
            resp = requests.post(
                f"{JQUANTS_BASE_URL}/token/auth_refresh?refreshtoken={refresh_token}",
                timeout=30
            )
            
            if resp.status_code == 429:
                logger.warning("ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã‚ˆã‚Š2åˆ†å¾…æ©Ÿ...")
                time.sleep(120)
                return self._get_id_token()
                
            resp.raise_for_status()
            self.id_token = resp.json().get("idToken")
            
            if not self.id_token:
                raise RuntimeError("IDãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            # ãƒˆãƒ¼ã‚¯ãƒ³ã®æœ‰åŠ¹æœŸé™ã‚’è¨­å®š
            self.token_expires_at = datetime.now() + timedelta(hours=1)
            
            logger.info("èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—å®Œäº†")
            return self.id_token
            
        except Exception as e:
            logger.error(f"èªè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    def get_daily_quotes_test(
        self, 
        code: str,
        from_date: str,
        to_date: str
    ) -> pd.DataFrame:
        """
        æŒ‡å®šæœŸé–“ã®æ—¥æ¬¡æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
        """
        try:
            headers = {"Authorization": f"Bearer {self._get_id_token()}"}
            results: List[Dict] = []
            pagination_key: Optional[str] = None
            
            logger.info(f"éŠ˜æŸ„ {code}: ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹")
            logger.info(f"  æœŸé–“: {from_date} ï½ {to_date}")
            
            while True:
                params = {
                    "code": code,
                    "from": from_date,
                    "to": to_date
                }
                if pagination_key:
                    params["pagination_key"] = pagination_key
                
                resp = requests.get(
                    f"{JQUANTS_BASE_URL}/prices/daily_quotes",
                    headers=headers,
                    params=params,
                    timeout=120
                )
                
                if resp.status_code == 429:
                    logger.warning(f"éŠ˜æŸ„ {code}: ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã€30ç§’å¾…æ©Ÿ...")
                    time.sleep(30)
                    continue
                
                if resp.status_code == 400:
                    logger.warning(f"éŠ˜æŸ„ {code}: ç„¡åŠ¹ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆ400ã‚¨ãƒ©ãƒ¼ï¼‰")
                    return pd.DataFrame()
                
                resp.raise_for_status()
                data = resp.json()
                
                items = data.get("daily_quotes", [])
                if items:
                    results.extend(items)
                    logger.info(f"  å–å¾—ä»¶æ•°: {len(items)} (ç´¯è¨ˆ: {len(results)})")
                
                pagination_key = data.get("pagination_key")
                if not pagination_key:
                    break
                
                # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³é–“ã®å¾…æ©Ÿ
                time.sleep(0.3)
            
            if results:
                df = pd.DataFrame(results)
                logger.info(f"éŠ˜æŸ„ {code}: ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† ({len(df):,}ä»¶)")
                return df
            else:
                logger.warning(f"éŠ˜æŸ„ {code}: ãƒ‡ãƒ¼ã‚¿ãªã—")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"éŠ˜æŸ„ {code} å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return pd.DataFrame()
    
    def find_maximum_period(self, test_code: str = "72030", end_date: str = "2025-08-31") -> str:
        """
        1éŠ˜æŸ„ã§æœ€å¤§å–å¾—å¯èƒ½æœŸé–“ã‚’æœˆå˜ä½ã§ç‰¹å®š
        8.5å¹´ã‹ã‚‰1ãƒ¶æœˆãšã¤å»¶é•·
        """
        logger.info("=== æœˆå˜ä½ç²¾å¯†æœŸé–“ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
        logger.info(f"ãƒ†ã‚¹ãƒˆéŠ˜æŸ„: {test_code}")
        logger.info(f"çµ‚äº†æ—¥å›ºå®š: {end_date}")
        
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")
        
        # 8.5å¹´ã‹ã‚‰é–‹å§‹ã—ã€1ãƒ¶æœˆãšã¤å»¶é•·
        base_years = 8.5
        max_successful_period = None
        max_successful_start_date = None
        
        # 8.5å¹´ã‹ã‚‰æœ€å¤§12å¹´ã¾ã§æœˆå˜ä½ã§ãƒ†ã‚¹ãƒˆ
        for additional_months in range(0, 43):  # 8.5å¹´ + 3.5å¹´ = 12å¹´ã¾ã§
            total_months = base_years * 12 + additional_months
            total_years = total_months / 12
            
            # é–‹å§‹æ—¥ã‚’è¨ˆç®—
            start_dt = end_dt - timedelta(days=int(total_years * 365.25))
            start_date = start_dt.strftime("%Y-%m-%d")
            
            period_name = f"{total_years:.2f}å¹´"
            logger.info(f"\næœŸé–“ãƒ†ã‚¹ãƒˆ: {start_date} ï½ {end_date} ({period_name})")
            
            # ãƒ‡ãƒ¼ã‚¿å–å¾—è©¦è¡Œ
            df = self.get_daily_quotes_test(test_code, start_date, end_date)
            
            if not df.empty:
                logger.info(f"âœ… æˆåŠŸ: {period_name} ({len(df):,}ä»¶)")
                max_successful_period = period_name
                max_successful_start_date = start_date
                time.sleep(2)  # æˆåŠŸæ™‚ã¯çŸ­ã„å¾…æ©Ÿ
            else:
                logger.warning(f"âŒ å¤±æ•—: {period_name}")
                break  # å¤±æ•—ã—ãŸã‚‰ãã‚Œä»¥ä¸Šã¯è©¦ã•ãªã„
            
            # å¾…æ©Ÿæ™‚é–“
            time.sleep(3)
        
        logger.info(f"\n=== æœ€å¤§å–å¾—å¯èƒ½æœŸé–“ç‰¹å®šå®Œäº† ===")
        logger.info(f"éŠ˜æŸ„ {test_code} ã®æœ€å¤§æœŸé–“: {max_successful_period}")
        logger.info(f"æœŸé–“: {max_successful_start_date} ï½ {end_date}")
        
        return max_successful_start_date
    
    def get_all_working_stocks(self) -> List[str]:
        """
        ç¢ºå®Ÿã«å‹•ä½œã™ã‚‹å…¨38éŠ˜æŸ„ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
        """
        working_stocks = [
            "72030", "99840", "67580", "94320", "83060", "80350", "63670", "79740",
            "99830", "40630", "65010", "72670", "69020", "80010", "29140", "45190",
            "45430", "69540", "83090", "45020", "68610", "49010", "45680", "62730", 
            "69200", "78320", "84110", "88020", "45230", "61780", "60980", "40050", 
            "45070", "69710", "68570", "69050", "80310", "90200"
        ]
        
        logger.info(f"å…¨38éŠ˜æŸ„ãƒªã‚¹ãƒˆå–å¾—å®Œäº†")
        return working_stocks
    
    def fetch_maximum_period_data(self, start_date: str, end_date: str = "2025-08-31") -> pd.DataFrame:
        """
        æœ€é•·æœŸé–“ã§å…¨éŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        """
        logger.info("=== æœ€é•·æœŸé–“ã§ã®å…¨éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹ ===")
        logger.info(f"æœŸé–“: {start_date} ï½ {end_date}")
        
        # æœŸé–“ã®å¹´æ•°ã‚’è¨ˆç®—
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")
        total_days = (end_dt - start_dt).days
        total_years = total_days / 365.25
        
        logger.info(f"ãƒ‡ãƒ¼ã‚¿å–å¾—æœŸé–“: {total_years:.2f}å¹´ ({total_days}æ—¥)")
        
        # å…¨éŠ˜æŸ„å–å¾—
        stock_codes = self.get_all_working_stocks()
        all_stock_data = []
        failed_stocks = []
        
        # ä¸­é–“ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        intermediate_dir = Path("data/maximum_period_data")
        intermediate_dir.mkdir(parents=True, exist_ok=True)
        
        for idx, code in enumerate(stock_codes, 1):
            try:
                logger.info(f"éŠ˜æŸ„ {code} ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­... ({idx}/{len(stock_codes)}) - {idx/len(stock_codes)*100:.1f}%å®Œäº†")
                
                stock_data = self.get_daily_quotes_test(code, start_date, end_date)
                
                if not stock_data.empty:
                    all_stock_data.append(stock_data)
                    logger.info(f"  âœ… éŠ˜æŸ„ {code}: {len(stock_data):,}ä»¶å–å¾—æˆåŠŸ")
                    
                    # ä¸­é–“ä¿å­˜ï¼ˆ10éŠ˜æŸ„ã”ã¨ï¼‰
                    if idx % 10 == 0:
                        intermediate_df = pd.concat(all_stock_data, ignore_index=True)
                        intermediate_file = intermediate_dir / f"intermediate_max_{total_years:.2f}y_{idx}stocks_{datetime.now().strftime('%Y%m%d_%H%M')}.pkl"
                        intermediate_df.to_pickle(intermediate_file)
                        logger.info(f"  ğŸ’¾ ä¸­é–“ä¿å­˜: {intermediate_file} ({len(intermediate_df):,}ä»¶)")
                
                else:
                    failed_stocks.append(code)
                    logger.warning(f"  âŒ éŠ˜æŸ„ {code}: ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
                
                # éŠ˜æŸ„é–“ã®å¾…æ©Ÿï¼ˆé‡è¦ï¼‰
                wait_time = 4.0  # 4ç§’å¾…æ©Ÿ
                if idx % 5 == 0:
                    wait_time = 8.0  # 5éŠ˜æŸ„ã”ã¨ã«é•·ã„å¾…æ©Ÿ
                    logger.info(f"  â¸ï¸  APIåˆ¶é™å¯¾å¿œã§{wait_time:.1f}ç§’å¾…æ©Ÿ...")
                
                time.sleep(wait_time)
                
            except Exception as e:
                logger.error(f"  âŒ éŠ˜æŸ„ {code} ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
                failed_stocks.append(code)
                continue
        
        # ãƒ‡ãƒ¼ã‚¿çµ±åˆ
        if not all_stock_data:
            raise RuntimeError("å…¨ã¦ã®éŠ˜æŸ„ã§ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        logger.info("=== ãƒ‡ãƒ¼ã‚¿çµ±åˆä¸­ ===")
        combined_df = pd.concat(all_stock_data, ignore_index=True)
        
        logger.info("=== æœ€é•·æœŸé–“ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† ===")
        logger.info(f"æˆåŠŸéŠ˜æŸ„: {len(all_stock_data)}éŠ˜æŸ„")
        logger.info(f"å¤±æ•—éŠ˜æŸ„: {len(failed_stocks)}éŠ˜æŸ„")
        if failed_stocks:
            logger.info(f"å¤±æ•—éŠ˜æŸ„ãƒªã‚¹ãƒˆ: {failed_stocks}")
        logger.info(f"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(combined_df):,}ä»¶")
        logger.info(f"æœŸé–“: {combined_df['Date'].min()} ï½ {combined_df['Date'].max()}")
        
        # æœ€çµ‚ä¿å­˜
        output_dir = Path("data/maximum_period_data")
        output_dir.mkdir(parents=True, exist_ok=True)
        output_file = output_dir / f"maximum_period_{total_years:.2f}years_{len(all_stock_data)}stocks_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
        combined_df.to_pickle(output_file)
        
        logger.info(f"ğŸ‰ æœ€é•·æœŸé–“ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {output_file}")
        
        return combined_df


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        tester = MonthlyPrecisionTester()
        
        # Step 1: 1éŠ˜æŸ„ã§æœ€å¤§æœŸé–“ã‚’ç‰¹å®š
        logger.info("Step 1: 1éŠ˜æŸ„ã§ã®æœ€å¤§æœŸé–“ç‰¹å®š...")
        max_start_date = tester.find_maximum_period()
        
        if not max_start_date:
            logger.error("æœ€å¤§æœŸé–“ã®ç‰¹å®šã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        print(f"âœ… æœ€å¤§å–å¾—å¯èƒ½æœŸé–“ç‰¹å®šå®Œäº†")
        print(f"æœŸé–“: {max_start_date} ï½ 2025-08-31")
        
        # æœŸé–“ã®å¹´æ•°ã‚’è¨ˆç®—ã—ã¦è¡¨ç¤º
        start_dt = datetime.strptime(max_start_date, "%Y-%m-%d")
        end_dt = datetime.strptime("2025-08-31", "%Y-%m-%d")
        total_days = (end_dt - start_dt).days
        total_years = total_days / 365.25
        print(f"åˆè¨ˆæœŸé–“: {total_years:.2f}å¹´ ({total_days}æ—¥)")
        
        # Step 2: å…¨éŠ˜æŸ„ã§ãƒ‡ãƒ¼ã‚¿å–å¾—
        logger.info(f"\nStep 2: æœ€é•·æœŸé–“{total_years:.2f}å¹´ã§å…¨38éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿å–å¾—...")
        all_data = tester.fetch_maximum_period_data(max_start_date)
        
        print(f"\n=== æœ€é•·æœŸé–“ãƒ‡ãƒ¼ã‚¿å–å¾—çµæœ ===")
        print(f"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(all_data):,}ä»¶")
        print(f"éŠ˜æŸ„æ•°: {all_data['Code'].nunique()}éŠ˜æŸ„")
        print(f"æœŸé–“: {all_data['Date'].min()} ï½ {all_data['Date'].max()}")
        print(f"å®Ÿéš›ã®å¹´æ•°: {total_years:.2f}å¹´")
        
        print("ğŸ‰ æœ€é•·æœŸé–“ã§ã®å…¨éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†")
        
        return all_data
        
    except Exception as e:
        logger.error(f"æœˆå˜ä½ç²¾å¯†ãƒ†ã‚¹ãƒˆã«å¤±æ•—: {str(e)}")
        raise


if __name__ == "__main__":
    main()