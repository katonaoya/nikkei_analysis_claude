"""
9å¹´11ãƒ¶æœˆåˆ†ã®J-Quantsãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
APIã®10å¹´åˆ¶é™ã‚’å›é¿ã™ã‚‹ãŸã‚ã€9å¹´11ãƒ¶æœˆé–“ã§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
æœŸé–“: 2015å¹´2æœˆ1æ—¥ ã€œ 2025å¹´1æœˆ31æ—¥
"""

import os
import time
import json
from typing import Dict, List, Optional, Tuple
from datetime import datetime, date, timedelta
from pathlib import Path
import logging

import pandas as pd
import requests
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# APIè¨­å®š
JQUANTS_BASE_URL = "https://api.jquants.com/v1"


class NineYearsElevenMonthsFetcher:
    """9å¹´11ãƒ¶æœˆåˆ†ã®J-Quantsãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.mail_address = os.getenv("JQUANTS_MAIL_ADDRESS")
        self.password = os.getenv("JQUANTS_PASSWORD")
        self.id_token: Optional[str] = None
        self.token_expires_at: Optional[datetime] = None
        
        if not self.mail_address or not self.password:
            raise ValueError("JQuantsã®èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ (.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„)")
        
        logger.info("9å¹´11ãƒ¶æœˆåˆ†J-Quantsãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
    
    def _get_id_token(self) -> str:
        """IDãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—"""
        # ãƒˆãƒ¼ã‚¯ãƒ³ãŒæœ‰åŠ¹ãªå ´åˆã¯ãã®ã¾ã¾è¿”ã™
        if self.id_token and self.token_expires_at and datetime.now() < self.token_expires_at:
            return self.id_token
        
        logger.info("JQuantsèªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ä¸­...")
        time.sleep(3)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
        
        try:
            # ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            auth_payload = {
                "mailaddress": self.mail_address,
                "password": self.password
            }
            
            resp = requests.post(
                f"{JQUANTS_BASE_URL}/token/auth_user",
                data=json.dumps(auth_payload),
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            
            if resp.status_code == 429:
                logger.warning("ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã‚ˆã‚Š2åˆ†å¾…æ©Ÿ...")
                time.sleep(120)
                return self._get_id_token()
                
            resp.raise_for_status()
            refresh_token = resp.json().get("refreshToken")
            
            if not refresh_token:
                raise RuntimeError("ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            time.sleep(1)
            resp = requests.post(
                f"{JQUANTS_BASE_URL}/token/auth_refresh?refreshtoken={refresh_token}",
                timeout=30
            )
            
            if resp.status_code == 429:
                logger.warning("ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã‚ˆã‚Š2åˆ†å¾…æ©Ÿ...")
                time.sleep(120)
                return self._get_id_token()
                
            resp.raise_for_status()
            self.id_token = resp.json().get("idToken")
            
            if not self.id_token:
                raise RuntimeError("IDãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            # ãƒˆãƒ¼ã‚¯ãƒ³ã®æœ‰åŠ¹æœŸé™ã‚’è¨­å®š
            self.token_expires_at = datetime.now() + timedelta(hours=1)
            
            logger.info("èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—å®Œäº†")
            return self.id_token
            
        except Exception as e:
            logger.error(f"èªè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    def get_confirmed_working_stocks(self) -> List[str]:
        """
        å‰å›ç¢ºå®Ÿã«å‹•ä½œã—ãŸéŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’è¿”ã™
        """
        # å‰å›æˆåŠŸã—ãŸ38éŠ˜æŸ„ï¼ˆç¢ºå®Ÿã«å‹•ä½œã™ã‚‹ï¼‰
        working_stocks = [
            "72030", "99840", "67580", "94320", "83060", "80350", "63670", "79740",
            "99830", "40630", "65010", "72670", "69020", "80010", "29140", "45190",
            "45430", "69540", "83090", "45020", "68610", "49010", "45680", "62730", 
            "69200", "78320", "84110", "88020", "45230", "61780", "60980", "40050", 
            "45070", "69710", "68570", "69050", "80310", "90200"
        ]
        
        logger.info(f"ç¢ºå®Ÿå‹•ä½œéŠ˜æŸ„ãƒªã‚¹ãƒˆ: {len(working_stocks)}éŠ˜æŸ„")
        return working_stocks
    
    def get_daily_quotes_nine_years_eleven_months(
        self, 
        code: str,
        from_date: str = "2015-02-01",  # 9å¹´11ãƒ¶æœˆå‰
        to_date: str = "2025-01-31"     # ã¡ã‚‡ã†ã©9å¹´11ãƒ¶æœˆå¾Œ
    ) -> pd.DataFrame:
        """
        9å¹´11ãƒ¶æœˆåˆ†ã®æ—¥æ¬¡æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—
        """
        try:
            headers = {"Authorization": f"Bearer {self._get_id_token()}"}
            results: List[Dict] = []
            pagination_key: Optional[str] = None
            
            logger.info(f"éŠ˜æŸ„ {code}: 9å¹´11ãƒ¶æœˆåˆ†ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹")
            logger.info(f"  æœŸé–“: {from_date} ï½ {to_date}")
            
            while True:
                params = {
                    "code": code,
                    "from": from_date,
                    "to": to_date
                }
                if pagination_key:
                    params["pagination_key"] = pagination_key
                
                resp = requests.get(
                    f"{JQUANTS_BASE_URL}/prices/daily_quotes",
                    headers=headers,
                    params=params,
                    timeout=120
                )
                
                if resp.status_code == 429:
                    logger.warning(f"éŠ˜æŸ„ {code}: ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã€30ç§’å¾…æ©Ÿ...")
                    time.sleep(30)
                    continue
                
                if resp.status_code == 400:
                    logger.warning(f"éŠ˜æŸ„ {code}: ç„¡åŠ¹ãªã‚³ãƒ¼ãƒ‰ï¼ˆ400ã‚¨ãƒ©ãƒ¼ï¼‰")
                    return pd.DataFrame()
                
                resp.raise_for_status()
                data = resp.json()
                
                items = data.get("daily_quotes", [])
                if items:
                    results.extend(items)
                    logger.info(f"  å–å¾—ä»¶æ•°: {len(items)} (ç´¯è¨ˆ: {len(results)})")
                
                pagination_key = data.get("pagination_key")
                if not pagination_key:
                    break
                
                # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³é–“ã®å¾…æ©Ÿ
                time.sleep(0.3)
            
            if results:
                df = pd.DataFrame(results)
                logger.info(f"éŠ˜æŸ„ {code}: 9å¹´11ãƒ¶æœˆåˆ†ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† ({len(df):,}ä»¶)")
                return df
            else:
                logger.warning(f"éŠ˜æŸ„ {code}: ãƒ‡ãƒ¼ã‚¿ãªã—")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"éŠ˜æŸ„ {code} å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return pd.DataFrame()
    
    def fetch_nine_years_eleven_months_data(self) -> pd.DataFrame:
        """
        9å¹´11ãƒ¶æœˆåˆ†ã®å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        """
        logger.info("=== 9å¹´11ãƒ¶æœˆåˆ†ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹ ===")
        logger.info("æœŸé–“: 2015å¹´2æœˆ1æ—¥ ï½ 2025å¹´1æœˆ31æ—¥ (9å¹´11ãƒ¶æœˆ)")
        
        # Step 1: ç¢ºå®Ÿã«å‹•ä½œã™ã‚‹éŠ˜æŸ„ãƒªã‚¹ãƒˆå–å¾—
        stock_codes = self.get_confirmed_working_stocks()
        
        # Step 2: ãƒ‡ãƒ¼ã‚¿å–å¾—
        all_stock_data = []
        failed_stocks = []
        
        # ä¸­é–“ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        intermediate_dir = Path("data/nine_years_eleven_months_data")
        intermediate_dir.mkdir(parents=True, exist_ok=True)
        
        for idx, code in enumerate(stock_codes, 1):
            try:
                logger.info(f"éŠ˜æŸ„ {code} ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­... ({idx}/{len(stock_codes)}) - {idx/len(stock_codes)*100:.1f}%å®Œäº†")
                
                stock_data = self.get_daily_quotes_nine_years_eleven_months(code)
                
                if not stock_data.empty:
                    all_stock_data.append(stock_data)
                    logger.info(f"  âœ… éŠ˜æŸ„ {code}: {len(stock_data):,}ä»¶å–å¾—æˆåŠŸ")
                    
                    # ä¸­é–“ä¿å­˜ï¼ˆ10éŠ˜æŸ„ã”ã¨ï¼‰
                    if idx % 10 == 0:
                        intermediate_df = pd.concat(all_stock_data, ignore_index=True)
                        intermediate_file = intermediate_dir / f"intermediate_9y11m_{idx}stocks_{datetime.now().strftime('%Y%m%d_%H%M')}.pkl"
                        intermediate_df.to_pickle(intermediate_file)
                        logger.info(f"  ğŸ’¾ ä¸­é–“ä¿å­˜: {intermediate_file} ({len(intermediate_df):,}ä»¶)")
                
                else:
                    failed_stocks.append(code)
                    logger.warning(f"  âŒ éŠ˜æŸ„ {code}: ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
                
                # éŠ˜æŸ„é–“ã®å¾…æ©Ÿï¼ˆé‡è¦ï¼‰
                wait_time = 4.0  # 4ç§’å¾…æ©Ÿ
                if idx % 5 == 0:
                    wait_time = 8.0  # 5éŠ˜æŸ„ã”ã¨ã«é•·ã„å¾…æ©Ÿ
                    logger.info(f"  â¸ï¸  APIåˆ¶é™å¯¾å¿œã§{wait_time:.1f}ç§’å¾…æ©Ÿ...")
                
                time.sleep(wait_time)
                
            except Exception as e:
                logger.error(f"  âŒ éŠ˜æŸ„ {code} ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
                failed_stocks.append(code)
                continue
        
        # Step 3: ãƒ‡ãƒ¼ã‚¿çµ±åˆ
        if not all_stock_data:
            raise RuntimeError("å…¨ã¦ã®éŠ˜æŸ„ã§ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        logger.info("=== ãƒ‡ãƒ¼ã‚¿çµ±åˆä¸­ ===")
        combined_df = pd.concat(all_stock_data, ignore_index=True)
        
        logger.info("=== 9å¹´11ãƒ¶æœˆåˆ†ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† ===")
        logger.info(f"æˆåŠŸéŠ˜æŸ„: {len(all_stock_data)}éŠ˜æŸ„")
        logger.info(f"å¤±æ•—éŠ˜æŸ„: {len(failed_stocks)}éŠ˜æŸ„")
        if failed_stocks:
            logger.info(f"å¤±æ•—éŠ˜æŸ„ãƒªã‚¹ãƒˆ: {failed_stocks}")
        logger.info(f"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(combined_df):,}ä»¶")
        logger.info(f"æœŸé–“: {combined_df['Date'].min()} ï½ {combined_df['Date'].max()}")
        
        # Step 4: ãƒ‡ãƒ¼ã‚¿å‡¦ç†
        processed_df = self._process_data(combined_df)
        
        # Step 5: ä¿å­˜
        output_dir = Path("data/nine_years_eleven_months_data")
        output_dir.mkdir(parents=True, exist_ok=True)
        output_file = output_dir / f"nine_years_eleven_months_{len(all_stock_data)}stocks_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
        processed_df.to_pickle(output_file)
        
        logger.info(f"ğŸ‰ 9å¹´11ãƒ¶æœˆåˆ†ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {output_file}")
        
        return processed_df
    
    def _process_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿å‡¦ç†"""
        logger.info("9å¹´11ãƒ¶æœˆåˆ†ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–‹å§‹...")
        
        # åˆ—åæ¨™æº–åŒ–
        column_mapping = {
            'Date': 'date',
            'Code': 'symbol', 
            'Close': 'close_price',
            'Open': 'open_price',
            'High': 'high_price',
            'Low': 'low_price',
            'Volume': 'volume',
            'AdjustmentFactor': 'adjustment_factor',
            'AdjustmentOpen': 'adj_open',
            'AdjustmentHigh': 'adj_high', 
            'AdjustmentLow': 'adj_low',
            'AdjustmentClose': 'adj_close',
            'AdjustmentVolume': 'adj_volume'
        }
        
        for old_col, new_col in column_mapping.items():
            if old_col in df.columns:
                df[new_col] = df[old_col]
        
        # ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›
        df['date'] = pd.to_datetime(df['date'])
        df['close_price'] = pd.to_numeric(df['close_price'], errors='coerce')
        if 'volume' in df.columns:
            df['volume'] = pd.to_numeric(df['volume'], errors='coerce')
        
        # é‡è¤‡é™¤å»ãƒ»ã‚½ãƒ¼ãƒˆ
        df = df.drop_duplicates(subset=['date', 'symbol'])
        df = df.sort_values(['symbol', 'date']).reset_index(drop=True)
        
        # ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—
        logger.info("ãƒªã‚¿ãƒ¼ãƒ³ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨ˆç®—ä¸­...")
        df['daily_return'] = df.groupby('symbol')['close_price'].pct_change(fill_method=None)
        df['next_day_return'] = df.groupby('symbol')['close_price'].pct_change(fill_method=None).shift(-1)
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆ
        df['target'] = (df['next_day_return'] >= 0.01).astype(int)
        
        # ä¸å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã‚’é™¤å»
        df = df.dropna(subset=['close_price', 'next_day_return', 'target'])
        
        logger.info(f"9å¹´11ãƒ¶æœˆåˆ†ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†: {len(df):,}ãƒ¬ã‚³ãƒ¼ãƒ‰")
        logger.info(f"å¯¾è±¡éŠ˜æŸ„æ•°: {df['symbol'].nunique()}éŠ˜æŸ„")
        logger.info(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒ: {df['target'].mean():.1%} (ä¸Šæ˜‡)")
        logger.info(f"æœŸé–“: {df['date'].min().date()} ï½ {df['date'].max().date()}")
        
        # ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®è©³ç´°ç¢ºèª
        period_start = df['date'].min()
        period_end = df['date'].max()
        total_days = (period_end - period_start).days
        total_years = total_days / 365.25
        
        logger.info(f"å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿æœŸé–“: {total_days}æ—¥ ({total_years:.2f}å¹´)")
        logger.info(f"æœŸå¾…æœŸé–“: 9å¹´11ãƒ¶æœˆ (ç´„3,621æ—¥)")
        
        return df


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        fetcher = NineYearsElevenMonthsFetcher()
        
        # 9å¹´11ãƒ¶æœˆåˆ†ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
        nine_years_eleven_months_data = fetcher.fetch_nine_years_eleven_months_data()
        
        print("\n=== 9å¹´11ãƒ¶æœˆåˆ†J-Quantsãƒ‡ãƒ¼ã‚¿å–å¾—çµæœ ===")
        print(f"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(nine_years_eleven_months_data):,}ä»¶")
        print(f"éŠ˜æŸ„æ•°: {nine_years_eleven_months_data['symbol'].nunique()}éŠ˜æŸ„") 
        print(f"æœŸé–“: {nine_years_eleven_months_data['date'].min().date()} ï½ {nine_years_eleven_months_data['date'].max().date()}")
        print(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒ: {nine_years_eleven_months_data['target'].mean():.1%}")
        
        # æœŸé–“ç¢ºèª
        period_start = nine_years_eleven_months_data['date'].min()
        period_end = nine_years_eleven_months_data['date'].max()
        total_days = (period_end - period_start).days
        total_years = total_days / 365.25
        print(f"å®Ÿéš›ã®æœŸé–“: {total_days}æ—¥ ({total_years:.2f}å¹´)")
        
        print("âœ… 9å¹´11ãƒ¶æœˆåˆ†ã®100%å®Ÿãƒ‡ãƒ¼ã‚¿ã§å–å¾—å®Œäº†")
        
        return nine_years_eleven_months_data
        
    except Exception as e:
        logger.error(f"9å¹´11ãƒ¶æœˆåˆ†ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—: {str(e)}")
        print("âŒ 9å¹´11ãƒ¶æœˆåˆ†ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
        raise


if __name__ == "__main__":
    main()