#!/usr/bin/env python3
"""
Precision 60%é”æˆã‚’ç›®æŒ‡ã™ - ä¸Šä½5éŠ˜æŸ„ã®ã¿ã«çµã£ãŸé«˜ç²¾åº¦äºˆæ¸¬
"""

import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
import yaml
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import precision_score, accuracy_score
import lightgbm as lgb
from loguru import logger
import warnings
warnings.filterwarnings('ignore')

class Top5PrecisionOptimizer:
    """ä¸Šä½5éŠ˜æŸ„ã«çµã£ãŸé«˜ç²¾åº¦äºˆæ¸¬ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.best_precision = 0
        self.best_config = None
        
    def load_and_prepare_data(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†"""
        logger.info("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
        df = pd.read_parquet('data/processed/integrated_with_external.parquet')
        
        # ã‚«ãƒ©ãƒ åã®èª¿æ•´
        if 'date' in df.columns:
            df['Date'] = pd.to_datetime(df['date'])
        if 'code' in df.columns:
            df['Stock'] = df['code']
        
        # åŸºæœ¬çš„ãªç‰¹å¾´é‡ã‚’ç”Ÿæˆ
        logger.info("ğŸ”§ ç‰¹å¾´é‡ç”Ÿæˆä¸­...")
        features = []
        
        for stock, stock_df in df.groupby('Stock'):
            stock_df = stock_df.sort_values('Date')
            
            # ä¾¡æ ¼å¤‰åŒ–ç‡
            stock_df['Return'] = stock_df['close'].pct_change()
            stock_df['Target'] = (stock_df['close'].shift(-1) > stock_df['close']).astype(int)
            
            # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ï¼ˆé‡è¦ãªã‚‚ã®ã®ã¿ï¼‰
            # RSI
            delta = stock_df['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss.replace(0, 1)
            stock_df['RSI'] = 100 - (100 / (1 + rs))
            
            # ç§»å‹•å¹³å‡ã‹ã‚‰ã®ä¹–é›¢
            for period in [5, 20]:
                stock_df[f'MA{period}'] = stock_df['close'].rolling(period).mean()
                stock_df[f'Price_vs_MA{period}'] = (stock_df['close'] - stock_df[f'MA{period}']) / stock_df[f'MA{period}']
            
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            stock_df['Volatility_20'] = stock_df['Return'].rolling(20).std()
            
            # å‡ºæ¥é«˜æ¯”ç‡
            stock_df['Volume_MA20'] = stock_df['volume'].rolling(20).mean()
            stock_df['Volume_Ratio'] = stock_df['volume'] / stock_df['Volume_MA20'].replace(0, 1)
            
            # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ 
            stock_df['Momentum_5'] = stock_df['close'].pct_change(5)
            stock_df['Momentum_20'] = stock_df['close'].pct_change(20)
            
            # é«˜å€¤å®‰å€¤ã‹ã‚‰ã®ä½ç½®
            stock_df['High_20'] = stock_df['high'].rolling(20).max()
            stock_df['Low_20'] = stock_df['low'].rolling(20).min()
            stock_df['Price_Position'] = (stock_df['close'] - stock_df['Low_20']) / (stock_df['High_20'] - stock_df['Low_20'])
            
            features.append(stock_df)
        
        df = pd.concat(features, ignore_index=True)
        
        # ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡
        feature_cols = [
            'RSI', 'Price_vs_MA5', 'Price_vs_MA20', 'Volatility_20',
            'Volume_Ratio', 'Momentum_5', 'Momentum_20', 'Price_Position'
        ]
        
        return df, feature_cols
    
    def test_top5_precision(self, df, feature_cols):
        """ä¸Šä½5éŠ˜æŸ„ã®ã¿ã§Precisionæ¸¬å®š"""
        logger.info("ğŸ¯ ä¸Šä½5éŠ˜æŸ„ã®ç²¾åº¦ãƒ†ã‚¹ãƒˆé–‹å§‹...")
        
        # ãƒ†ã‚¹ãƒˆæœŸé–“ï¼ˆç›´è¿‘30æ—¥ï¼‰
        df = df.sort_values('Date')
        unique_dates = sorted(df['Date'].unique())
        test_dates = unique_dates[-30:]
        
        # è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã¨é–¾å€¤ã‚’ãƒ†ã‚¹ãƒˆ
        models = {
            'lgb': lgb.LGBMClassifier(
                n_estimators=100, max_depth=3, min_child_samples=20,
                subsample=0.8, colsample_bytree=0.8, random_state=42
            ),
            'rf': RandomForestClassifier(
                n_estimators=200, max_depth=5, min_samples_split=50,
                min_samples_leaf=20, random_state=42, n_jobs=-1
            ),
            'gb': GradientBoostingClassifier(
                n_estimators=100, max_depth=3, min_samples_split=50,
                min_samples_leaf=20, learning_rate=0.05, random_state=42
            )
        }
        
        results = []
        
        for model_name, model in models.items():
            logger.info(f"\nãƒ¢ãƒ‡ãƒ«: {model_name}")
            
            # ç•°ãªã‚‹é¸æŠæˆ¦ç•¥ã‚’ãƒ†ã‚¹ãƒˆ
            for strategy in ['top5_any', 'top5_threshold', 'top3_high_conf']:
                
                daily_precisions = []
                daily_counts = []
                all_predictions = []
                all_actuals = []
                
                for test_date in test_dates:
                    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
                    train_data = df[df['Date'] < test_date]
                    test_data = df[df['Date'] == test_date]
                    
                    if len(train_data) < 5000 or len(test_data) < 20:
                        continue
                    
                    # ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ‡ãƒ¼ã‚¿
                    train_clean = train_data.dropna(subset=['Target'] + feature_cols)
                    test_clean = test_data.dropna(subset=['Target'] + feature_cols)
                    
                    if len(train_clean) < 1000 or len(test_clean) < 10:
                        continue
                    
                    X_train = train_clean[feature_cols]
                    y_train = train_clean['Target']
                    X_test = test_clean[feature_cols]
                    y_test = test_clean['Target']
                    
                    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
                    scaler = StandardScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)
                    
                    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
                    try:
                        model.fit(X_train_scaled, y_train)
                        
                        # äºˆæ¸¬ç¢ºç‡
                        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
                        test_clean['pred_proba'] = y_pred_proba
                        
                        # æˆ¦ç•¥åˆ¥ã®éŠ˜æŸ„é¸æŠ
                        if strategy == 'top5_any':
                            # ä¸Šä½5éŠ˜æŸ„ï¼ˆé–¾å€¤ãªã—ï¼‰
                            selected = test_clean.nlargest(5, 'pred_proba')
                            
                        elif strategy == 'top5_threshold':
                            # ä¸Šä½5éŠ˜æŸ„ï¼ˆ60%ä»¥ä¸Šã®ç¢ºç‡ã®ã¿ï¼‰
                            high_conf = test_clean[test_clean['pred_proba'] >= 0.6]
                            if len(high_conf) > 0:
                                selected = high_conf.nlargest(min(5, len(high_conf)), 'pred_proba')
                            else:
                                continue
                                
                        elif strategy == 'top3_high_conf':
                            # ä¸Šä½3éŠ˜æŸ„ï¼ˆ65%ä»¥ä¸Šã®ç¢ºç‡ã®ã¿ï¼‰
                            high_conf = test_clean[test_clean['pred_proba'] >= 0.65]
                            if len(high_conf) > 0:
                                selected = high_conf.nlargest(min(3, len(high_conf)), 'pred_proba')
                            else:
                                continue
                        
                        if len(selected) > 0:
                            # Precisionè¨ˆç®—
                            predictions = (selected['pred_proba'] >= 0.5).astype(int)
                            actuals = selected['Target'].values
                            
                            precision = precision_score(actuals, predictions, zero_division=0)
                            
                            if precision > 0:
                                daily_precisions.append(precision)
                                daily_counts.append(len(selected))
                                all_predictions.extend(predictions)
                                all_actuals.extend(actuals)
                                
                    except Exception as e:
                        continue
                
                # çµæœé›†è¨ˆ
                if len(daily_precisions) >= 10:
                    avg_precision = np.mean(daily_precisions)
                    avg_count = np.mean(daily_counts)
                    overall_precision = precision_score(all_actuals, all_predictions, zero_division=0)
                    
                    result = {
                        'model': model_name,
                        'strategy': strategy,
                        'avg_daily_precision': avg_precision,
                        'overall_precision': overall_precision,
                        'avg_picks_per_day': avg_count,
                        'test_days': len(daily_precisions),
                        'total_correct': sum([a for a, p in zip(all_actuals, all_predictions) if a == 1 and p == 1]),
                        'total_predicted': sum(all_predictions)
                    }
                    
                    results.append(result)
                    
                    if overall_precision > self.best_precision:
                        self.best_precision = overall_precision
                        self.best_config = result
                        logger.success(f"  ğŸ¯ æ–°è¨˜éŒ²! {strategy}: Precision {overall_precision:.2%} (1æ—¥å¹³å‡{avg_count:.1f}éŠ˜æŸ„)")
        
        return results
    
    def advanced_filtering(self, df, feature_cols):
        """é«˜åº¦ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Š"""
        logger.info("ğŸ”¬ é«˜åº¦ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æˆ¦ç•¥ã®ãƒ†ã‚¹ãƒˆ...")
        
        # æœ€é©ãªæ¡ä»¶ã®çµ„ã¿åˆã‚ã›ã‚’æ¢ç´¢
        df = df.sort_values('Date')
        unique_dates = sorted(df['Date'].unique())
        test_dates = unique_dates[-30:]
        
        # LightGBMãƒ¢ãƒ‡ãƒ«ï¼ˆæœ€ã‚‚è‰¯å¥½ãªçµæœã‚’ç¤ºã—ã‚„ã™ã„ï¼‰
        model = lgb.LGBMClassifier(
            n_estimators=150, max_depth=4, min_child_samples=30,
            subsample=0.9, colsample_bytree=0.9, random_state=42,
            learning_rate=0.02
        )
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ã®çµ„ã¿åˆã‚ã›
        filters = [
            {'name': 'high_volume', 'condition': lambda df: df['Volume_Ratio'] > 1.2},
            {'name': 'low_rsi', 'condition': lambda df: (df['RSI'] < 40) | (df['RSI'] > 60)},
            {'name': 'strong_momentum', 'condition': lambda df: df['Momentum_5'] > 0.02},
            {'name': 'oversold', 'condition': lambda df: df['Price_Position'] < 0.3},
            {'name': 'breakout', 'condition': lambda df: df['Price_Position'] > 0.8}
        ]
        
        best_filter_result = None
        best_filter_precision = 0
        
        for filter_config in filters:
            daily_results = []
            
            for test_date in test_dates:
                train_data = df[df['Date'] < test_date]
                test_data = df[df['Date'] == test_date]
                
                if len(train_data) < 5000 or len(test_data) < 20:
                    continue
                
                # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
                test_filtered = test_data[filter_config['condition'](test_data)]
                
                if len(test_filtered) < 5:
                    continue
                
                train_clean = train_data.dropna(subset=['Target'] + feature_cols)
                test_clean = test_filtered.dropna(subset=['Target'] + feature_cols)
                
                if len(train_clean) < 1000 or len(test_clean) < 3:
                    continue
                
                X_train = train_clean[feature_cols]
                y_train = train_clean['Target']
                X_test = test_clean[feature_cols]
                
                # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨äºˆæ¸¬
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)
                
                model.fit(X_train_scaled, y_train)
                y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
                
                test_clean['pred_proba'] = y_pred_proba
                
                # ä¸Šä½5éŠ˜æŸ„ã‚’é¸æŠ
                top5 = test_clean.nlargest(min(5, len(test_clean)), 'pred_proba')
                
                if len(top5) > 0 and top5['pred_proba'].iloc[0] >= 0.55:
                    predictions = (top5['pred_proba'] >= 0.5).astype(int)
                    actuals = top5['Target'].values
                    
                    if sum(predictions) > 0:
                        precision = sum([a for a, p in zip(actuals, predictions) if a == 1 and p == 1]) / sum(predictions)
                        daily_results.append({
                            'precision': precision,
                            'count': len(top5),
                            'correct': sum([a for a, p in zip(actuals, predictions) if a == 1 and p == 1])
                        })
            
            if len(daily_results) >= 5:
                avg_precision = np.mean([r['precision'] for r in daily_results])
                total_correct = sum([r['correct'] for r in daily_results])
                total_predicted = sum([r['count'] for r in daily_results])
                
                if total_predicted > 0:
                    overall_precision = total_correct / total_predicted
                    
                    if overall_precision > best_filter_precision:
                        best_filter_precision = overall_precision
                        best_filter_result = {
                            'filter': filter_config['name'],
                            'precision': overall_precision,
                            'avg_daily_precision': avg_precision,
                            'test_days': len(daily_results)
                        }
                        
                        logger.info(f"  ãƒ•ã‚£ãƒ«ã‚¿ {filter_config['name']}: Precision {overall_precision:.2%}")
        
        return best_filter_result
    
    def print_final_results(self, results, filter_result):
        """æœ€çµ‚çµæœã®è¡¨ç¤º"""
        print("\n" + "="*80)
        print("ğŸ¯ Precision 60%é”æˆãƒãƒ£ãƒ¬ãƒ³ã‚¸ - æœ€çµ‚çµæœ")
        print("="*80)
        
        # çµæœã‚’Precisionã§ã‚½ãƒ¼ãƒˆ
        results_sorted = sorted(results, key=lambda x: x['overall_precision'], reverse=True)
        
        print("\nğŸ“Š ã€ä¸Šä½5éŠ˜æŸ„æˆ¦ç•¥ã®çµæœã€‘")
        print(f"{'é †ä½':<4} {'ãƒ¢ãƒ‡ãƒ«':<10} {'æˆ¦ç•¥':<20} {'Precision':<12} {'1æ—¥å¹³å‡':<10}")
        print("-"*70)
        
        for i, result in enumerate(results_sorted[:10], 1):
            print(f"{i:<4} {result['model']:<10} {result['strategy']:<20} "
                  f"{result['overall_precision']:<12.2%} {result['avg_picks_per_day']:<10.1f}")
        
        if self.best_config:
            print("\nğŸ† ã€æœ€é«˜æˆç¸¾ã€‘")
            print(f"  ãƒ¢ãƒ‡ãƒ«: {self.best_config['model']}")
            print(f"  æˆ¦ç•¥: {self.best_config['strategy']}")
            print(f"  é”æˆPrecision: {self.best_config['overall_precision']:.2%}")
            print(f"  1æ—¥å¹³å‡é¸æŠæ•°: {self.best_config['avg_picks_per_day']:.1f}éŠ˜æŸ„")
            print(f"  çš„ä¸­æ•°/äºˆæ¸¬æ•°: {self.best_config['total_correct']}/{self.best_config['total_predicted']}")
            
            if self.best_config['overall_precision'] >= 0.6:
                print("\nâœ… ç›®æ¨™ã®Precision 60%ã‚’é”æˆã—ã¾ã—ãŸï¼")
                
                # æˆåŠŸè¨­å®šã‚’ä¿å­˜
                success_config = {
                    'achieved': True,
                    'precision': float(self.best_config['overall_precision']),
                    'model': self.best_config['model'],
                    'strategy': self.best_config['strategy'],
                    'timestamp': datetime.now().isoformat()
                }
                
                with open('precision_60_achieved.yaml', 'w') as f:
                    yaml.dump(success_config, f)
                
                print("ğŸ’¾ æˆåŠŸè¨­å®šã‚’ precision_60_achieved.yaml ã«ä¿å­˜ã—ã¾ã—ãŸ")
            else:
                print(f"\nâš ï¸ ç›®æ¨™ã¾ã§ã‚ã¨ {0.6 - self.best_config['overall_precision']:.2%}")
        
        if filter_result:
            print(f"\nğŸ”¬ ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æˆ¦ç•¥ã€‘")
            print(f"  æœ€è‰¯ãƒ•ã‚£ãƒ«ã‚¿: {filter_result['filter']}")
            print(f"  é”æˆPrecision: {filter_result['precision']:.2%}")
            
            if filter_result['precision'] >= 0.6:
                print("  âœ… ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã§60%é”æˆï¼")
        
        print("\n" + "="*80)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    optimizer = Top5PrecisionOptimizer()
    
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    df, feature_cols = optimizer.load_and_prepare_data()
    
    # ä¸Šä½5éŠ˜æŸ„æˆ¦ç•¥ã®ãƒ†ã‚¹ãƒˆ
    results = optimizer.test_top5_precision(df, feature_cols)
    
    # é«˜åº¦ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    filter_result = optimizer.advanced_filtering(df, feature_cols)
    
    # çµæœè¡¨ç¤º
    optimizer.print_final_results(results, filter_result)

if __name__ == "__main__":
    main()