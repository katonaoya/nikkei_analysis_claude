#!/usr/bin/env python3
"""
Yahoo Finance ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
æ—¥çµŒå¹³å‡ã€TOPIXã€ãƒ‰ãƒ«å††ã€VIXç­‰ã®å¸‚å ´æŒ‡æ¨™å–å¾—
"""

import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
from typing import Dict, List
from loguru import logger
import warnings
warnings.filterwarnings('ignore')

class YahooMarketData:
    """Yahoo Finance ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        # ãƒãƒ¼ã‚±ãƒƒãƒˆæŒ‡æ¨™ã®ã‚·ãƒ³ãƒœãƒ«å®šç¾©
        self.market_symbols = {
            'nikkei225': '^N225',      # æ—¥çµŒå¹³å‡æ ªä¾¡
            'topix': '^TOPX',          # TOPIX
            'usdjpy': 'USDJPY=X',      # ãƒ‰ãƒ«å††
            'vix': '^VIX',             # VIXææ€–æŒ‡æ•°
            'us_10y': '^TNX',          # ç±³10å¹´å‚µåˆ©å›ã‚Š
            'jpy_index': 'JPY=X',      # å††ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            'dow': '^DJI',             # ãƒ€ã‚¦å¹³å‡
            'sp500': '^GSPC',          # S&P500
            'nasdaq': '^IXIC'          # NASDAQ
        }
    
    def get_market_data(self, symbol: str, period: str = "2y") -> pd.DataFrame:
        """å˜ä¸€ãƒãƒ¼ã‚±ãƒƒãƒˆæŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            ticker = yf.Ticker(symbol)
            df = ticker.history(period=period)
            
            if not df.empty:
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦Dateã‚«ãƒ©ãƒ ã«
                df = df.reset_index()
                df['Symbol'] = symbol
                logger.debug(f"âœ… {symbol}: {len(df)}æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿å–å¾—")
                return df
            else:
                logger.warning(f"âš ï¸ {symbol}: ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"âŒ {symbol}ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {e}")
            return pd.DataFrame()
    
    def get_all_market_data(self, period: str = "2y") -> Dict[str, pd.DataFrame]:
        """å…¨ãƒãƒ¼ã‚±ãƒƒãƒˆæŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å–å¾—"""
        logger.info(f"ğŸ”„ ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å–å¾—é–‹å§‹ (æœŸé–“: {period})")
        
        market_data = {}
        
        for name, symbol in self.market_symbols.items():
            logger.info(f"  å–å¾—ä¸­: {name} ({symbol})")
            df = self.get_market_data(symbol, period)
            
            if not df.empty:
                market_data[name] = df
                logger.info(f"    âœ… {name}: {len(df)}æ—¥åˆ†")
            else:
                logger.warning(f"    âŒ {name}: å–å¾—å¤±æ•—")
        
        logger.success(f"âœ… ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(market_data)}/{len(self.market_symbols)}æŒ‡æ¨™")
        return market_data
    
    def calculate_market_features(self, market_data: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        """ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´é‡ç”Ÿæˆ"""
        logger.info("ğŸ”§ ãƒãƒ¼ã‚±ãƒƒãƒˆç‰¹å¾´é‡ç”Ÿæˆä¸­...")
        
        if not market_data:
            logger.warning("ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            return pd.DataFrame()
        
        # å…¨ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ç¯„å›²ã‚’çµ±ä¸€
        date_ranges = []
        for name, df in market_data.items():
            if not df.empty:
                date_ranges.append(df['Date'])
        
        if not date_ranges:
            return pd.DataFrame()
        
        # å…±é€šæ—¥ä»˜ç¯„å›²
        all_dates = pd.concat(date_ranges).drop_duplicates().sort_values()
        
        # ç‰¹å¾´é‡DataFrameåˆæœŸåŒ–
        features_df = pd.DataFrame({'Date': all_dates})
        
        # å„æŒ‡æ¨™ã®ç‰¹å¾´é‡è¨ˆç®—
        for name, df in market_data.items():
            if df.empty:
                continue
                
            logger.debug(f"  å‡¦ç†ä¸­: {name}")
            
            # æ—¥ä»˜ã§ãƒãƒ¼ã‚¸ï¼ˆæ—¥ä»˜å‹ã‚’çµ±ä¸€ï¼‰
            df = df[['Date', 'Close', 'Volume']].copy()
            df.columns = ['Date', f'{name}_close', f'{name}_volume']
            
            # æ—¥ä»˜å‹ã‚’çµ±ä¸€
            df['Date'] = pd.to_datetime(df['Date']).dt.date
            
            features_df = features_df.merge(df, on='Date', how='left')
            
            # å‰æ–¹è£œå®Œã§æ¬ æå€¤åŸ‹ã‚
            features_df[f'{name}_close'] = features_df[f'{name}_close'].fillna(method='ffill')
            features_df[f'{name}_volume'] = features_df[f'{name}_volume'].fillna(method='ffill')
            
            # æŠ€è¡“æŒ‡æ¨™è¨ˆç®—
            close_col = f'{name}_close'
            
            if close_col in features_df.columns:
                # 1. ãƒªã‚¿ãƒ¼ãƒ³
                features_df[f'{name}_return_1d'] = features_df[close_col].pct_change(1)
                features_df[f'{name}_return_5d'] = features_df[close_col].pct_change(5)
                features_df[f'{name}_return_20d'] = features_df[close_col].pct_change(20)
                
                # 2. ç§»å‹•å¹³å‡
                features_df[f'{name}_ma5'] = features_df[close_col].rolling(5).mean()
                features_df[f'{name}_ma20'] = features_df[close_col].rolling(20).mean()
                features_df[f'{name}_ma60'] = features_df[close_col].rolling(60).mean()
                
                # 3. ç§»å‹•å¹³å‡ä¹–é›¢ç‡
                features_df[f'{name}_ma5_ratio'] = (features_df[close_col] - features_df[f'{name}_ma5']) / features_df[f'{name}_ma5']
                features_df[f'{name}_ma20_ratio'] = (features_df[close_col] - features_df[f'{name}_ma20']) / features_df[f'{name}_ma20']
                
                # 4. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                features_df[f'{name}_volatility_5d'] = features_df[f'{name}_return_1d'].rolling(5).std()
                features_df[f'{name}_volatility_20d'] = features_df[f'{name}_return_1d'].rolling(20).std()
                
                # 5. RSIé¢¨æŒ‡æ¨™
                delta = features_df[close_col].diff()
                gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
                loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
                rs = gain / loss.replace(0, 1)
                features_df[f'{name}_rsi'] = 100 - (100 / (1 + rs))
                
                # 6. ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ï¼ˆç§»å‹•å¹³å‡ã®å‚¾ãï¼‰
                features_df[f'{name}_ma5_slope'] = features_df[f'{name}_ma5'].pct_change(2)
                features_df[f'{name}_ma20_slope'] = features_df[f'{name}_ma20'].pct_change(5)
        
        # ç›¸é–¢ç³»ç‰¹å¾´é‡ï¼ˆä¸»è¦ãƒšã‚¢ï¼‰
        if 'nikkei225_close' in features_df.columns and 'usdjpy_close' in features_df.columns:
            # æ—¥çµŒå¹³å‡ã¨ãƒ‰ãƒ«å††ã®ç›¸é–¢
            features_df['nikkei_usdjpy_correlation'] = features_df['nikkei225_return_1d'].rolling(20).corr(features_df['usdjpy_return_1d'])
        
        if 'nikkei225_close' in features_df.columns and 'topix_close' in features_df.columns:
            # æ—¥çµŒå¹³å‡ã¨TOPIXã®ä¹–é›¢
            features_df['nikkei_topix_spread'] = (features_df['nikkei225_return_1d'] - features_df['topix_return_1d'])
        
        if 'vix_close' in features_df.columns:
            # VIXãƒ¬ã‚¸ãƒ¼ãƒ ï¼ˆä½ãƒªã‚¹ã‚¯/é«˜ãƒªã‚¹ã‚¯ï¼‰
            features_df['vix_regime_low'] = (features_df['vix_close'] < 20).astype(int)
            features_df['vix_regime_high'] = (features_df['vix_close'] > 30).astype(int)
        
        # æ¬ æå€¤å‡¦ç†
        features_df = features_df.fillna(method='ffill').fillna(0)
        
        # ç•°å¸¸å€¤å‡¦ç†
        numeric_cols = features_df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            if col != 'Date':
                q99 = features_df[col].quantile(0.99)
                q01 = features_df[col].quantile(0.01)
                features_df[col] = features_df[col].clip(q01, q99)
        
        logger.success(f"âœ… ãƒãƒ¼ã‚±ãƒƒãƒˆç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {len(features_df)}æ—¥, {len(features_df.columns)-1}ç‰¹å¾´é‡")
        
        # ç”Ÿæˆã•ã‚ŒãŸä¸»è¦ç‰¹å¾´é‡ã®ç¢ºèª
        key_features = [col for col in features_df.columns if any(keyword in col.lower() for keyword in ['return', 'ratio', 'volatility', 'rsi'])]
        logger.info(f"ğŸ“Š ç”Ÿæˆã•ã‚ŒãŸä¸»è¦ç‰¹å¾´é‡æ•°: {len(key_features)}")
        
        return features_df
    
    def get_sector_etf_data(self, period: str = "1y") -> pd.DataFrame:
        """ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥ETFãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæ—¥æœ¬ï¼‰"""
        sector_etfs = {
            'tse_reit': '1343.T',      # NEXT FUNDS æ±è¨¼REITæŒ‡æ•°é€£å‹•å‹ä¸Šå ´æŠ•ä¿¡
            'tech': '1625.T',          # NEXT FUNDS æ—¥çµŒ225é€£å‹•å‹ä¸Šå ´æŠ•ä¿¡
            'financial': '1615.T'      # NEXT FUNDS TOPIXéŠ€è¡Œæ¥­é€£å‹•å‹ä¸Šå ´æŠ•ä¿¡
        }
        
        logger.info("ğŸ¢ ã‚»ã‚¯ã‚¿ãƒ¼ETFãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
        
        sector_data = {}
        for name, symbol in sector_etfs.items():
            df = self.get_market_data(symbol, period)
            if not df.empty:
                sector_data[name] = df
        
        if sector_data:
            logger.success(f"âœ… ã‚»ã‚¯ã‚¿ãƒ¼ETFãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(sector_data)}ã‚»ã‚¯ã‚¿ãƒ¼")
        
        return sector_data
    
    def save_market_data(self, features_df: pd.DataFrame, filename: str = "market_features.parquet"):
        """ãƒãƒ¼ã‚±ãƒƒãƒˆç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
        try:
            features_df.to_parquet(filename)
            logger.success(f"âœ… ãƒãƒ¼ã‚±ãƒƒãƒˆç‰¹å¾´é‡ä¿å­˜å®Œäº†: {filename}")
            return True
        except Exception as e:
            logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ä¿å­˜å¤±æ•—: {e}")
            return False

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
    market_data = YahooMarketData()
    
    # å…¨ãƒãƒ¼ã‚±ãƒƒãƒˆæŒ‡æ¨™å–å¾—
    data_dict = market_data.get_all_market_data(period="2y")
    
    if data_dict:
        # ç‰¹å¾´é‡ç”Ÿæˆ
        features_df = market_data.calculate_market_features(data_dict)
        
        if not features_df.empty:
            # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            market_data.save_market_data(features_df)
            
            # åŸºæœ¬çµ±è¨ˆ
            logger.info("ğŸ“Š ãƒãƒ¼ã‚±ãƒƒãƒˆç‰¹å¾´é‡çµ±è¨ˆ:")
            logger.info(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {features_df['Date'].min()} ï½ {features_df['Date'].max()}")
            logger.info(f"ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°: {len(features_df)}")
            
            # ä¸»è¦æŒ‡æ¨™ã®ç¢ºèª
            key_cols = ['nikkei225_return_1d', 'usdjpy_return_1d', 'vix_close', 'topix_return_1d']
            available_cols = [col for col in key_cols if col in features_df.columns]
            
            for col in available_cols:
                mean_val = features_df[col].mean()
                std_val = features_df[col].std()
                logger.info(f"  {col}: å¹³å‡{mean_val:.4f}, æ¨™æº–åå·®{std_val:.4f}")
        else:
            logger.warning("ç‰¹å¾´é‡ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
    else:
        logger.error("ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")