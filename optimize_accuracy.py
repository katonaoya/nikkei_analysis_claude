#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç²¾åº¦æ”¹å–„ã®ãŸã‚ã®ç‰¹å¾´é‡æœ€é©åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ç›®æ¨™: é¸å‡ºã•ã‚ŒãŸ5éŠ˜æŸ„/æ—¥ã®ç²¾åº¦ã‚’60%ä»¥ä¸Šã«ã™ã‚‹
"""

import pandas as pd
import numpy as np
from pathlib import Path
import yaml
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif
from itertools import combinations
import logging
import warnings
warnings.filterwarnings('ignore')

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s'
)
logger = logging.getLogger(__name__)


class AccuracyOptimizer:
    """ç²¾åº¦æœ€é©åŒ–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.best_accuracy = 0
        self.best_features = None
        self.best_params = None
        self.best_model = None
        
    def load_data(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        data_path = Path("data/processed/integrated_with_external.parquet")
        
        if not data_path.exists():
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_path}")
            return None
            
        logger.info(f"ğŸ“¥ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
        df = pd.read_parquet(data_path)
        
        # å¿…è¦ãªåˆ—ã®å‡¦ç†
        if 'Target' not in df.columns and 'Binary_Direction' in df.columns:
            df['Target'] = df['Binary_Direction']
        if 'Stock' not in df.columns and 'Code' in df.columns:
            df['Stock'] = df['Code']
            
        return df
    
    def get_all_features(self, df):
        """åˆ©ç”¨å¯èƒ½ãªå…¨ç‰¹å¾´é‡ã‚’å–å¾—"""
        # é™¤å¤–ã™ã‚‹åˆ—
        exclude_cols = ['Date', 'Stock', 'Code', 'Target', 'Binary_Direction', 
                       'Close', 'Open', 'High', 'Low', 'Volume', 'Direction']
        
        # æ•°å€¤å‹ã®åˆ—ã®ã¿æŠ½å‡º
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        # ç‰¹å¾´é‡åˆ—ã‚’æŠ½å‡º
        feature_cols = [col for col in numeric_cols if col not in exclude_cols]
        
        logger.info(f"ğŸ“Š åˆ©ç”¨å¯èƒ½ãªç‰¹å¾´é‡: {len(feature_cols)}å€‹")
        logger.info(f"  {feature_cols[:10]}...")
        
        return feature_cols
    
    def evaluate_features(self, df, features, model_type='logistic', 
                         confidence_threshold=0.50, top_n=5):
        """ç‰¹å®šã®ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã§ç²¾åº¦ã‚’è©•ä¾¡"""
        
        # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date')
        
        # å¿…è¦ãªåˆ—ã®ã¿æŠ½å‡º
        required_cols = ['Date', 'Stock', 'Target', 'Close'] + features
        df_clean = df[required_cols].dropna()
        
        if len(df_clean) < 10000:
            return 0, 0, 0
        
        # ãƒ†ã‚¹ãƒˆæœŸé–“ï¼ˆç›´è¿‘30æ—¥ï¼‰
        unique_dates = sorted(df_clean['Date'].unique())
        if len(unique_dates) < 130:
            return 0, 0, 0
            
        test_dates = unique_dates[-30:]
        
        all_predictions = []
        all_actuals = []
        daily_accuracies = []
        
        for test_date in test_dates:
            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
            train_data = df_clean[df_clean['Date'] < test_date]
            test_data = df_clean[df_clean['Date'] == test_date]
            
            if len(train_data) < 1000 or len(test_data) < 10:
                continue
            
            # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
            X_train = train_data[features]
            y_train = train_data['Target']
            X_test = test_data[features]
            y_test = test_data['Target']
            
            # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # ãƒ¢ãƒ‡ãƒ«é¸æŠã¨å­¦ç¿’
            if model_type == 'logistic':
                model = LogisticRegression(random_state=42, max_iter=1000, 
                                          class_weight='balanced')
            elif model_type == 'rf':
                model = RandomForestClassifier(n_estimators=100, random_state=42,
                                              class_weight='balanced', max_depth=10)
            else:  # gradient_boost
                model = GradientBoostingClassifier(n_estimators=100, random_state=42,
                                                  max_depth=5)
            
            model.fit(X_train_scaled, y_train)
            
            # äºˆæ¸¬ç¢ºç‡ã‚’å–å¾—
            y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
            
            # ä¸Šä½NéŠ˜æŸ„ã‚’é¸æŠ
            test_data_copy = test_data.copy()
            test_data_copy['confidence'] = y_pred_proba
            test_data_copy = test_data_copy.sort_values('confidence', ascending=False)
            
            # ä¿¡é ¼åº¦é–¾å€¤ã‚’æº€ãŸã™ä¸Šä½NéŠ˜æŸ„
            top_stocks = test_data_copy[test_data_copy['confidence'] >= confidence_threshold].head(top_n)
            
            if len(top_stocks) > 0:
                # é¸å‡ºã•ã‚ŒãŸéŠ˜æŸ„ã®å®Ÿéš›ã®çµæœ
                selected_actuals = top_stocks['Target'].values
                selected_predictions = np.ones(len(selected_actuals))  # å…¨ã¦è²·ã„äºˆæ¸¬
                
                all_actuals.extend(selected_actuals)
                all_predictions.extend(selected_predictions)
                
                daily_accuracy = (selected_actuals == selected_predictions).mean()
                daily_accuracies.append(daily_accuracy)
        
        if len(all_predictions) == 0:
            return 0, 0, 0
        
        # å…¨ä½“ç²¾åº¦
        overall_accuracy = accuracy_score(all_actuals, all_predictions)
        
        # æ—¥æ¬¡ç²¾åº¦ã®å¹³å‡
        avg_daily_accuracy = np.mean(daily_accuracies) if daily_accuracies else 0
        
        # é¸å‡ºç‡ï¼ˆä½•æ—¥è²·ã„ã‚·ã‚°ãƒŠãƒ«ãŒå‡ºãŸã‹ï¼‰
        selection_rate = len(daily_accuracies) / len(test_dates)
        
        return overall_accuracy, avg_daily_accuracy, selection_rate
    
    def optimize_features(self, df):
        """ç‰¹å¾´é‡ã®æœ€é©åŒ–"""
        logger.info("ğŸ” ç‰¹å¾´é‡ã®æœ€é©åŒ–é–‹å§‹...")
        
        # å…¨ç‰¹å¾´é‡å–å¾—
        all_features = self.get_all_features(df)
        
        # Step 1: çµ±è¨ˆçš„ã«é‡è¦ãªç‰¹å¾´é‡ã‚’é¸æŠ
        logger.info("Step 1: çµ±è¨ˆçš„ç‰¹å¾´é‡é¸æŠ...")
        
        # ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ‡ãƒ¼ã‚¿æº–å‚™
        required_cols = ['Target'] + all_features
        df_clean = df[required_cols].dropna()
        
        if len(df_clean) < 10000:
            logger.error("ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return None
        
        X = df_clean[all_features]
        y = df_clean['Target']
        
        # ç›¸äº’æƒ…å ±é‡ã«ã‚ˆã‚‹ç‰¹å¾´é‡é¸æŠ
        selector = SelectKBest(score_func=mutual_info_classif, k=20)
        selector.fit(X, y)
        
        # é‡è¦åº¦ã§ã‚½ãƒ¼ãƒˆ
        feature_scores = zip(all_features, selector.scores_)
        sorted_features = sorted(feature_scores, key=lambda x: x[1], reverse=True)
        
        # ä¸Šä½20ç‰¹å¾´é‡
        top_features = [f[0] for f in sorted_features[:20]]
        
        logger.info(f"ğŸ“Š ä¸Šä½20ç‰¹å¾´é‡:")
        for i, (feat, score) in enumerate(sorted_features[:20], 1):
            logger.info(f"  {i:2d}. {feat:20s} (ã‚¹ã‚³ã‚¢: {score:.4f})")
        
        # Step 2: ç‰¹å¾´é‡ã®çµ„ã¿åˆã‚ã›ã‚’è©¦ã™
        logger.info("\nStep 2: ç‰¹å¾´é‡çµ„ã¿åˆã‚ã›æœ€é©åŒ–...")
        
        best_result = {
            'features': None,
            'accuracy': 0,
            'daily_accuracy': 0,
            'selection_rate': 0,
            'model_type': None,
            'threshold': None
        }
        
        # ç•°ãªã‚‹ç‰¹å¾´é‡æ•°ã‚’è©¦ã™
        for n_features in [3, 5, 7, 10, 15]:
            logger.info(f"\nğŸ“Š {n_features}å€‹ã®ç‰¹å¾´é‡ã§è©•ä¾¡...")
            
            # ä¸Šä½nå€‹ã®ç‰¹å¾´é‡
            test_features = top_features[:n_features]
            
            # ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™
            for model_type in ['logistic', 'rf', 'gradient_boost']:
                
                # ç•°ãªã‚‹ä¿¡é ¼åº¦é–¾å€¤ã‚’è©¦ã™
                for threshold in [0.45, 0.50, 0.52, 0.55]:
                    
                    accuracy, daily_acc, selection_rate = self.evaluate_features(
                        df, test_features, model_type, threshold, top_n=5
                    )
                    
                    # é¸å‡ºã•ã‚ŒãŸ5éŠ˜æŸ„ã®ç²¾åº¦ãŒé‡è¦
                    if accuracy > best_result['accuracy']:
                        best_result = {
                            'features': test_features,
                            'accuracy': accuracy,
                            'daily_accuracy': daily_acc,
                            'selection_rate': selection_rate,
                            'model_type': model_type,
                            'threshold': threshold
                        }
                        
                        logger.info(f"  âœ… æ–°è¨˜éŒ²! ç²¾åº¦: {accuracy:.2%} "
                                  f"(ãƒ¢ãƒ‡ãƒ«: {model_type}, é–¾å€¤: {threshold})")
                        
                        if accuracy >= 0.60:
                            logger.info(f"  ğŸ¯ ç›®æ¨™ç²¾åº¦60%ã‚’é”æˆ!")
        
        # Step 3: ã•ã‚‰ã«ç‰¹å¾´é‡ã‚’è¿½åŠ ã—ã¦è©¦ã™
        if best_result['accuracy'] < 0.60:
            logger.info("\nStep 3: è¿½åŠ ã®ç‰¹å¾´é‡çµ„ã¿åˆã‚ã›...")
            
            # æŠ€è¡“æŒ‡æ¨™ç³»ã®ç‰¹å¾´é‡ã‚’é‡ç‚¹çš„ã«è©¦ã™
            technical_features = [f for f in all_features if any(
                keyword in f for keyword in ['RSI', 'MA', 'EMA', 'MACD', 'Bollinger', 
                                            'Volatility', 'Volume', 'Price_vs', 'Returns']
            )]
            
            # æ§˜ã€…ãªçµ„ã¿åˆã‚ã›ã‚’è©¦ã™
            for combo_size in [5, 7, 10]:
                if len(technical_features) >= combo_size:
                    # æœ€åˆã®combo_sizeå€‹ã‚’è©¦ã™
                    test_features = technical_features[:combo_size]
                    
                    for model_type in ['rf', 'gradient_boost']:
                        for threshold in [0.48, 0.51, 0.53]:
                            
                            accuracy, daily_acc, selection_rate = self.evaluate_features(
                                df, test_features, model_type, threshold, top_n=5
                            )
                            
                            if accuracy > best_result['accuracy']:
                                best_result = {
                                    'features': test_features,
                                    'accuracy': accuracy,
                                    'daily_accuracy': daily_acc,
                                    'selection_rate': selection_rate,
                                    'model_type': model_type,
                                    'threshold': threshold
                                }
                                
                                logger.info(f"  âœ… æ›´æ–°! ç²¾åº¦: {accuracy:.2%}")
                                
                                if accuracy >= 0.60:
                                    logger.info(f"  ğŸ¯ ç›®æ¨™ç²¾åº¦60%ã‚’é”æˆ!")
                                    break
        
        return best_result
    
    def save_optimal_config(self, best_result):
        """æœ€é©ãªè¨­å®šã‚’ä¿å­˜"""
        if best_result['accuracy'] >= 0.60:
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°
            config_path = Path("production_config.yaml")
            
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # ç‰¹å¾´é‡æ›´æ–°
            config['features']['optimal_features'] = best_result['features']
            config['system']['confidence_threshold'] = best_result['threshold']
            
            # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¿½åŠ 
            config['model'] = {
                'type': best_result['model_type'],
                'accuracy': float(best_result['accuracy']),
                'daily_accuracy': float(best_result['daily_accuracy']),
                'optimized_date': pd.Timestamp.now().strftime('%Y-%m-%d')
            }
            
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, allow_unicode=True, default_flow_style=False)
            
            logger.info(f"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
            
            # çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚‚ä¿å­˜
            result_path = Path("optimization_result.txt")
            with open(result_path, 'w', encoding='utf-8') as f:
                f.write(f"ç²¾åº¦æœ€é©åŒ–çµæœ\n")
                f.write(f"="*50 + "\n")
                f.write(f"é”æˆç²¾åº¦: {best_result['accuracy']:.2%}\n")
                f.write(f"æ—¥æ¬¡å¹³å‡ç²¾åº¦: {best_result['daily_accuracy']:.2%}\n")
                f.write(f"é¸å‡ºç‡: {best_result['selection_rate']:.2%}\n")
                f.write(f"ãƒ¢ãƒ‡ãƒ«: {best_result['model_type']}\n")
                f.write(f"ä¿¡é ¼åº¦é–¾å€¤: {best_result['threshold']}\n")
                f.write(f"ç‰¹å¾´é‡æ•°: {len(best_result['features'])}\n")
                f.write(f"ç‰¹å¾´é‡:\n")
                for feat in best_result['features']:
                    f.write(f"  - {feat}\n")
            
            return True
        return False


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    optimizer = AccuracyOptimizer()
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = optimizer.load_data()
    if df is None:
        return
    
    logger.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(df):,}ãƒ¬ã‚³ãƒ¼ãƒ‰")
    
    # ç‰¹å¾´é‡æœ€é©åŒ–
    best_result = optimizer.optimize_features(df)
    
    if best_result and best_result['accuracy'] > 0:
        logger.info("\n" + "="*80)
        logger.info("ğŸ¯ æœ€é©åŒ–çµæœ")
        logger.info("="*80)
        logger.info(f"æœ€é«˜ç²¾åº¦: {best_result['accuracy']:.2%}")
        logger.info(f"æ—¥æ¬¡å¹³å‡ç²¾åº¦: {best_result['daily_accuracy']:.2%}")
        logger.info(f"é¸å‡ºç‡: {best_result['selection_rate']:.2%}")
        logger.info(f"æœ€é©ãƒ¢ãƒ‡ãƒ«: {best_result['model_type']}")
        logger.info(f"æœ€é©é–¾å€¤: {best_result['threshold']}")
        logger.info(f"æœ€é©ç‰¹å¾´é‡ ({len(best_result['features'])}å€‹):")
        for i, feat in enumerate(best_result['features'], 1):
            logger.info(f"  {i:2d}. {feat}")
        
        if best_result['accuracy'] >= 0.60:
            logger.info("\nâœ… ç›®æ¨™ç²¾åº¦60%ã‚’é”æˆã—ã¾ã—ãŸ!")
            
            # è¨­å®šã‚’ä¿å­˜
            if optimizer.save_optimal_config(best_result):
                logger.info("ğŸ“ æœ€é©ãªè¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ")
        else:
            logger.info(f"\nâš ï¸ ç›®æ¨™ç²¾åº¦60%ã«å±Šãã¾ã›ã‚“ã§ã—ãŸ ({best_result['accuracy']:.2%})")
            logger.info("ã•ã‚‰ãªã‚‹æœ€é©åŒ–ãŒå¿…è¦ã§ã™")
    else:
        logger.error("æœ€é©åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()