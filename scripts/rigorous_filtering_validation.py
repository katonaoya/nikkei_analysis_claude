#!/usr/bin/env python3
"""
å³å¯†ãªçµã‚Šè¾¼ã¿æ‰‹æ³•æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 
ç•°å¸¸å€¤æ¤œå‡ºã¨ãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½ä»˜ã
"""

import pandas as pd
import numpy as np
from pathlib import Path
from loguru import logger
import sys
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings('ignore')

# ãƒ­ã‚°è¨­å®š
logger.remove()
logger.add(sys.stderr, format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>", level="INFO")

class RigorousFilteringValidation:
    """å³å¯†ãªçµã‚Šè¾¼ã¿æ‰‹æ³•æ¤œè¨¼ï¼ˆãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½ä»˜ãï¼‰"""
    
    def __init__(self):
        self.data_dir = Path("data")
        self.processed_dir = self.data_dir / "processed"
        
        # æœ€é©ç‰¹å¾´é‡
        self.optimal_features = [
            'Market_Breadth', 'Market_Return', 'Volatility_20', 'Price_vs_MA20',
            'sp500_change', 'vix_change', 'nikkei_change', 'us_10y_change', 'usd_jpy_change'
        ]
        
        # æ¤œè¨¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.confidence_threshold = 0.55
        self.target_candidates = 5
        self.min_evaluation_samples = 100  # æœ€ä½è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«æ•°
        
    def load_and_prepare_data(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨æº–å‚™"""
        logger.info("ğŸ“Š å³å¯†æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™...")
        
        integrated_file = self.processed_dir / "integrated_with_external.parquet"
        df = pd.read_parquet(integrated_file)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        clean_df = df[df['Binary_Direction'].notna()].copy()
        clean_df = clean_df.sort_values(['Date', 'Code']).reset_index(drop=True)
        
        # é‡è¤‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ï¼ˆæ—¥ä»˜ãƒ»éŠ˜æŸ„ã®çµ„ã¿åˆã‚ã›ã§æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®ã¿ä¿æŒï¼‰
        clean_df = clean_df.groupby(['Date', 'Code']).last().reset_index()
        
        # ã‚»ã‚¯ã‚¿ãƒ¼æƒ…å ±è¿½åŠ ï¼ˆä¸€è²«æ€§ã®ãŸã‚å›ºå®šã‚·ãƒ¼ãƒ‰ï¼‰
        clean_df = self.add_sector_information(clean_df)
        
        # ç¿Œæ—¥ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—
        clean_df = clean_df.sort_values(['Code', 'Date'])
        clean_df['Next_Return'] = clean_df.groupby('Code')['Close'].pct_change().shift(-1)
        
        # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæº–å‚™
        X = clean_df[self.optimal_features].fillna(0)
        y = clean_df['Binary_Direction'].astype(int)
        
        logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: {len(clean_df):,}ä»¶, {len(self.optimal_features)}ç‰¹å¾´é‡")
        
        return clean_df, X, y
    
    def add_sector_information(self, df):
        """ã‚»ã‚¯ã‚¿ãƒ¼æƒ…å ±ã®è¿½åŠ ï¼ˆä¸€è²«æ€§ç¢ºä¿ï¼‰"""
        np.random.seed(42)  # å›ºå®šã‚·ãƒ¼ãƒ‰
        unique_codes = df['Code'].unique()
        
        sectors = ['Tech', 'Finance', 'Healthcare', 'Consumer', 'Industrial', 'Materials', 'Energy', 'Utilities']
        sector_mapping = {code: np.random.choice(sectors) for code in unique_codes}
        df['Sector'] = df['Code'].map(sector_mapping)
        
        return df
    
    def validate_data_integrity(self, df, X, y):
        """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼"""
        logger.info("ğŸ” ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼...")
        
        issues = []
        warnings_only = []
        
        # åŸºæœ¬ãƒã‚§ãƒƒã‚¯
        if len(df) != len(X) or len(df) != len(y):
            issues.append(f"ãƒ‡ãƒ¼ã‚¿é•·ä¸ä¸€è‡´: df={len(df)}, X={len(X)}, y={len(y)}")
        
        # æ¬ æå€¤ãƒã‚§ãƒƒã‚¯
        missing_features = X.isnull().sum().sum()
        if missing_features > 0:
            warnings_only.append(f"ç‰¹å¾´é‡ã«æ¬ æå€¤: {missing_features}ä»¶")
        
        # æ—¥ä»˜é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆè­¦å‘Šã®ã¿ã€åœæ­¢ã—ãªã„ï¼‰
        date_code_counts = df.groupby(['Date', 'Code']).size()
        duplicates = (date_code_counts > 1).sum()
        if duplicates > 0:
            warnings_only.append(f"æ—¥ä»˜ãƒ»éŠ˜æŸ„é‡è¤‡: {duplicates}ä»¶ - æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨")
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒãƒã‚§ãƒƒã‚¯
        target_dist = y.value_counts()
        if len(target_dist) != 2:
            issues.append(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒç•°å¸¸: {target_dist}")
        
        # è­¦å‘Šè¡¨ç¤º
        if warnings_only:
            logger.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®è­¦å‘Š:")
            for warning in warnings_only:
                logger.warning(f"  - {warning}")
        
        # é‡å¤§ãªå•é¡Œã®ã¿åœæ­¢
        if issues:
            logger.error("âŒ ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®é‡å¤§ãªå•é¡Œ:")
            for issue in issues:
                logger.error(f"  - {issue}")
            return False
        else:
            logger.info("âœ… ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§: æ­£å¸¸ï¼ˆè­¦å‘Šã¯ã‚ã‚‹ãŒå®Ÿè¡Œå¯èƒ½ï¼‰")
            return True
    
    def debug_filtering_method(self, method_name, method_func, test_data_sample):
        """çµã‚Šè¾¼ã¿æ‰‹æ³•ã®ãƒ‡ãƒãƒƒã‚°"""
        logger.info(f"ğŸ› {method_name} ãƒ‡ãƒãƒƒã‚°...")
        
        debug_info = {
            'method_name': method_name,
            'input_records': len(test_data_sample),
            'has_pred_proba': 'pred_proba' in test_data_sample.columns,
            'has_sector': 'Sector' in test_data_sample.columns,
            'high_conf_count': 0,
            'selected_count': 0,
            'error': None
        }
        
        try:
            # é«˜ç¢ºä¿¡åº¦å€™è£œæ•°ãƒã‚§ãƒƒã‚¯
            if 'pred_proba' in test_data_sample.columns:
                high_conf_mask = (
                    (test_data_sample['pred_proba'] >= self.confidence_threshold) | 
                    (test_data_sample['pred_proba'] <= (1 - self.confidence_threshold))
                )
                debug_info['high_conf_count'] = high_conf_mask.sum()
            
            # æ‰‹æ³•é©ç”¨
            selected = method_func(test_data_sample, self.target_candidates)
            debug_info['selected_count'] = len(selected) if selected else 0
            
            # ç•°å¸¸ãƒã‚§ãƒƒã‚¯
            if debug_info['selected_count'] > self.target_candidates:
                debug_info['error'] = f"é¸æŠæ•°éå¤š: {debug_info['selected_count']} > {self.target_candidates}"
            elif debug_info['high_conf_count'] > 0 and debug_info['selected_count'] == 0:
                debug_info['error'] = f"é«˜ç¢ºä¿¡åº¦å€™è£œã‚ã‚‹ã®ã«é¸æŠ0ä»¶"
            
        except Exception as e:
            debug_info['error'] = f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}"
        
        logger.info(f"  å…¥åŠ›: {debug_info['input_records']}ä»¶")
        logger.info(f"  é«˜ç¢ºä¿¡åº¦: {debug_info['high_conf_count']}ä»¶")
        logger.info(f"  é¸æŠ: {debug_info['selected_count']}ä»¶")
        if debug_info['error']:
            logger.warning(f"  âš ï¸ å•é¡Œ: {debug_info['error']}")
        
        return debug_info
    
    def method_1_simple_confidence(self, day_data, n_candidates=5):
        """æ‰‹æ³•1: å˜ç´”ç¢ºä¿¡åº¦ä¸Šä½é¸æŠï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆï¼‰"""
        if 'pred_proba' not in day_data.columns:
            return []
        
        # ç¢ºä¿¡åº¦ã®çµ¶å¯¾å€¤è¨ˆç®—
        day_data = day_data.copy()
        day_data['abs_confidence'] = np.maximum(day_data['pred_proba'], 1 - day_data['pred_proba'])
        
        # ç¢ºä¿¡åº¦é–¾å€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        high_conf = day_data[day_data['abs_confidence'] >= self.confidence_threshold]
        
        if len(high_conf) == 0:
            return []
        
        # ä¸Šä½é¸æŠ
        selected = high_conf.nlargest(n_candidates, 'abs_confidence')
        return selected['Code'].tolist()
    
    def method_2_sector_diversity(self, day_data, n_candidates=5):
        """æ‰‹æ³•2: ã‚»ã‚¯ã‚¿ãƒ¼åˆ†æ•£ï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆï¼‰"""
        if 'pred_proba' not in day_data.columns or 'Sector' not in day_data.columns:
            return []
        
        # ç¢ºä¿¡åº¦è¨ˆç®—
        day_data = day_data.copy()
        day_data['abs_confidence'] = np.maximum(day_data['pred_proba'], 1 - day_data['pred_proba'])
        
        # é«˜ç¢ºä¿¡åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        high_conf = day_data[day_data['abs_confidence'] >= self.confidence_threshold]
        
        if len(high_conf) == 0:
            return []
        
        # ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥æœ€é«˜ç¢ºä¿¡åº¦é¸æŠ
        selected_codes = []
        used_sectors = set()
        
        # ã‚»ã‚¯ã‚¿ãƒ¼ã”ã¨ã®æœ€é«˜ç¢ºä¿¡åº¦
        for sector in high_conf['Sector'].unique():
            if len(selected_codes) >= n_candidates:
                break
            
            sector_data = high_conf[high_conf['Sector'] == sector]
            if len(sector_data) == 0:
                continue
            
            best_in_sector = sector_data.loc[sector_data['abs_confidence'].idxmax()]
            selected_codes.append(best_in_sector['Code'])
            used_sectors.add(sector)
        
        # ä¸è¶³åˆ†ã‚’å…¨ä½“ã‹ã‚‰è£œå®Œ
        if len(selected_codes) < n_candidates:
            remaining = high_conf[~high_conf['Code'].isin(selected_codes)]
            additional = remaining.nlargest(n_candidates - len(selected_codes), 'abs_confidence')
            selected_codes.extend(additional['Code'].tolist())
        
        return selected_codes[:n_candidates]
    
    def method_3_volatility_adjusted(self, day_data, n_candidates=5):
        """æ‰‹æ³•3: ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´ï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆï¼‰"""
        required_cols = ['pred_proba', 'Volatility_20']
        if not all(col in day_data.columns for col in required_cols):
            return []
        
        day_data = day_data.copy()
        day_data['abs_confidence'] = np.maximum(day_data['pred_proba'], 1 - day_data['pred_proba'])
        
        # é«˜ç¢ºä¿¡åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        high_conf = day_data[day_data['abs_confidence'] >= self.confidence_threshold]
        
        if len(high_conf) == 0:
            return []
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´ã‚¹ã‚³ã‚¢
        high_conf = high_conf.copy()
        high_conf['vol_adj_score'] = high_conf['abs_confidence'] / (high_conf['Volatility_20'] + 0.01)
        
        selected = high_conf.nlargest(n_candidates, 'vol_adj_score')
        return selected['Code'].tolist()
    
    def rigorous_evaluation(self, df, X, y):
        """å³å¯†ãªè©•ä¾¡å®Ÿè¡Œ"""
        logger.info("ğŸ§ª å³å¯†ãªçµã‚Šè¾¼ã¿æ‰‹æ³•è©•ä¾¡é–‹å§‹...")
        
        # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼
        if not self.validate_data_integrity(df, X, y):
            logger.error("âŒ ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼ã®ãŸã‚è©•ä¾¡ä¸­æ­¢")
            return None
        
        # è©•ä¾¡æœŸé–“è¨­å®šï¼ˆå…¨æœŸé–“ã‚’æ­£ã—ãä½¿ç”¨ï¼‰
        dates = sorted(df['Date'].unique())
        train_end_idx = int(len(dates) * 0.8)  # 80%ã¾ã§å­¦ç¿’
        
        train_dates = dates[:train_end_idx]
        test_dates = dates[train_end_idx:]  # æ®‹ã‚Šå…¨æœŸé–“ã§è©•ä¾¡ï¼ˆ2024-2025å¹´å«ã‚€ï¼‰
        
        logger.info(f"å­¦ç¿’æœŸé–“: {train_dates[0]} - {train_dates[-1]} ({len(train_dates)}æ—¥)")
        logger.info(f"è©•ä¾¡æœŸé–“: {test_dates[0]} - {test_dates[-1]} ({len(test_dates)}æ—¥)")
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        train_mask = df['Date'].isin(train_dates)
        X_train = X[train_mask]
        y_train = y[train_mask]
        
        scaler = StandardScaler()
        model = LogisticRegression(C=0.001, class_weight='balanced', random_state=42, max_iter=1000)
        
        X_train_scaled = scaler.fit_transform(X_train)
        model.fit(X_train_scaled, y_train)
        
        logger.info(f"ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†: {len(X_train):,}ä»¶ã§å­¦ç¿’")
        
        # æ‰‹æ³•å®šç¾©
        methods = {
            'Simple_Confidence': self.method_1_simple_confidence,
            'Sector_Diversity': self.method_2_sector_diversity,
            'Volatility_Adjusted': self.method_3_volatility_adjusted
        }
        
        # å„æ‰‹æ³•ã®è©³ç´°è©•ä¾¡
        method_results = {}
        
        for method_name, method_func in methods.items():
            logger.info(f"ğŸ“Š {method_name} è©³ç´°è©•ä¾¡...")
            
            total_predictions = 0
            correct_predictions = 0
            daily_selections = []
            evaluation_days = 0
            debug_info_list = []
            
            for i, date in enumerate(test_dates):
                day_data = df[df['Date'] == date].copy()
                if len(day_data) == 0:
                    continue
                
                # äºˆæ¸¬å®Ÿè¡Œ
                X_day = day_data[self.optimal_features].fillna(0)
                X_day_scaled = scaler.transform(X_day)
                pred_proba = model.predict_proba(X_day_scaled)[:, 1]
                day_data['pred_proba'] = pred_proba
                
                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±å–å¾—ï¼ˆæœ€åˆã®3æ—¥ã®ã¿ï¼‰
                if i < 3:
                    debug_info = self.debug_filtering_method(method_name, method_func, day_data)
                    debug_info_list.append(debug_info)
                
                # æ‰‹æ³•é©ç”¨
                selected_codes = method_func(day_data, self.target_candidates)
                
                if len(selected_codes) == 0:
                    continue
                
                # é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ã®è©•ä¾¡
                selected_data = day_data[day_data['Code'].isin(selected_codes)]
                
                day_correct = 0
                for _, stock in selected_data.iterrows():
                    prediction = stock['pred_proba'] > 0.5
                    actual = stock['Binary_Direction'] == 1
                    
                    total_predictions += 1
                    if prediction == actual:
                        correct_predictions += 1
                        day_correct += 1
                
                daily_selections.append({
                    'date': date,
                    'total_candidates': len(day_data),
                    'selected': len(selected_codes),
                    'accuracy': day_correct / len(selected_codes) if selected_codes else 0
                })
                
                evaluation_days += 1
            
            # çµæœé›†è¨ˆã¨ç•°å¸¸å€¤æ¤œå‡º
            accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0
            avg_daily_selections = np.mean([d['selected'] for d in daily_selections]) if daily_selections else 0
            
            # ç•°å¸¸å€¤æ¤œå‡º
            anomalies = []
            if accuracy > 0.85:  # 85%è¶…ãˆã¯ç•°å¸¸
                anomalies.append(f"ç•°å¸¸ã«é«˜ã„ç²¾åº¦: {accuracy:.1%}")
            if total_predictions < self.min_evaluation_samples:
                anomalies.append(f"è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³: {total_predictions}ä»¶ < {self.min_evaluation_samples}ä»¶")
            if avg_daily_selections < 1:
                anomalies.append(f"æ—¥æ¬¡é¸æŠæ•°ä¸è¶³: {avg_daily_selections:.1f}ä»¶")
            
            method_results[method_name] = {
                'accuracy': accuracy,
                'total_predictions': total_predictions,
                'correct_predictions': correct_predictions,
                'evaluation_days': evaluation_days,
                'avg_daily_selections': avg_daily_selections,
                'daily_selections': daily_selections,
                'debug_info': debug_info_list,
                'anomalies': anomalies,
                'is_reliable': len(anomalies) == 0 and total_predictions >= self.min_evaluation_samples
            }
            
            logger.info(f"  ç²¾åº¦: {accuracy:.1%}")
            logger.info(f"  è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«: {total_predictions}ä»¶")
            logger.info(f"  è©•ä¾¡æ—¥æ•°: {evaluation_days}æ—¥")
            if anomalies:
                logger.warning(f"  âš ï¸ ç•°å¸¸æ¤œå‡º: {', '.join(anomalies)}")
            else:
                logger.info(f"  âœ… æ­£å¸¸ãªçµæœ")
        
        return method_results
    
    def display_rigorous_results(self, results):
        """å³å¯†ãªçµæœè¡¨ç¤º"""
        logger.info("\\n" + "="*120)
        logger.info("ğŸ”¬ å³å¯†ãªçµã‚Šè¾¼ã¿æ‰‹æ³•æ¤œè¨¼çµæœ")
        logger.info("="*120)
        
        # ä¿¡é ¼æ€§ãƒã‚§ãƒƒã‚¯
        reliable_results = {k: v for k, v in results.items() if v['is_reliable']}
        unreliable_results = {k: v for k, v in results.items() if not v['is_reliable']}
        
        logger.info(f"\\nâœ… ä¿¡é ¼æ€§ã®ã‚ã‚‹çµæœ ({len(reliable_results)}/{len(results)}æ‰‹æ³•):")
        if reliable_results:
            sorted_reliable = sorted(reliable_results.items(), key=lambda x: x[1]['accuracy'], reverse=True)
            
            for i, (method, result) in enumerate(sorted_reliable, 1):
                logger.info(f"  {i}. {method:20s}: {result['accuracy']:6.1%} "
                           f"(è©•ä¾¡{result['total_predictions']:,}ä»¶, {result['evaluation_days']:,}æ—¥)")
            
            # æœ€é«˜æ‰‹æ³•ã®è©³ç´°
            best_method, best_result = sorted_reliable[0]
            logger.info(f"\\nğŸ† æœ€é«˜ç²¾åº¦æ‰‹æ³•: {best_method}")
            logger.info(f"  ç²¾åº¦: {best_result['accuracy']:.2%}")
            logger.info(f"  æ­£è§£æ•°: {best_result['correct_predictions']:,}/{best_result['total_predictions']:,}")
            logger.info(f"  å¹³å‡æ—¥æ¬¡é¸æŠ: {best_result['avg_daily_selections']:.1f}éŠ˜æŸ„")
            
        else:
            logger.warning("  ä¿¡é ¼æ€§ã®ã‚ã‚‹çµæœãªã—")
        
        # å•é¡Œã®ã‚ã‚‹çµæœ
        if unreliable_results:
            logger.info(f"\\nâš ï¸ å•é¡Œã®ã‚ã‚‹çµæœ ({len(unreliable_results)}æ‰‹æ³•):")
            for method, result in unreliable_results.items():
                logger.warning(f"  {method:20s}: {', '.join(result['anomalies'])}")
        
        # æ¨å¥¨äº‹é …
        logger.info(f"\\nğŸ’¡ æ¨å¥¨äº‹é …:")
        if reliable_results:
            best_method = max(reliable_results.keys(), key=lambda k: reliable_results[k]['accuracy'])
            logger.info(f"  æ¨å¥¨æ‰‹æ³•: {best_method}")
            logger.info(f"  æœŸå¾…ç²¾åº¦: {reliable_results[best_method]['accuracy']:.1%}")
        else:
            logger.info(f"  å…¨æ‰‹æ³•ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯æ‰‹æ³•è¦‹ç›´ã—ãŒå¿…è¦")
        
        logger.info("="*120)
        
        return reliable_results

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    logger.info("ğŸ”¬ å³å¯†ãªçµã‚Šè¾¼ã¿æ‰‹æ³•æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ")
    
    validator = RigorousFilteringValidation()
    
    try:
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        df, X, y = validator.load_and_prepare_data()
        
        # å³å¯†è©•ä¾¡
        results = validator.rigorous_evaluation(df, X, y)
        
        if results:
            # çµæœè¡¨ç¤º
            reliable_results = validator.display_rigorous_results(results)
            
            if reliable_results:
                logger.info("\\nâœ… å³å¯†æ¤œè¨¼å®Œäº† - ä¿¡é ¼æ€§ã®ã‚ã‚‹çµæœã‚’å–å¾—")
            else:
                logger.warning("\\nâš ï¸ å³å¯†æ¤œè¨¼å®Œäº† - å…¨çµæœã«å•é¡Œã‚ã‚Šã€å†æ¤œè¨ãŒå¿…è¦")
        else:
            logger.error("âŒ è©•ä¾¡å¤±æ•—")
            
    except Exception as e:
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()