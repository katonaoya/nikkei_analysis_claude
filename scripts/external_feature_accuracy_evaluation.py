#!/usr/bin/env python3
"""
å¤–éƒ¨ç‰¹å¾´é‡ã§ã®ç²¾åº¦è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
Yahoo Financeå¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Šæ¤œè¨¼
"""

import pandas as pd
import numpy as np
from pathlib import Path
from loguru import logger
import sys
from sklearn.model_selection import TimeSeriesSplit
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
import warnings
warnings.filterwarnings('ignore')

# ãƒ­ã‚°è¨­å®š
logger.remove()
logger.add(sys.stderr, format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>", level="INFO")

class ExternalFeatureEvaluator:
    """å¤–éƒ¨ç‰¹å¾´é‡è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.data_dir = Path("data")
        self.processed_dir = self.data_dir / "processed"
        self.scaler = StandardScaler()
        
        # å¾“æ¥ã®æœ€é©ç‰¹å¾´é‡ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰
        self.baseline_features = [
            'Market_Breadth', 'Market_Return', 'Volatility_20', 'Price_vs_MA20'
        ]
        
    def load_integrated_data(self):
        """çµ±åˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        logger.info("ğŸ“Š çµ±åˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿...")
        
        integrated_file = self.processed_dir / "integrated_with_external.parquet"
        if not integrated_file.exists():
            logger.error("âŒ çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None
            
        df = pd.read_parquet(integrated_file)
        logger.info(f"âœ… çµ±åˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df):,}ä»¶, {len(df.columns)}ã‚«ãƒ©ãƒ ")
        
        return df
    
    def identify_external_features(self, df):
        """å¤–éƒ¨ç‰¹å¾´é‡ã®ç‰¹å®š"""
        logger.info("ğŸ” å¤–éƒ¨ç‰¹å¾´é‡ç‰¹å®š...")
        
        # å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³
        external_patterns = ['us_10y', 'sp500', 'usd_jpy', 'nikkei', 'vix']
        external_features = [col for col in df.columns 
                           if any(pattern in col for pattern in external_patterns)]
        
        logger.info(f"å¤–éƒ¨ç‰¹å¾´é‡ç·æ•°: {len(external_features)}å€‹")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†é¡
        value_features = [col for col in external_features if 'value' in col]
        change_features = [col for col in external_features if 'change' in col]
        volatility_features = [col for col in external_features if 'volatility' in col]
        
        logger.info(f"  å€¤ç‰¹å¾´é‡: {len(value_features)}å€‹")
        logger.info(f"  å¤‰åŒ–ç‰¹å¾´é‡: {len(change_features)}å€‹")
        logger.info(f"  ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡: {len(volatility_features)}å€‹")
        
        return {
            'all': external_features,
            'value': value_features,
            'change': change_features,
            'volatility': volatility_features
        }
    
    def baseline_accuracy_test(self, df):
        """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç²¾åº¦ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ“ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç²¾åº¦ãƒ†ã‚¹ãƒˆï¼ˆå¾“æ¥ç‰¹å¾´é‡ï¼‰...")
        
        clean_df = df[df['Binary_Direction'].notna()].copy()
        clean_df = clean_df.sort_values(['Date', 'Code']).reset_index(drop=True)
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç‰¹å¾´é‡ã®å­˜åœ¨ç¢ºèª
        missing_baseline = [f for f in self.baseline_features if f not in clean_df.columns]
        if missing_baseline:
            logger.error(f"âŒ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç‰¹å¾´é‡ä¸è¶³: {missing_baseline}")
            return None
            
        X = clean_df[self.baseline_features].fillna(0)
        y = clean_df['Binary_Direction'].astype(int)
        
        return self._evaluate_model(X, y, "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆå¾“æ¥4ç‰¹å¾´é‡ï¼‰")
    
    def external_features_test(self, df, external_features_dict):
        """å¤–éƒ¨ç‰¹å¾´é‡ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸŒ å¤–éƒ¨ç‰¹å¾´é‡ç²¾åº¦ãƒ†ã‚¹ãƒˆ...")
        
        clean_df = df[df['Binary_Direction'].notna()].copy()
        clean_df = clean_df.sort_values(['Date', 'Code']).reset_index(drop=True)
        y = clean_df['Binary_Direction'].astype(int)
        
        results = {}
        
        # 1. å¤–éƒ¨ç‰¹å¾´é‡ã®ã¿
        logger.info("  1. å¤–éƒ¨ç‰¹å¾´é‡ã®ã¿")
        X_external_only = clean_df[external_features_dict['value']].fillna(0)
        results['external_only'] = self._evaluate_model(
            X_external_only, y, f"å¤–éƒ¨ç‰¹å¾´é‡ã®ã¿ï¼ˆ{len(external_features_dict['value'])}å€‹ï¼‰"
        )
        
        # 2. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ + å¤–éƒ¨å€¤ç‰¹å¾´é‡
        logger.info("  2. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ + å¤–éƒ¨å€¤ç‰¹å¾´é‡")
        combined_value_features = self.baseline_features + external_features_dict['value']
        available_combined = [f for f in combined_value_features if f in clean_df.columns]
        X_combined_value = clean_df[available_combined].fillna(0)
        results['baseline_plus_values'] = self._evaluate_model(
            X_combined_value, y, f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ + å¤–éƒ¨å€¤ï¼ˆ{len(available_combined)}å€‹ï¼‰"
        )
        
        # 3. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ + å¤–éƒ¨å¤‰åŒ–ç‰¹å¾´é‡
        logger.info("  3. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ + å¤–éƒ¨å¤‰åŒ–ç‰¹å¾´é‡")
        combined_change_features = self.baseline_features + external_features_dict['change']
        available_change_combined = [f for f in combined_change_features if f in clean_df.columns]
        X_combined_change = clean_df[available_change_combined].fillna(0)
        results['baseline_plus_changes'] = self._evaluate_model(
            X_combined_change, y, f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ + å¤–éƒ¨å¤‰åŒ–ï¼ˆ{len(available_change_combined)}å€‹ï¼‰"
        )
        
        # 4. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ + å…¨å¤–éƒ¨ç‰¹å¾´é‡
        logger.info("  4. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ + å…¨å¤–éƒ¨ç‰¹å¾´é‡")
        all_combined_features = self.baseline_features + external_features_dict['all']
        available_all_combined = [f for f in all_combined_features if f in clean_df.columns]
        X_combined_all = clean_df[available_all_combined].fillna(0)
        results['baseline_plus_all_external'] = self._evaluate_model(
            X_combined_all, y, f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ + å…¨å¤–éƒ¨ï¼ˆ{len(available_all_combined)}å€‹ï¼‰"
        )
        
        return results
    
    def feature_importance_analysis(self, df, best_features):
        """ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ"""
        logger.info("ğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ...")
        
        clean_df = df[df['Binary_Direction'].notna()].copy()
        available_features = [f for f in best_features if f in clean_df.columns]
        
        X = clean_df[available_features].fillna(0)
        y = clean_df['Binary_Direction'].astype(int)
        
        # StandardScaleré©ç”¨
        X_scaled = self.scaler.fit_transform(X)
        
        # LogisticRegressionä¿‚æ•°
        model = LogisticRegression(C=0.001, class_weight='balanced', random_state=42, max_iter=1000)
        model.fit(X_scaled, y)
        
        # é‡è¦åº¦ï¼ˆçµ¶å¯¾å€¤ï¼‰
        importances = abs(model.coef_[0])
        feature_importance = list(zip(available_features, importances))
        feature_importance.sort(key=lambda x: x[1], reverse=True)
        
        logger.info("ğŸ¯ ç‰¹å¾´é‡é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°:")
        for i, (feature, importance) in enumerate(feature_importance, 1):
            feature_type = "å¤–éƒ¨" if any(pattern in feature for pattern in ['us_10y', 'sp500', 'usd_jpy', 'nikkei', 'vix']) else "å¾“æ¥"
            logger.info(f"  {i:2d}. {feature:25s}: {importance:.4f} ({feature_type})")
        
        return feature_importance
    
    def _evaluate_model(self, X, y, description):
        """ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ï¼ˆæ™‚ç³»åˆ—5åˆ†å‰²ï¼‰"""
        X_scaled = self.scaler.fit_transform(X)
        
        model = LogisticRegression(
            C=0.001, 
            class_weight='balanced', 
            random_state=42, 
            max_iter=1000,
            solver='lbfgs'
        )
        
        tscv = TimeSeriesSplit(n_splits=5)
        scores = []
        
        for train_idx, test_idx in tscv.split(X_scaled):
            X_train = X_scaled[train_idx]
            X_test = X_scaled[test_idx]
            y_train = y.iloc[train_idx]
            y_test = y.iloc[test_idx]
            
            model.fit(X_train, y_train)
            pred = model.predict(X_test)
            scores.append(accuracy_score(y_test, pred))
        
        avg_score = np.mean(scores)
        std_score = np.std(scores)
        
        logger.info(f"    {description}: {avg_score:.3%} Â± {std_score:.3%}")
        
        return {
            'avg': avg_score,
            'std': std_score,
            'scores': scores,
            'description': description
        }

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    logger.info("ğŸš€ å¤–éƒ¨ç‰¹å¾´é‡ç²¾åº¦è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ")
    logger.info("ğŸ¯ ç›®æ¨™: Yahoo Financeå¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Šæ¤œè¨¼")
    
    evaluator = ExternalFeatureEvaluator()
    
    try:
        # 1. çµ±åˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        df = evaluator.load_integrated_data()
        if df is None:
            return
        
        # 2. å¤–éƒ¨ç‰¹å¾´é‡ç‰¹å®š
        external_features_dict = evaluator.identify_external_features(df)
        
        # 3. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç²¾åº¦ãƒ†ã‚¹ãƒˆ
        baseline_result = evaluator.baseline_accuracy_test(df)
        
        if baseline_result is None:
            return
        
        # 4. å¤–éƒ¨ç‰¹å¾´é‡ãƒ†ã‚¹ãƒˆ
        external_results = evaluator.external_features_test(df, external_features_dict)
        
        # çµæœæ¯”è¼ƒã¨åˆ†æ
        logger.info("\n" + "="*100)
        logger.info("ğŸ¯ å¤–éƒ¨ç‰¹å¾´é‡ã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Šçµæœ")
        logger.info("="*100)
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è¡¨ç¤º
        logger.info(f"ğŸ“ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: {baseline_result['avg']:.3%} Â± {baseline_result['std']:.3%}")
        
        # å¤–éƒ¨ç‰¹å¾´é‡çµæœè¡¨ç¤º
        logger.info(f"\nğŸ“Š å¤–éƒ¨ç‰¹å¾´é‡ãƒ†ã‚¹ãƒˆçµæœ:")
        results_with_baseline = [('baseline', baseline_result)] + list(external_results.items())
        
        best_result = None
        best_score = 0
        
        for result_name, result in results_with_baseline:
            accuracy = result['avg']
            if accuracy > best_score:
                best_score = accuracy
                best_result = (result_name, result)
            
            improvement = (accuracy - baseline_result['avg']) * 100
            status = "ğŸ“ˆ" if improvement > 0 else "ğŸ“‰" if improvement < 0 else "ğŸ”·"
            
            logger.info(f"  {status} {result['description']:35s}: {accuracy:.3%} ({improvement:+.2f}%)")
        
        # æœ€é«˜çµæœã®è©³ç´°
        logger.info(f"\nğŸ† æœ€é«˜ç²¾åº¦:")
        logger.info(f"  æ‰‹æ³•: {best_result[1]['description']}")
        logger.info(f"  ç²¾åº¦: {best_result[1]['avg']:.3%} Â± {best_result[1]['std']:.3%}")
        logger.info(f"  å‘ä¸Š: {(best_result[1]['avg'] - baseline_result['avg']) * 100:+.2f}%")
        
        # ç›®æ¨™é”æˆç¢ºèª
        target_52 = 0.52
        target_53 = 0.53
        
        if best_result[1]['avg'] >= target_53:
            logger.info(f"ğŸ‰ ç›®æ¨™é”æˆï¼ 53%è¶…ãˆ ({best_result[1]['avg']:.1%} >= 53.0%)")
        elif best_result[1]['avg'] >= target_52:
            logger.info(f"âœ… è‰¯å¥½ãªçµæœï¼ 52%è¶…ãˆ ({best_result[1]['avg']:.1%} >= 52.0%)")
        else:
            logger.info(f"ğŸ“ˆ æ”¹å–„åŠ¹æœã‚ã‚Š ({best_result[1]['avg']:.1%} vs ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³{baseline_result['avg']:.1%})")
        
        # æœ€é«˜ç²¾åº¦è¨­å®šã§ã®ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ
        if best_result[0] != 'baseline':
            logger.info(f"\nğŸ” æœ€é«˜ç²¾åº¦è¨­å®šã§ã®ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ...")
            if best_result[0] == 'baseline_plus_all_external':
                best_features = evaluator.baseline_features + external_features_dict['all']
            elif best_result[0] == 'baseline_plus_values':
                best_features = evaluator.baseline_features + external_features_dict['value']
            elif best_result[0] == 'baseline_plus_changes':
                best_features = evaluator.baseline_features + external_features_dict['change']
            else:  # external_only
                best_features = external_features_dict['value']
            
            evaluator.feature_importance_analysis(df, best_features)
        
        logger.info(f"\nğŸ’¡ çµè«–:")
        improvement_pct = (best_result[1]['avg'] - baseline_result['avg']) * 100
        if improvement_pct > 1.0:
            logger.info(f"âœ… å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã¯æœ‰åŠ¹ï¼ {improvement_pct:.2f}%ã®ç²¾åº¦å‘ä¸Š")
        elif improvement_pct > 0.5:
            logger.info(f"ğŸ“ˆ å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã¯æœ‰ç›Šï¼ {improvement_pct:.2f}%ã®ç²¾åº¦å‘ä¸Š")
        elif improvement_pct > 0:
            logger.info(f"ğŸ“Š å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã¯å¾®å¢—åŠ¹æœï¼ {improvement_pct:.2f}%ã®ç²¾åº¦å‘ä¸Š")
        else:
            logger.info(f"âš ï¸ å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã®åŠ¹æœé™å®šçš„ ({improvement_pct:.2f}%)")
        
        logger.info(f"\nâš–ï¸ ã“ã®çµæœã¯å…¨ãƒ‡ãƒ¼ã‚¿{len(df):,}ä»¶ã§ã®å³å¯†ãª5åˆ†å‰²æ™‚ç³»åˆ—æ¤œè¨¼ã§ã™")
        
    except Exception as e:
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()