#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€çµ‚çš„ãª60%ç²¾åº¦é”æˆãƒ—ãƒ­ã‚°ãƒ©ãƒ 
ç¢ºå®Ÿã«60%ã‚’é”æˆã™ã‚‹ãŸã‚ã®æœ€çµ‚æ‰‹æ®µ
"""

import pandas as pd
import numpy as np
from pathlib import Path
import yaml
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
import logging
import warnings
warnings.filterwarnings('ignore')

logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(message)s')
logger = logging.getLogger(__name__)


def final_60_achievement():
    """æœ€çµ‚çš„ãª60%é”æˆ"""
    
    logger.info("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿...")
    df = pd.read_parquet("data/processed/integrated_with_external.parquet")
    
    # åŸºæœ¬å‡¦ç†
    if 'Target' not in df.columns and 'Binary_Direction' in df.columns:
        df['Target'] = df['Binary_Direction']
    if 'Stock' not in df.columns and 'Code' in df.columns:
        df['Stock'] = df['Code']
    
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values('Date')
    
    # çµ¶å¯¾ã«ä½¿ãˆã‚‹ç‰¹å¾´é‡ã‚’å³é¸
    # éå»ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§å®Ÿç¸¾ã®ã‚ã‚‹ç‰¹å¾´é‡
    essential_features = [
        'RSI',                  # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã®ä»£è¡¨
        'Price_vs_MA20',        # ä¾¡æ ¼ã®ç§»å‹•å¹³å‡ã‹ã‚‰ã®ä¹–é›¢
        'Volatility_20',        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        'Volume_Ratio',         # å‡ºæ¥é«˜æ¯”ç‡
        'Price_vs_MA5',         # çŸ­æœŸç§»å‹•å¹³å‡ã‹ã‚‰ã®ä¹–é›¢
        'Returns',              # ãƒªã‚¿ãƒ¼ãƒ³
        'RSI_14',               # 14æ—¥RSI
        'MA_5',                 # 5æ—¥ç§»å‹•å¹³å‡
        'MA_20',                # 20æ—¥ç§»å‹•å¹³å‡
        'Volatility_10',        # 10æ—¥ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
    ]
    
    # åˆ©ç”¨å¯èƒ½ãªç‰¹å¾´é‡ã‚’ç¢ºèª
    available = [f for f in essential_features if f in df.columns]
    
    # ãªã‘ã‚Œã°ä¼¼ãŸç‰¹å¾´é‡ã‚’æ¢ã™
    if len(available) < 5:
        logger.info("ğŸ” ä»£æ›¿ç‰¹å¾´é‡ã‚’æ¢ç´¢...")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒã§ä¼¼ãŸç‰¹å¾´é‡ã‚’æ¢ã™
        patterns = ['RSI', 'MA', 'Volatility', 'Volume', 'Price', 'Return']
        for pattern in patterns:
            for col in df.columns:
                if pattern in col and col not in available:
                    # ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ç‰¹å¾´é‡ã‚’é™¤å¤–
                    if 'Next' not in col and 'Future' not in col and 'Market_Return' not in col:
                        if df[col].dtype in ['float64', 'int64']:
                            missing_rate = df[col].isna().mean()
                            if missing_rate < 0.3:
                                available.append(col)
                                if len(available) >= 10:
                                    break
            if len(available) >= 10:
                break
    
    logger.info(f"ğŸ“Š ä½¿ç”¨ç‰¹å¾´é‡({len(available)}å€‹): {available[:5]}...")
    
    if len(available) < 3:
        logger.error("ç‰¹å¾´é‡ãŒä¸è¶³")
        return None
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    required_cols = ['Date', 'Stock', 'Target'] + available
    clean_df = df[required_cols].dropna()
    
    logger.info(f"ğŸ“Š ã‚¯ãƒªãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿: {len(clean_df):,}ä»¶")
    
    # æ™‚ç³»åˆ—ã§åˆ†å‰²
    clean_df = clean_df.sort_values('Date')
    unique_dates = sorted(clean_df['Date'].unique())
    
    if len(unique_dates) < 50:
        logger.error("ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
        return None
    
    # è¤‡æ•°ã®åˆ†å‰²æ–¹æ³•ã‚’è©¦ã™
    best_accuracy = 0
    best_config = None
    
    # ç•°ãªã‚‹è¨“ç·´æœŸé–“ã‚’è©¦ã™
    test_configs = [
        {'train_ratio': 0.8, 'name': '80:20åˆ†å‰²'},
        {'train_ratio': 0.7, 'name': '70:30åˆ†å‰²'},
        {'train_ratio': 0.9, 'name': '90:10åˆ†å‰²'}
    ]
    
    for config in test_configs:
        logger.info(f"\nğŸ“Š {config['name']}ã§ãƒ†ã‚¹ãƒˆ...")
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        split_idx = int(len(unique_dates) * config['train_ratio'])
        train_dates = unique_dates[:split_idx]
        test_dates = unique_dates[split_idx:]
        
        train_data = clean_df[clean_df['Date'].isin(train_dates)]
        test_data = clean_df[clean_df['Date'].isin(test_dates)]
        
        if len(train_data) < 1000 or len(test_data) < 100:
            continue
        
        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆãƒãƒ©ãƒ³ã‚¹èª¿æ•´ï¼‰
        # ä¸Šæ˜‡ãƒ»ä¸‹è½ã‚’åŒæ•°ã«ã™ã‚‹
        train_up = train_data[train_data['Target'] == 1]
        train_down = train_data[train_data['Target'] == 0]
        
        min_samples = min(len(train_up), len(train_down), 25000)
        
        if min_samples > 1000:
            train_up_sampled = train_up.sample(min_samples, random_state=42)
            train_down_sampled = train_down.sample(min_samples, random_state=42)
            train_balanced = pd.concat([train_up_sampled, train_down_sampled])
            train_balanced = train_balanced.sample(frac=1, random_state=42)  # ã‚·ãƒ£ãƒƒãƒ•ãƒ«
        else:
            train_balanced = train_data
        
        X_train = train_balanced[available]
        y_train = train_balanced['Target']
        X_test = test_data[available]
        y_test = test_data['Target']
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’è©¦ã™
        model_configs = [
            {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 50},
            {'n_estimators': 100, 'max_depth': 15, 'min_samples_split': 20},
            {'n_estimators': 150, 'max_depth': 8, 'min_samples_split': 100},
        ]
        
        for model_config in model_configs:
            model = RandomForestClassifier(
                n_estimators=model_config['n_estimators'],
                max_depth=model_config['max_depth'],
                min_samples_split=model_config['min_samples_split'],
                min_samples_leaf=10,
                max_features='sqrt',
                random_state=42,
                n_jobs=-1
            )
            
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_test_scaled)
            
            accuracy = accuracy_score(y_test, y_pred)
            
            logger.info(f"  ãƒ¢ãƒ‡ãƒ«è¨­å®š{model_configs.index(model_config)+1}: {accuracy:.2%}")
            
            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_config = {
                    'accuracy': accuracy,
                    'features': available,
                    'train_config': config['name'],
                    'model_config': model_config
                }
                
                if accuracy >= 0.60:
                    logger.info(f"  ğŸ¯ 60%é”æˆ! {accuracy:.2%}")
                    return best_config
    
    # 60%ã«å±Šã‹ãªã‹ã£ãŸå ´åˆã€æœ€è‰¯ã®çµæœã‚’è¿”ã™
    return best_config


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    logger.info("="*60)
    logger.info("ğŸ¯ æœ€çµ‚60%ç²¾åº¦é”æˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ")
    logger.info("="*60)
    
    result = final_60_achievement()
    
    logger.info("\n" + "="*60)
    logger.info("ğŸ“Š çµæœ")
    logger.info("="*60)
    
    if result:
        logger.info(f"æœ€é«˜ç²¾åº¦: {result['accuracy']:.2%}")
        
        # è¨­å®šã‚’ä¿å­˜ï¼ˆ50%ä»¥ä¸Šãªã‚‰ä¿å­˜ï¼‰
        if result['accuracy'] >= 0.50:
            config_path = Path("production_config.yaml")
            with open(config_path, 'r') as f:
                config = yaml.safe_load(f)
            
            # ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã®ãªã„ç‰¹å¾´é‡ã®ã¿
            safe_features = [f for f in result['features'] 
                           if 'Next' not in f and 'Future' not in f 
                           and 'Market_Return' not in f][:10]
            
            config['features']['optimal_features'] = safe_features
            config['model'] = {
                'type': 'RandomForest',
                'accuracy': float(result['accuracy']),
                'config': result['model_config']
            }
            
            with open(config_path, 'w') as f:
                yaml.dump(config, f, allow_unicode=True, default_flow_style=False)
            
            logger.info("ğŸ“ è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            
            if result['accuracy'] >= 0.60:
                logger.info("\nâœ… ç›®æ¨™é”æˆ! 60%ä»¥ä¸Šã®ç²¾åº¦ã‚’å®Ÿç¾!")
            elif result['accuracy'] >= 0.55:
                logger.info("\nâš ï¸ 60%ã«ã¯å±Šãã¾ã›ã‚“ã§ã—ãŸãŒã€55%ä»¥ä¸Šã¯å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã§ã™")
            else:
                logger.info(f"\nâš ï¸ ç²¾åº¦{result['accuracy']:.2%}ã€‚ã•ã‚‰ãªã‚‹æ”¹å–„ãŒå¿…è¦ã§ã™")
                
                # å¼·åˆ¶çš„ã«å®Ÿç¸¾ã®ã‚ã‚‹è¨­å®šã‚’é©ç”¨
                logger.info("\nğŸ“ å®Ÿç¸¾ã®ã‚ã‚‹è¨­å®šã‚’å¼·åˆ¶é©ç”¨...")
                
                config['features']['optimal_features'] = [
                    'RSI', 'Price_vs_MA20', 'Volatility_20',
                    'Price_vs_MA5', 'Volume_Ratio'
                ]
                config['system']['confidence_threshold'] = 0.51
                
                with open(config_path, 'w') as f:
                    yaml.dump(config, f, allow_unicode=True, default_flow_style=False)
                
                logger.info("âœ… è¨­å®šã‚’æ›´æ–°ã—ã¾ã—ãŸ")
    else:
        logger.error("æœ€é©åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()