#!/usr/bin/env python3
"""
J-Quants ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—
ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ãƒ—ãƒ©ãƒ³å¯¾å¿œ
"""

import pandas as pd
import numpy as np
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from loguru import logger
import time
from jquants_auth import JQuantsAuth

class JQuantsFundamental:
    """J-Quants ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, auth: JQuantsAuth):
        self.auth = auth
        self.base_url = "https://api.jquants.com"
        
    def get_listed_companies(self, date: str = None) -> pd.DataFrame:
        """ä¸Šå ´éŠ˜æŸ„ä¸€è¦§å–å¾—"""
        url = f"{self.base_url}/v1/listed/info"
        headers = self.auth.get_headers()
        
        params = {}
        if date:
            params['date'] = date
        
        try:
            response = requests.get(url, headers=headers, params=params)
            response.raise_for_status()
            data = response.json()
            
            if 'info' in data and data['info']:
                df = pd.DataFrame(data['info'])
                logger.info(f"âœ… ä¸Šå ´éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿å–å¾—: {len(df)}ä»¶")
                return df
            else:
                logger.warning("ä¸Šå ´éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"âŒ ä¸Šå ´éŠ˜æŸ„å–å¾—å¤±æ•—: {e}")
            return pd.DataFrame()
    
    def get_financial_statements(self, code: str, from_date: str, to_date: str) -> pd.DataFrame:
        """è²¡å‹™æƒ…å ±å–å¾—ï¼ˆå˜ä¸€éŠ˜æŸ„ï¼‰"""
        url = f"{self.base_url}/v1/fins/statements"
        headers = self.auth.get_headers()
        
        params = {
            'code': code,
            'from': from_date,
            'to': to_date
        }
        
        all_data = []
        pagination_key = None
        
        try:
            while True:
                if pagination_key:
                    params['pagination_key'] = pagination_key
                
                response = requests.get(url, headers=headers, params=params)
                response.raise_for_status()
                data = response.json()
                
                if 'statements' in data and data['statements']:
                    all_data.extend(data['statements'])
                
                # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ç¢ºèª
                pagination_key = data.get('pagination_key')
                if not pagination_key:
                    break
                
                # APIåˆ¶é™å¯¾ç­–
                time.sleep(0.1)
            
            if all_data:
                df = pd.DataFrame(all_data)
                logger.debug(f"éŠ˜æŸ„{code}: è²¡å‹™ãƒ‡ãƒ¼ã‚¿{len(df)}ä»¶å–å¾—")
                return df
            else:
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"âŒ éŠ˜æŸ„{code}ã®è²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {e}")
            return pd.DataFrame()
    
    def get_bulk_financial_data(self, stock_codes: List[str], from_date: str, to_date: str) -> pd.DataFrame:
        """è¤‡æ•°éŠ˜æŸ„ã®è²¡å‹™ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å–å¾—"""
        logger.info(f"ğŸ”„ è²¡å‹™ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å–å¾—é–‹å§‹: {len(stock_codes)}éŠ˜æŸ„")
        
        all_financial_data = []
        processed = 0
        
        for code in stock_codes:
            try:
                df = self.get_financial_statements(code, from_date, to_date)
                if not df.empty:
                    all_financial_data.append(df)
                
                processed += 1
                if processed % 50 == 0:
                    logger.info(f"  é€²æ—: {processed}/{len(stock_codes)} ({processed/len(stock_codes)*100:.1f}%)")
                
                # APIåˆ¶é™å¯¾ç­–
                time.sleep(0.2)
                
            except Exception as e:
                logger.warning(f"éŠ˜æŸ„{code}ã‚’ã‚¹ã‚­ãƒƒãƒ—: {e}")
                continue
        
        if all_financial_data:
            combined_df = pd.concat(all_financial_data, ignore_index=True)
            logger.success(f"âœ… è²¡å‹™ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å–å¾—å®Œäº†: {len(combined_df)}ä»¶")
            return combined_df
        else:
            logger.warning("è²¡å‹™ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return pd.DataFrame()
    
    def process_fundamental_features(self, financial_df: pd.DataFrame) -> pd.DataFrame:
        """è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´é‡ã‚’ç”Ÿæˆ"""
        if financial_df.empty:
            return pd.DataFrame()
        
        logger.info("ğŸ”§ ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ç‰¹å¾´é‡ç”Ÿæˆä¸­...")
        
        # å¿…è¦ãªåˆ—ã®å­˜åœ¨ç¢ºèª
        required_cols = ['Local Code', 'Disclosed Date', 'TypeOfDocument', 'TypeOfCurrentPeriod']
        missing_cols = [col for col in required_cols if col not in financial_df.columns]
        if missing_cols:
            logger.warning(f"å¿…è¦ãªåˆ—ãŒä¸è¶³: {missing_cols}")
            return pd.DataFrame()
        
        # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
        df = financial_df.copy()
        
        # æ—¥ä»˜å¤‰æ›
        df['Date'] = pd.to_datetime(df['Disclosed Date'])
        df['Stock'] = df['Local Code'].astype(str)
        
        # æœ€æ–°ã®å››åŠæœŸãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ½å‡º
        df = df[df['TypeOfDocument'] == 'FY']  # é€šæœŸæ±ºç®—ã®ã¿
        df = df[df['TypeOfCurrentPeriod'] == 'Actual']  # å®Ÿç¸¾å€¤ã®ã¿
        
        # é‡è¤‡å‰Šé™¤ï¼ˆæœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å„ªå…ˆï¼‰
        df = df.sort_values(['Stock', 'Date']).groupby('Stock').tail(1)
        
        # ç‰¹å¾´é‡ç”Ÿæˆ
        features_df = pd.DataFrame()
        features_df['Stock'] = df['Stock']
        features_df['Date'] = df['Date']
        
        # 1. PERï¼ˆæ ªä¾¡åç›Šç‡ï¼‰
        if 'ForecastPER' in df.columns:
            features_df['PER'] = pd.to_numeric(df['ForecastPER'], errors='coerce')
        
        # 2. PBRï¼ˆæ ªä¾¡ç´”è³‡ç”£å€ç‡ï¼‰
        if 'ForecastPBR' in df.columns:
            features_df['PBR'] = pd.to_numeric(df['ForecastPBR'], errors='coerce')
        
        # 3. ROEï¼ˆè‡ªå·±è³‡æœ¬åˆ©ç›Šç‡ï¼‰
        if 'ROE' in df.columns:
            features_df['ROE'] = pd.to_numeric(df['ROE'], errors='coerce')
        
        # 4. ROAï¼ˆç·è³‡ç”£åˆ©ç›Šç‡ï¼‰
        if 'ROA' in df.columns:
            features_df['ROA'] = pd.to_numeric(df['ROA'], errors='coerce')
        
        # 5. EPSï¼ˆ1æ ªå½“ãŸã‚Šç´”åˆ©ç›Šï¼‰
        if 'ForecastEPS' in df.columns:
            features_df['EPS'] = pd.to_numeric(df['ForecastEPS'], errors='coerce')
        
        # 6. å–¶æ¥­åˆ©ç›Šç‡
        if 'OperatingProfitMargin' in df.columns:
            features_df['Operating_Margin'] = pd.to_numeric(df['OperatingProfitMargin'], errors='coerce')
        
        # 7. è‡ªå·±è³‡æœ¬æ¯”ç‡
        if 'EquityRatio' in df.columns:
            features_df['Equity_Ratio'] = pd.to_numeric(df['EquityRatio'], errors='coerce')
        
        # 8. äºˆæƒ³é…å½“åˆ©å›ã‚Š
        if 'ForecastDividendYield' in df.columns:
            features_df['Dividend_Yield'] = pd.to_numeric(df['ForecastDividendYield'], errors='coerce')
        
        # 9. æ™‚ä¾¡ç·é¡ï¼ˆå¯¾æ•°å¤‰æ›ï¼‰
        if 'MarketCapitalization' in df.columns:
            market_cap = pd.to_numeric(df['MarketCapitalization'], errors='coerce')
            features_df['Log_Market_Cap'] = np.log1p(market_cap.fillna(0))
        
        # 10. æµå‹•æ¯”ç‡
        if 'CurrentRatio' in df.columns:
            features_df['Current_Ratio'] = pd.to_numeric(df['CurrentRatio'], errors='coerce')
        
        # æ¬ æå€¤å‡¦ç†
        numeric_cols = features_df.select_dtypes(include=[np.number]).columns
        features_df[numeric_cols] = features_df[numeric_cols].fillna(features_df[numeric_cols].median())
        
        # ç•°å¸¸å€¤å‡¦ç†ï¼ˆ99.5%ã‚¿ã‚¤ãƒ«å€¤ã§ã‚­ãƒ£ãƒƒãƒ—ï¼‰
        for col in numeric_cols:
            if col not in ['Stock', 'Date']:
                upper_bound = features_df[col].quantile(0.995)
                lower_bound = features_df[col].quantile(0.005)
                features_df[col] = features_df[col].clip(lower_bound, upper_bound)
        
        logger.success(f"âœ… ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {len(features_df)}éŠ˜æŸ„, {len(features_df.columns)-2}ç‰¹å¾´é‡")
        
        # ç”Ÿæˆã•ã‚ŒãŸç‰¹å¾´é‡ã®çµ±è¨ˆæƒ…å ±
        logger.info("ğŸ“Š ç”Ÿæˆã•ã‚ŒãŸç‰¹å¾´é‡:")
        feature_cols = [col for col in features_df.columns if col not in ['Stock', 'Date']]
        for col in feature_cols:
            if not features_df[col].empty:
                mean_val = features_df[col].mean()
                std_val = features_df[col].std()
                logger.info(f"  {col}: å¹³å‡{mean_val:.2f}, æ¨™æº–åå·®{std_val:.2f}")
        
        return features_df
    
    def save_fundamental_data(self, df: pd.DataFrame, filename: str = "fundamental_data.parquet"):
        """ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        try:
            df.to_parquet(filename)
            logger.success(f"âœ… ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {filename}")
            return True
        except Exception as e:
            logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ä¿å­˜å¤±æ•—: {e}")
            return False

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # èªè¨¼
    auth = JQuantsAuth()
    
    if not auth.test_auth():
        logger.error("èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
        exit(1)
    
    # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—
    fundamental = JQuantsFundamental(auth)
    
    # ä¸Šå ´éŠ˜æŸ„ä¸€è¦§å–å¾—
    listed_df = fundamental.get_listed_companies()
    
    if not listed_df.empty:
        # ä¸»è¦éŠ˜æŸ„ï¼ˆæ—¥çµŒ225ãªã©ï¼‰ã®ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆä¾‹ï¼š1000-9999ã®4æ¡ã‚³ãƒ¼ãƒ‰ï¼‰
        major_codes = listed_df[
            (listed_df['Local Code'].str.len() == 4) & 
            (listed_df['Local Code'].str.isdigit())
        ]['Local Code'].head(100).tolist()  # ãƒ†ã‚¹ãƒˆç”¨ã«100éŠ˜æŸ„
        
        logger.info(f"å¯¾è±¡éŠ˜æŸ„æ•°: {len(major_codes)}")
        
        # è²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆéå»2å¹´ï¼‰
        from_date = (datetime.now() - timedelta(days=730)).strftime('%Y-%m-%d')
        to_date = datetime.now().strftime('%Y-%m-%d')
        
        financial_df = fundamental.get_bulk_financial_data(major_codes, from_date, to_date)
        
        if not financial_df.empty:
            # ç‰¹å¾´é‡ç”Ÿæˆ
            features_df = fundamental.process_fundamental_features(financial_df)
            
            # ä¿å­˜
            if not features_df.empty:
                fundamental.save_fundamental_data(features_df)
            else:
                logger.warning("ç‰¹å¾´é‡ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        else:
            logger.warning("è²¡å‹™ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
    else:
        logger.error("ä¸Šå ´éŠ˜æŸ„ä¸€è¦§ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")