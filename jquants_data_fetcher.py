#!/usr/bin/env python3
"""
J-Quants API å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—ã‚·ã‚¹ãƒ†ãƒ 
å®Ÿéš›ã®æ—¥æœ¬æ ªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦AIäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã«çµ±åˆ
"""

import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time
import os
from loguru import logger
import json

class JQuantsDataFetcher:
    def __init__(self):
        self.base_url = "https://api.jquants.com"
        self.id_token = None
        self.refresh_token = None
        
        # èªè¨¼æƒ…å ±ï¼ˆ.envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—ï¼‰
        from dotenv import load_dotenv
        load_dotenv()
        
        self.email = os.getenv('JQUANTS_MAIL_ADDRESS')  # .envãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚­ãƒ¼åã«åˆã‚ã›ã‚‹
        self.password = os.getenv('JQUANTS_PASSWORD')
        self.refresh_token = os.getenv('JQUANTS_REFRESH_TOKEN')  # æ—¢å­˜ã®ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³ã‚‚èª­ã¿è¾¼ã¿
        
        if not self.email or not self.password:
            logger.warning("âš ï¸ J-Quantsèªè¨¼æƒ…å ±ãŒ.envãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            logger.info(".envãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã‚’è¨­å®šã—ã¦ãã ã•ã„:")
            logger.info("JQUANTS_MAIL_ADDRESS=your-email@example.com")
            logger.info("JQUANTS_PASSWORD=your-password")
    
    def authenticate(self):
        """J-Quants APIã®èªè¨¼ã‚’å®Ÿè¡Œ"""
        try:
            # 1. ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—
            auth_url = f"{self.base_url}/v1/token/auth_user"
            auth_data = {
                "mailaddress": self.email,
                "password": self.password
            }
            
            logger.info("ğŸ” J-Quantsèªè¨¼é–‹å§‹...")
            response = requests.post(auth_url, json=auth_data)
            
            if response.status_code == 200:
                self.refresh_token = response.json()['refreshToken']
                logger.success("âœ… ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—æˆåŠŸ")
            else:
                logger.error(f"âŒ èªè¨¼å¤±æ•—: {response.status_code} - {response.text}")
                return False
            
            # 2. IDãƒˆãƒ¼ã‚¯ãƒ³å–å¾—
            id_token_url = f"{self.base_url}/v1/token/auth_refresh"
            params = {"refreshtoken": self.refresh_token}
            
            response = requests.post(id_token_url, params=params)
            
            if response.status_code == 200:
                self.id_token = response.json()['idToken']
                logger.success("âœ… IDãƒˆãƒ¼ã‚¯ãƒ³å–å¾—æˆåŠŸï¼ˆ24æ™‚é–“æœ‰åŠ¹ï¼‰")
                return True
            else:
                logger.error(f"âŒ IDãƒˆãƒ¼ã‚¯ãƒ³å–å¾—å¤±æ•—: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def get_headers(self):
        """APIãƒªã‚¯ã‚¨ã‚¹ãƒˆç”¨ãƒ˜ãƒƒãƒ€ãƒ¼"""
        return {
            "Authorization": f"Bearer {self.id_token}",
            "Content-Type": "application/json"
        }
    
    def get_listed_companies(self):
        """ä¸Šå ´éŠ˜æŸ„ä¸€è¦§å–å¾—"""
        try:
            url = f"{self.base_url}/v1/listed/info"
            headers = self.get_headers()
            
            logger.info("ğŸ“‹ ä¸Šå ´éŠ˜æŸ„ä¸€è¦§å–å¾—ä¸­...")
            response = requests.get(url, headers=headers)
            
            if response.status_code == 200:
                data = response.json()
                companies_df = pd.DataFrame(data['info'])
                logger.success(f"âœ… {len(companies_df)}ç¤¾ã®éŠ˜æŸ„æƒ…å ±å–å¾—å®Œäº†")
                return companies_df
            else:
                logger.error(f"âŒ éŠ˜æŸ„ä¸€è¦§å–å¾—å¤±æ•—: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ éŠ˜æŸ„ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_stock_prices(self, code, from_date, to_date):
        """æŒ‡å®šéŠ˜æŸ„ã®æ ªä¾¡å–å¾—"""
        try:
            url = f"{self.base_url}/v1/prices/daily_quotes"
            headers = self.get_headers()
            
            params = {
                "code": code,
                "from": from_date,
                "to": to_date
            }
            
            response = requests.get(url, headers=headers, params=params)
            
            if response.status_code == 200:
                data = response.json()
                if 'daily_quotes' in data:
                    return pd.DataFrame(data['daily_quotes'])
                else:
                    return pd.DataFrame()
            else:
                logger.warning(f"âš ï¸ {code}: æ ªä¾¡å–å¾—å¤±æ•— {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ {code} æ ªä¾¡å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_bulk_stock_data(self, stock_codes, years=2):
        """è¤‡æ•°éŠ˜æŸ„ã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬å–å¾—"""
        try:
            end_date = datetime.now().date()
            start_date = end_date - timedelta(days=years * 365)
            
            all_data = []
            total_codes = len(stock_codes)
            
            logger.info(f"ğŸ“Š {total_codes}éŠ˜æŸ„ã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹")
            logger.info(f"æœŸé–“: {start_date} ï½ {end_date}")
            
            for i, code in enumerate(stock_codes):
                logger.info(f"å–å¾—ä¸­: {code} ({i+1}/{total_codes})")
                
                stock_data = self.get_stock_prices(
                    code, 
                    start_date.strftime('%Y-%m-%d'),
                    end_date.strftime('%Y-%m-%d')
                )
                
                if stock_data is not None and not stock_data.empty:
                    stock_data['Code'] = code
                    all_data.append(stock_data)
                    logger.debug(f"âœ… {code}: {len(stock_data)}æ—¥åˆ†")
                else:
                    logger.warning(f"âš ï¸ {code}: ãƒ‡ãƒ¼ã‚¿ãªã—")
                
                # APIãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ
                time.sleep(0.1)
            
            if all_data:
                combined_df = pd.concat(all_data, ignore_index=True)
                logger.success(f"âœ… å…¨{len(combined_df)}ä»¶ã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†")
                return combined_df
            else:
                logger.error("âŒ å–å¾—ã§ããŸæ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return None
                
        except Exception as e:
            logger.error(f"âŒ ä¸€æ‹¬æ ªä¾¡å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_nikkei225_stocks(self):
        """æ—¥çµŒ225æ§‹æˆéŠ˜æŸ„ã®ã‚³ãƒ¼ãƒ‰å–å¾—"""
        # ä¸»è¦æ—¥çµŒ225æ§‹æˆéŠ˜æŸ„ï¼ˆå®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ï¼‰
        nikkei225_codes = [
            # ä¸»è¦æ§‹æˆéŠ˜æŸ„
            "7203",  # ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Š
            "9984",  # ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯ã‚°ãƒ«ãƒ¼ãƒ—
            "6098",  # ãƒªã‚¯ãƒ«ãƒ¼ãƒˆãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹
            "8306",  # ä¸‰è±UFJãƒ•ã‚£ãƒŠãƒ³ã‚·ãƒ£ãƒ«ãƒ»ã‚°ãƒ«ãƒ¼ãƒ—
            "9434",  # ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯
            "4063",  # ä¿¡è¶ŠåŒ–å­¦å·¥æ¥­
            "6861",  # ã‚­ãƒ¼ã‚¨ãƒ³ã‚¹
            "8035",  # æ±äº¬ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ³
            "6954",  # ãƒ•ã‚¡ãƒŠãƒƒã‚¯
            "9432",  # æ—¥æœ¬é›»ä¿¡é›»è©±
            "4519",  # ä¸­å¤–è£½è–¬
            "7974",  # ä»»å¤©å ‚
            "6367",  # ãƒ€ã‚¤ã‚­ãƒ³å·¥æ¥­
            "4523",  # ã‚¨ãƒ¼ã‚¶ã‚¤
            "8411",  # ã¿ãšã»ãƒ•ã‚£ãƒŠãƒ³ã‚·ãƒ£ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—
            "7741",  # HOYA
            "9983",  # ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆãƒªãƒ†ã‚¤ãƒªãƒ³ã‚°
            "8316",  # ä¸‰äº•ä½å‹ãƒ•ã‚£ãƒŠãƒ³ã‚·ãƒ£ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—
            "6902",  # ãƒ‡ãƒ³ã‚½ãƒ¼
            "4578",  # å¤§å¡šãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹
            "6273",  # SMC
            "4568",  # ç¬¬ä¸€ä¸‰å…±
            "6758",  # ã‚½ãƒ‹ãƒ¼ã‚°ãƒ«ãƒ¼ãƒ—
            "8001",  # ä¼Šè—¤å¿ å•†äº‹
            "3382",  # ã‚»ãƒ–ãƒ³&ã‚¢ã‚¤ãƒ»ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹
            "4661",  # ã‚ªãƒªã‚¨ãƒ³ã‚¿ãƒ«ãƒ©ãƒ³ãƒ‰
            "8058",  # ä¸‰è±å•†äº‹
            "9020",  # æ±æ—¥æœ¬æ—…å®¢é‰„é“
            "4502",  # æ­¦ç”°è–¬å“å·¥æ¥­
            "7267",  # æœ¬ç”°æŠ€ç ”å·¥æ¥­
            "4478",  # ãƒ•ãƒªãƒ¼
            "6501",  # æ—¥ç«‹è£½ä½œæ‰€
            "4005",  # ä½å‹åŒ–å­¦
            "9301",  # ä¸‰è±å€‰åº«
            "8031",  # ä¸‰äº•ç‰©ç”£
        ]
        return nikkei225_codes
    
    def get_financial_statements(self, stock_codes, years=3):
        """è²¡å‹™æƒ…å ±ã‚’å–å¾—"""
        try:
            end_date = datetime.now().date()
            start_date = end_date - timedelta(days=years * 365)
            
            all_financial_data = []
            
            logger.info(f"ğŸ“Š è²¡å‹™æƒ…å ±å–å¾—é–‹å§‹: {len(stock_codes)}éŠ˜æŸ„")
            
            for i, code in enumerate(stock_codes):
                logger.info(f"è²¡å‹™å–å¾—ä¸­: {code} ({i+1}/{len(stock_codes)})")
                
                url = f"{self.base_url}/v1/fins/statements"
                headers = self.get_headers()
                params = {
                    "code": code,
                    "from": start_date.strftime('%Y-%m-%d'),
                    "to": end_date.strftime('%Y-%m-%d')
                }
                
                response = requests.get(url, headers=headers, params=params)
                
                if response.status_code == 200:
                    data = response.json()
                    if 'statements' in data and data['statements']:
                        financial_df = pd.DataFrame(data['statements'])
                        financial_df['Code'] = code
                        all_financial_data.append(financial_df)
                        logger.debug(f"âœ… {code}: {len(financial_df)}ä»¶ã®è²¡å‹™ãƒ‡ãƒ¼ã‚¿")
                    else:
                        logger.warning(f"âš ï¸ {code}: è²¡å‹™ãƒ‡ãƒ¼ã‚¿ãªã—")
                else:
                    logger.warning(f"âš ï¸ {code}: è²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•— {response.status_code}")
                
                time.sleep(0.1)  # APIåˆ¶é™å¯¾å¿œ
            
            if all_financial_data:
                combined_financial = pd.concat(all_financial_data, ignore_index=True)
                logger.success(f"âœ… è²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(combined_financial)}ä»¶")
                return combined_financial
            else:
                logger.warning("âš ï¸ è²¡å‹™ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return None
                
        except Exception as e:
            logger.error(f"âŒ è²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_market_indices(self, years=3):
        """å¸‚å ´æŒ‡æ•°ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            end_date = datetime.now().date()
            start_date = end_date - timedelta(days=years * 365)
            
            # TOPIXå–å¾—
            url = f"{self.base_url}/v1/indices/topix"
            headers = self.get_headers()
            params = {
                "from": start_date.strftime('%Y-%m-%d'),
                "to": end_date.strftime('%Y-%m-%d')
            }
            
            logger.info("ğŸ“ˆ TOPIXæŒ‡æ•°ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
            response = requests.get(url, headers=headers, params=params)
            
            if response.status_code == 200:
                data = response.json()
                if 'topix' in data:
                    topix_df = pd.DataFrame(data['topix'])
                    topix_df['Date'] = pd.to_datetime(topix_df['Date'])
                    logger.success(f"âœ… TOPIX ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(topix_df)}ä»¶")
                    return topix_df
                else:
                    return pd.DataFrame()
            else:
                logger.error(f"âŒ TOPIXå–å¾—å¤±æ•—: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ å¸‚å ´æŒ‡æ•°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def create_enhanced_dataset(self, output_path="data/processed/enhanced_jquants_data.parquet"):
        """J-Quantså…¨ãƒ‡ãƒ¼ã‚¿ + Yahoo Financeçµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ"""
        try:
            if not self.authenticate():
                return False
            
            # æ—¥çµŒ225ä¸»è¦éŠ˜æŸ„å–å¾—
            stock_codes = self.get_nikkei225_stocks()
            logger.info(f"å¯¾è±¡éŠ˜æŸ„: {len(stock_codes)}éŠ˜æŸ„")
            
            # 1. åŸºæœ¬æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—
            logger.info("ğŸ“Š 1/4: åŸºæœ¬æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
            stock_data = self.get_bulk_stock_data(stock_codes, years=3)
            
            if stock_data is None or stock_data.empty:
                logger.error("âŒ æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            # 2. æŠ€è¡“æŒ‡æ¨™è¿½åŠ 
            logger.info("ğŸ“Š 2/4: æŠ€è¡“æŒ‡æ¨™è¨ˆç®—ä¸­...")
            stock_data = self.add_technical_indicators(stock_data)
            
            # 3. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆ
            logger.info("ğŸ“Š 3/4: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ä½œæˆä¸­...")
            stock_data = self.create_target_variable(stock_data)
            
            # 4. J-Quantsè¿½åŠ ãƒ‡ãƒ¼ã‚¿å–å¾—
            logger.info("ğŸ“Š 4/4: J-Quantsè¿½åŠ ãƒ‡ãƒ¼ã‚¿çµ±åˆä¸­...")
            
            # è²¡å‹™æƒ…å ±å–å¾—
            financial_data = self.get_financial_statements(stock_codes, years=3)
            
            # TOPIXæŒ‡æ•°å–å¾—
            topix_data = self.get_market_indices(years=3)
            
            # Yahoo Financeå¸‚å ´ãƒ‡ãƒ¼ã‚¿çµ±åˆï¼ˆæ—¢å­˜ã®YahooMarketDataã‚¯ãƒ©ã‚¹ä½¿ç”¨ï¼‰
            try:
                from yahoo_market_data import YahooMarketData
                yahoo_data = YahooMarketData()
                
                logger.info("ğŸŒ Yahoo Finance ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
                market_data_dict = yahoo_data.get_all_market_data(period="3y")
                
                if market_data_dict:
                    market_features = yahoo_data.calculate_market_features(market_data_dict)
                    if not market_features.empty:
                        # æ—¥ä»˜çµ±ä¸€
                        stock_data['Date'] = pd.to_datetime(stock_data['Date']).dt.date
                        market_features['Date'] = pd.to_datetime(market_features['Date'], utc=True).dt.date
                        
                        stock_data = stock_data.merge(market_features, on='Date', how='left')
                        logger.success("âœ… Yahoo Finance ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿çµ±åˆå®Œäº†")
                
            except Exception as e:
                logger.warning(f"âš ï¸ Yahoo Financeçµ±åˆã‚¨ãƒ©ãƒ¼ï¼ˆç¶™ç¶šï¼‰: {e}")
            
            # TOPIXçµ±åˆ
            if topix_data is not None and not topix_data.empty:
                try:
                    topix_data['Date'] = pd.to_datetime(topix_data['Date']).dt.date
                    # TOPIXç‰¹å¾´é‡ã‚’è¿½åŠ 
                    topix_data = topix_data.rename(columns={'Close': 'TOPIX_Close'})
                    stock_data = stock_data.merge(topix_data[['Date', 'TOPIX_Close']], on='Date', how='left')
                    logger.success("âœ… TOPIX ãƒ‡ãƒ¼ã‚¿çµ±åˆå®Œäº†")
                except Exception as e:
                    logger.warning(f"âš ï¸ TOPIXçµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
            
            # è²¡å‹™ãƒ‡ãƒ¼ã‚¿çµ±åˆï¼ˆç°¡ç•¥ç‰ˆï¼‰
            if financial_data is not None and not financial_data.empty:
                try:
                    # æœ€æ–°ã®è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨ï¼ˆå››åŠæœŸãƒ™ãƒ¼ã‚¹ï¼‰
                    latest_financial = financial_data.sort_values(['Code', 'DisclosedDate']).groupby('Code').tail(1)
                    financial_features = latest_financial[['Code', 'NetSales', 'OperatingProfit', 'NetIncome']].copy()
                    stock_data = stock_data.merge(financial_features, on='Code', how='left')
                    logger.success("âœ… è²¡å‹™ãƒ‡ãƒ¼ã‚¿çµ±åˆå®Œäº†")
                except Exception as e:
                    logger.warning(f"âš ï¸ è²¡å‹™ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
            
            # ä¿å­˜
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            stock_data.to_parquet(output_path, index=False)
            
            logger.success(f"âœ… æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†: {output_path}")
            logger.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:")
            logger.info(f"  - ç·ä»¶æ•°: {len(stock_data):,}ä»¶")
            logger.info(f"  - éŠ˜æŸ„æ•°: {stock_data['Code'].nunique()}éŠ˜æŸ„") 
            logger.info(f"  - ç‰¹å¾´é‡æ•°: {len(stock_data.columns)}å€‹")
            logger.info(f"  - æœŸé–“: {stock_data['Date'].min()} ï½ {stock_data['Date'].max()}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def create_real_dataset(self, output_path="data/processed/real_jquants_data.parquet"):
        """åŸºæœ¬ã®J-Quantsãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆå…ƒã®æ©Ÿèƒ½ç¶­æŒï¼‰"""
        try:
            if not self.authenticate():
                return False
                
            # æ—¥çµŒ225ä¸»è¦éŠ˜æŸ„å–å¾—
            stock_codes = self.get_nikkei225_stocks()
            logger.info(f"å¯¾è±¡éŠ˜æŸ„: {len(stock_codes)}éŠ˜æŸ„")
            
            # æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—
            stock_data = self.get_bulk_stock_data(stock_codes, years=3)
            
            if stock_data is None or stock_data.empty:
                logger.error("âŒ æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
            stock_data['Date'] = pd.to_datetime(stock_data['Date'])
            stock_data = stock_data.sort_values(['Code', 'Date'])
            
            # æŠ€è¡“æŒ‡æ¨™è¿½åŠ 
            stock_data = self.add_technical_indicators(stock_data)
            
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆï¼ˆç¿Œæ—¥1%ä¸Šæ˜‡ï¼‰
            stock_data = self.create_target_variable(stock_data)
            
            # ä¿å­˜
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            stock_data.to_parquet(output_path, index=False)
            
            logger.success(f"âœ… å®Ÿãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†: {output_path}")
            logger.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:")
            logger.info(f"  - ç·ä»¶æ•°: {len(stock_data):,}ä»¶")
            logger.info(f"  - éŠ˜æŸ„æ•°: {stock_data['Code'].nunique()}éŠ˜æŸ„")
            logger.info(f"  - æœŸé–“: {stock_data['Date'].min()} ï½ {stock_data['Date'].max()}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ å®Ÿãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def add_technical_indicators(self, df):
        """æŠ€è¡“æŒ‡æ¨™ã‚’è¿½åŠ """
        df = df.copy()
        df = df.sort_values(['Code', 'Date'])
        
        # æ–°ã—ã„åˆ—ã‚’åˆæœŸåŒ–
        df['MA_5'] = None
        df['MA_20'] = None
        df['RSI'] = None
        df['Volatility'] = None
        df['Returns'] = None
        
        for code in df['Code'].unique():
            mask = df['Code'] == code
            code_data = df[mask].copy()
            
            # ç§»å‹•å¹³å‡
            code_data['MA_5'] = code_data['Close'].rolling(5).mean()
            code_data['MA_20'] = code_data['Close'].rolling(20).mean()
            
            # RSI
            delta = code_data['Close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
            rs = gain / loss
            code_data['RSI'] = 100 - (100 / (1 + rs))
            
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            code_data['Volatility'] = code_data['Close'].pct_change().rolling(20).std()
            
            # ä¾¡æ ¼å¤‰åŒ–ç‡
            code_data['Returns'] = code_data['Close'].pct_change()
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’æˆ»ã™
            df.loc[mask, 'MA_5'] = code_data['MA_5'].values
            df.loc[mask, 'MA_20'] = code_data['MA_20'].values
            df.loc[mask, 'RSI'] = code_data['RSI'].values
            df.loc[mask, 'Volatility'] = code_data['Volatility'].values
            df.loc[mask, 'Returns'] = code_data['Returns'].values
        
        return df
    
    def create_target_variable(self, df):
        """ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ä½œæˆï¼ˆç¿Œæ—¥1%ä¸Šæ˜‡ï¼‰"""
        df = df.copy()
        df = df.sort_values(['Code', 'Date'])
        
        # ç¿Œæ—¥ã®é«˜å€¤ã‚’å–å¾—
        df['Next_High'] = df.groupby('Code')['High'].shift(-1)
        
        # ç¿Œæ—¥é«˜å€¤ãŒçµ‚å€¤ã‹ã‚‰1%ä»¥ä¸Šä¸Šæ˜‡ã—ãŸã‹ã©ã†ã‹
        df['Target'] = (df['Next_High'] > df['Close'] * 1.01).astype(int)
        
        return df

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    fetcher = JQuantsDataFetcher()
    
    logger.info("ğŸš€ J-Quantså…¨ãƒ‡ãƒ¼ã‚¿ + Yahoo Financeçµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆé–‹å§‹")
    success = fetcher.create_enhanced_dataset()
    
    if success:
        logger.success("ğŸ‰ æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†ï¼")
        logger.info("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: AIäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã§æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ç²¾åº¦å‘ä¸Š")
    else:
        logger.error("ğŸ’¥ æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå¤±æ•—")

if __name__ == "__main__":
    main()