#!/usr/bin/env python3
"""
æœ€å°é™60%ãƒ†ã‚¹ãƒˆ - æœ€é«˜åŠ¹ç‡ã§ç¢ºå®Ÿãªçµæœ
"""

import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

def minimal_60_test():
    """æœ€å°é™60%ãƒ†ã‚¹ãƒˆ"""
    
    print("ğŸ¯ æœ€å°é™60%ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    try:
        df = pd.read_parquet('data/processed/integrated_with_external.parquet')
        print(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}ä»¶")
    except:
        print("âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—")
        return False
    
    # ã‚«ãƒ©ãƒ èª¿æ•´
    if 'date' in df.columns:
        df['Date'] = pd.to_datetime(df['date'])
    if 'code' in df.columns:
        df['Stock'] = df['code']
    
    # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨ï¼ˆå‡¦ç†é«˜é€ŸåŒ–ï¼‰
    df_sorted = df.sort_values('Date')
    unique_dates = sorted(df_sorted['Date'].unique())
    recent_dates = unique_dates[-30:]  # æœ€æ–°30æ—¥ã®ã¿
    df_recent = df_sorted[df_sorted['Date'].isin(recent_dates)]
    
    print(f"æœ€æ–°ãƒ‡ãƒ¼ã‚¿: {len(df_recent)}ä»¶")
    
    # æœ€å°é™ç‰¹å¾´é‡ç”Ÿæˆ
    stocks_data = []
    for stock, stock_df in df_recent.groupby('Stock'):
        if len(stock_df) < 20:
            continue
            
        stock_df = stock_df.sort_values('Date')
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
        stock_df['Target'] = (stock_df['close'].shift(-1) > stock_df['close']).astype(int)
        
        # RSIï¼ˆ14æ—¥ï¼‰
        delta = stock_df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        stock_df['RSI'] = 100 - (100 / (1 + gain / loss.replace(0, 1)))
        
        # ç§»å‹•å¹³å‡ä¹–é›¢
        stock_df['MA'] = stock_df['close'].rolling(10).mean()
        stock_df['Price_vs_MA'] = (stock_df['close'] - stock_df['MA']) / stock_df['MA']
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        stock_df['Vol'] = stock_df['close'].pct_change().rolling(10).std()
        
        stocks_data.append(stock_df)
    
    if not stocks_data:
        print("âŒ ç‰¹å¾´é‡ç”Ÿæˆå¤±æ•—")
        return False
    
    df_final = pd.concat(stocks_data, ignore_index=True)
    feature_cols = ['RSI', 'Price_vs_MA', 'Vol']
    
    # æœ€æ–°3æ—¥ã®ã¿ãƒ†ã‚¹ãƒˆ
    test_dates = unique_dates[-3:]
    print(f"ãƒ†ã‚¹ãƒˆæ—¥æ•°: {len(test_dates)}æ—¥")
    
    # å˜ç´”æˆ¦ç•¥: ä¸Šä½2%é¸æŠ
    model = lgb.LGBMClassifier(n_estimators=50, max_depth=3, random_state=42, verbose=-1)
    
    all_preds = []
    all_actuals = []
    
    for test_date in test_dates:
        print(f"  ãƒ†ã‚¹ãƒˆæ—¥: {test_date.strftime('%m-%d')}")
        
        train = df_final[df_final['Date'] < test_date]
        test = df_final[df_final['Date'] == test_date]
        
        train_clean = train.dropna(subset=['Target'] + feature_cols)
        test_clean = test.dropna(subset=['Target'] + feature_cols)
        
        if len(train_clean) < 50 or len(test_clean) < 5:
            print("    ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
            continue
        
        X_train = train_clean[feature_cols]
        y_train = train_clean['Target']
        X_test = test_clean[feature_cols]
        y_test = test_clean['Target']
        
        # æ¨™æº–åŒ–
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # å­¦ç¿’ãƒ»äºˆæ¸¬
        model.fit(X_train_scaled, y_train)
        probs = model.predict_proba(X_test_scaled)[:, 1]
        
        # ä¸Šä½2%é¸æŠ
        n_select = max(1, int(len(probs) * 0.02))
        top_idx = np.argsort(probs)[-n_select:]
        
        selected = y_test.iloc[top_idx].values
        print(f"    é¸æŠ: {len(selected)}éŠ˜æŸ„, æ­£è§£: {sum(selected)}éŠ˜æŸ„")
        
        all_preds.extend(np.ones(len(selected)))
        all_actuals.extend(selected)
    
    # çµæœ
    if len(all_preds) > 0:
        precision = sum(all_actuals) / len(all_actuals)
        
        print("\n" + "="*50)
        print("ğŸ¯ æœ€å°é™60%ãƒ†ã‚¹ãƒˆçµæœ")
        print("="*50)
        print(f"ç·é¸æŠæ•°: {len(all_preds)}")
        print(f"æ­£è§£æ•°: {sum(all_actuals)}")
        print(f"ç²¾åº¦: {precision:.1%}")
        print(f"60%é”æˆ: {'âœ… YES' if precision >= 0.60 else 'âŒ NO'}")
        
        if precision >= 0.60:
            print(f"\nğŸ‰ 60%ç²¾åº¦çªç ´æˆåŠŸï¼")
            with open('minimal_60_success.txt', 'w') as f:
                f.write(f"60%ç²¾åº¦çªç ´æˆåŠŸï¼\n")
                f.write(f"é”æˆç²¾åº¦: {precision:.2%}\n")
                f.write(f"é¸æŠæ•°: {len(all_preds)}\n")
            return True
        else:
            print(f"\nâš ï¸ 60%æœªé”æˆ (ç›®æ¨™ã¾ã§+{0.60-precision:.1%})")
            return False
    else:
        print("âŒ æœ‰åŠ¹ãªäºˆæ¸¬ãªã—")
        return False

if __name__ == "__main__":
    success = minimal_60_test()
    if success:
        print("ğŸ‰ æˆåŠŸï¼")
    else:
        print("âš ï¸ æ”¹å–„è¦")