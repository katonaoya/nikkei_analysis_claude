#!/usr/bin/env python3
"""
Precision 60%ä»¥ä¸Šã‚’é”æˆã™ã‚‹ãŸã‚ã®æœ€é©åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã€ç‰¹å¾´é‡ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¾¹åº•çš„ã«æœ€é©åŒ–
"""

import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
import yaml
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score
from sklearn.feature_selection import SelectFromModel, RFE
import lightgbm as lgb
import xgboost as xgb
from catboost import CatBoostClassifier
from loguru import logger
import warnings
warnings.filterwarnings('ignore')

class Precision60Optimizer:
    """Precision 60%ä»¥ä¸Šã‚’é”æˆã™ã‚‹ãŸã‚ã®æœ€é©åŒ–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.best_precision = 0
        self.best_config = None
        self.results = []
        
    def load_data(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        logger.info("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹...")
        df = pd.read_parquet('data/processed/integrated_with_external.parquet')
        
        # ã‚«ãƒ©ãƒ åã®èª¿æ•´
        if 'date' in df.columns:
            df['Date'] = pd.to_datetime(df['date'])
        if 'code' in df.columns:
            df['Stock'] = df['code']
            
        logger.info(f"ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(df):,}ä»¶")
        return df
    
    def generate_advanced_features(self, df):
        """é«˜åº¦ãªç‰¹å¾´é‡ç”Ÿæˆ"""
        logger.info("ğŸ”§ é«˜åº¦ãªç‰¹å¾´é‡ç”Ÿæˆä¸­...")
        features = []
        
        for stock, stock_df in df.groupby('Stock'):
            stock_df = stock_df.sort_values('Date')
            
            # åŸºæœ¬çš„ãªä¾¡æ ¼å¤‰åŒ–
            stock_df['Return'] = stock_df['close'].pct_change()
            stock_df['Log_Return'] = np.log(stock_df['close'] / stock_df['close'].shift(1))
            stock_df['Target'] = (stock_df['close'].shift(-1) > stock_df['close']).astype(int)
            
            # ä¾¡æ ¼é–¢é€£ã®ç‰¹å¾´é‡
            for period in [5, 10, 20, 50]:
                # ç§»å‹•å¹³å‡
                stock_df[f'MA{period}'] = stock_df['close'].rolling(period).mean()
                stock_df[f'Price_vs_MA{period}'] = (stock_df['close'] - stock_df[f'MA{period}']) / stock_df[f'MA{period}']
                
                # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                stock_df[f'Volatility_{period}'] = stock_df['Return'].rolling(period).std()
                
                # æœ€é«˜å€¤ãƒ»æœ€å®‰å€¤ã‹ã‚‰ã®ä½ç½®
                stock_df[f'High_{period}'] = stock_df['high'].rolling(period).max()
                stock_df[f'Low_{period}'] = stock_df['low'].rolling(period).min()
                stock_df[f'Price_Position_{period}'] = (stock_df['close'] - stock_df[f'Low_{period}']) / (stock_df[f'High_{period}'] - stock_df[f'Low_{period}'])
                
            # RSIï¼ˆè¤‡æ•°æœŸé–“ï¼‰
            for period in [7, 14, 21]:
                delta = stock_df['close'].diff()
                gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
                loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
                rs = gain / loss.replace(0, 1)
                stock_df[f'RSI_{period}'] = 100 - (100 / (1 + rs))
            
            # MACD
            exp1 = stock_df['close'].ewm(span=12, adjust=False).mean()
            exp2 = stock_df['close'].ewm(span=26, adjust=False).mean()
            stock_df['MACD'] = exp1 - exp2
            stock_df['MACD_signal'] = stock_df['MACD'].ewm(span=9, adjust=False).mean()
            stock_df['MACD_diff'] = stock_df['MACD'] - stock_df['MACD_signal']
            
            # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
            for period in [20, 30]:
                ma = stock_df['close'].rolling(period).mean()
                std = stock_df['close'].rolling(period).std()
                stock_df[f'BB_upper_{period}'] = ma + (std * 2)
                stock_df[f'BB_lower_{period}'] = ma - (std * 2)
                stock_df[f'BB_position_{period}'] = (stock_df['close'] - stock_df[f'BB_lower_{period}']) / (stock_df[f'BB_upper_{period}'] - stock_df[f'BB_lower_{period}'])
                stock_df[f'BB_width_{period}'] = (stock_df[f'BB_upper_{period}'] - stock_df[f'BB_lower_{period}']) / ma
            
            # å‡ºæ¥é«˜é–¢é€£
            stock_df['Volume_MA5'] = stock_df['volume'].rolling(5).mean()
            stock_df['Volume_MA20'] = stock_df['volume'].rolling(20).mean()
            stock_df['Volume_Ratio'] = stock_df['volume'] / stock_df['Volume_MA20'].replace(0, 1)
            stock_df['Volume_Ratio_5_20'] = stock_df['Volume_MA5'] / stock_df['Volume_MA20'].replace(0, 1)
            
            # ä¾¡æ ¼ã®å¤‰åŒ–ç‡ï¼ˆãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ï¼‰
            for period in [1, 2, 3, 5, 10, 20]:
                stock_df[f'Return_{period}d'] = stock_df['close'].pct_change(period)
                stock_df[f'Return_{period}d_abs'] = np.abs(stock_df[f'Return_{period}d'])
            
            # é€£ç¶šä¸Šæ˜‡ãƒ»ä¸‹é™æ—¥æ•°
            stock_df['Up'] = (stock_df['Return'] > 0).astype(int)
            stock_df['Down'] = (stock_df['Return'] < 0).astype(int)
            stock_df['Consecutive_Up'] = stock_df['Up'].groupby((stock_df['Up'] == 0).cumsum()).cumsum()
            stock_df['Consecutive_Down'] = stock_df['Down'].groupby((stock_df['Down'] == 0).cumsum()).cumsum()
            
            # æ›œæ—¥ã¨æœˆ
            stock_df['DayOfWeek'] = stock_df['Date'].dt.dayofweek
            stock_df['Month'] = stock_df['Date'].dt.month
            
            # é«˜å€¤å®‰å€¤ã®æ¯”ç‡
            stock_df['HL_Ratio'] = stock_df['high'] / stock_df['low']
            stock_df['OC_Ratio'] = stock_df['close'] / stock_df['open']
            
            # ATR (Average True Range)
            high_low = stock_df['high'] - stock_df['low']
            high_close = np.abs(stock_df['high'] - stock_df['close'].shift())
            low_close = np.abs(stock_df['low'] - stock_df['close'].shift())
            ranges = pd.concat([high_low, high_close, low_close], axis=1)
            true_range = ranges.max(axis=1)
            stock_df['ATR_14'] = true_range.rolling(14).mean()
            
            # ã‚¹ãƒˆã‚­ãƒ£ã‚¹ãƒ†ã‚£ã‚¯ã‚¹
            for period in [14, 21]:
                lowest_low = stock_df['low'].rolling(period).min()
                highest_high = stock_df['high'].rolling(period).max()
                stock_df[f'Stochastic_{period}'] = 100 * ((stock_df['close'] - lowest_low) / (highest_high - lowest_low))
            
            features.append(stock_df)
        
        df = pd.concat(features, ignore_index=True)
        
        # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ä½œæˆï¼ˆæ•°å€¤å‹ã®ã‚«ãƒ©ãƒ ã®ã¿ï¼‰
        feature_cols = []
        for col in df.columns:
            if col not in ['Date', 'Stock', 'Target', 'open', 'high', 'low', 'close', 'volume', 
                          'UpperLimit', 'LowerLimit', 'turnover_value', 'code', 'date']:
                # æ•°å€¤å‹ã®ã‚«ãƒ©ãƒ ã®ã¿ã‚’é¸æŠ
                if df[col].dtype in ['float64', 'int64', 'float32', 'int32']:
                    feature_cols.append(col)
        
        logger.info(f"ç”Ÿæˆã—ãŸç‰¹å¾´é‡æ•°: {len(feature_cols)}")
        return df, feature_cols
    
    def select_top_features(self, X_train, y_train, n_features=30):
        """é‡è¦åº¦ã®é«˜ã„ç‰¹å¾´é‡ã‚’é¸æŠ"""
        # Random Forestã§ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’è¨ˆç®—
        rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
        rf.fit(X_train, y_train)
        
        # é‡è¦åº¦ã§ã‚½ãƒ¼ãƒˆ
        importances = pd.DataFrame({
            'feature': X_train.columns,
            'importance': rf.feature_importances_
        }).sort_values('importance', ascending=False)
        
        # ä¸Šä½nå€‹ã®ç‰¹å¾´é‡ã‚’é¸æŠ
        top_features = importances.head(n_features)['feature'].tolist()
        return top_features
    
    def optimize_models(self, df, feature_cols):
        """è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æœ€é©åŒ–"""
        logger.info("ğŸ¯ ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–é–‹å§‹...")
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        df = df.sort_values('Date')
        
        # ãƒ†ã‚¹ãƒˆæœŸé–“ã®è¨­å®šï¼ˆç›´è¿‘1å¹´ï¼‰
        test_start = pd.to_datetime('2024-10-01')
        test_end = pd.to_datetime('2025-09-30')
        
        # å­¦ç¿’ç”¨ã¨ãƒ†ã‚¹ãƒˆç”¨ã«åˆ†å‰²
        train_df = df[df['Date'] < test_start]
        test_period_df = df[(df['Date'] >= test_start) & (df['Date'] <= test_end)]
        
        # ãƒ¢ãƒ‡ãƒ«å®šç¾©
        models = {
            'lgb_conservative': lgb.LGBMClassifier(
                n_estimators=300, max_depth=3, min_child_samples=50,
                subsample=0.8, colsample_bytree=0.8, random_state=42,
                learning_rate=0.01, min_split_gain=0.01
            ),
            'lgb_balanced': lgb.LGBMClassifier(
                n_estimators=200, max_depth=5, min_child_samples=30,
                subsample=0.9, colsample_bytree=0.9, random_state=42,
                learning_rate=0.03
            ),
            'xgb_conservative': xgb.XGBClassifier(
                n_estimators=300, max_depth=3, min_child_samples=50,
                subsample=0.8, colsample_bytree=0.8, random_state=42,
                learning_rate=0.01, gamma=0.1
            ),
            'rf_conservative': RandomForestClassifier(
                n_estimators=500, max_depth=5, min_samples_split=100,
                min_samples_leaf=50, random_state=42, n_jobs=-1
            ),
            'catboost': CatBoostClassifier(
                iterations=200, depth=4, learning_rate=0.03,
                random_state=42, verbose=False
            ),
            'extra_trees': ExtraTreesClassifier(
                n_estimators=500, max_depth=5, min_samples_split=100,
                min_samples_leaf=50, random_state=42, n_jobs=-1
            ),
            'gb_conservative': GradientBoostingClassifier(
                n_estimators=200, max_depth=3, min_samples_split=100,
                min_samples_leaf=50, learning_rate=0.01, random_state=42
            )
        }
        
        # ç•°ãªã‚‹ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã‚’è©¦ã™
        feature_sets = {
            'top_20': 20,
            'top_30': 30,
            'top_40': 40,
            'top_50': 50
        }
        
        best_results = []
        
        for feature_name, n_features in feature_sets.items():
            logger.info(f"\nç‰¹å¾´é‡ã‚»ãƒƒãƒˆ: {feature_name} ({n_features}å€‹)")
            
            # ç‰¹å¾´é‡é¸æŠç”¨ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™
            train_clean = train_df.dropna(subset=['Target'] + feature_cols)
            if len(train_clean) < 10000:
                continue
                
            # ç‰¹å¾´é‡é¸æŠ
            X_select = train_clean[feature_cols]
            y_select = train_clean['Target']
            top_features = self.select_top_features(X_select, y_select, n_features)
            
            for model_name, model in models.items():
                logger.info(f"  ãƒ¢ãƒ‡ãƒ«: {model_name}")
                
                # ç•°ãªã‚‹é–¾å€¤ã‚’è©¦ã™
                for confidence_threshold in [0.5, 0.55, 0.6, 0.65, 0.7, 0.75]:
                    
                    # æ—¥æ¬¡ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ
                    daily_precisions = []
                    daily_predictions = []
                    daily_top5_correct = []
                    
                    test_dates = sorted(test_period_df['Date'].unique())
                    
                    for test_date in test_dates[-30:]:  # ç›´è¿‘30æ—¥ã§ãƒ†ã‚¹ãƒˆ
                        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
                        train_data = df[df['Date'] < test_date]
                        test_data = df[df['Date'] == test_date]
                        
                        if len(train_data) < 5000 or len(test_data) < 20:
                            continue
                        
                        # ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ‡ãƒ¼ã‚¿
                        train_clean = train_data.dropna(subset=['Target'] + top_features)
                        test_clean = test_data.dropna(subset=['Target'] + top_features)
                        
                        if len(train_clean) < 1000 or len(test_clean) < 10:
                            continue
                        
                        X_train = train_clean[top_features]
                        y_train = train_clean['Target']
                        X_test = test_clean[top_features]
                        y_test = test_clean['Target']
                        
                        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
                        scaler = RobustScaler()
                        X_train_scaled = scaler.fit_transform(X_train)
                        X_test_scaled = scaler.transform(X_test)
                        
                        # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
                        try:
                            model.fit(X_train_scaled, y_train)
                            
                            # äºˆæ¸¬ç¢ºç‡ã‚’å–å¾—
                            y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
                            
                            # ä¸Šä½5éŠ˜æŸ„ã®ã¿ã‚’é¸æŠ
                            test_clean['pred_proba'] = y_pred_proba
                            test_clean['predicted'] = (y_pred_proba >= confidence_threshold).astype(int)
                            
                            # ä¿¡é ¼åº¦ã§ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½5ã¤ã‚’å–å¾—
                            top5 = test_clean.nlargest(5, 'pred_proba')
                            
                            if len(top5) > 0 and top5['pred_proba'].iloc[0] >= confidence_threshold:
                                # ä¸Šä½5éŠ˜æŸ„ã®ç²¾åº¦ã‚’è¨ˆç®—
                                top5_predictions = top5['predicted'].values
                                top5_actuals = top5['Target'].values
                                
                                # é–¾å€¤ã‚’è¶…ãˆãŸéŠ˜æŸ„ã®ã¿ã§ç²¾åº¦è¨ˆç®—
                                valid_predictions = top5[top5['pred_proba'] >= confidence_threshold]
                                if len(valid_predictions) > 0:
                                    precision = precision_score(
                                        valid_predictions['Target'], 
                                        valid_predictions['predicted'],
                                        zero_division=0
                                    )
                                    
                                    if precision > 0:
                                        daily_precisions.append(precision)
                                        daily_predictions.append(len(valid_predictions))
                                        daily_top5_correct.append(sum(valid_predictions['Target']))
                                        
                        except Exception as e:
                            continue
                    
                    # çµæœé›†è¨ˆ
                    if len(daily_precisions) >= 10:  # æœ€ä½10æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
                        avg_precision = np.mean(daily_precisions)
                        avg_predictions = np.mean(daily_predictions)
                        total_correct = sum(daily_top5_correct)
                        total_predicted = sum(daily_predictions)
                        
                        if avg_precision >= 0.55:  # 55%ä»¥ä¸Šã®å ´åˆã®ã¿è¨˜éŒ²
                            result = {
                                'model': model_name,
                                'features': feature_name,
                                'n_features': n_features,
                                'threshold': confidence_threshold,
                                'precision': avg_precision,
                                'avg_daily_picks': avg_predictions,
                                'total_correct': total_correct,
                                'total_predicted': total_predicted,
                                'test_days': len(daily_precisions),
                                'feature_list': top_features
                            }
                            
                            best_results.append(result)
                            
                            if avg_precision > self.best_precision:
                                self.best_precision = avg_precision
                                self.best_config = result
                                logger.success(f"    ğŸ¯ æ–°è¨˜éŒ²! Precision: {avg_precision:.2%} (é–¾å€¤: {confidence_threshold})")
        
        return best_results
    
    def print_results(self, results):
        """çµæœè¡¨ç¤º"""
        print("\n" + "="*80)
        print("ğŸ¯ Precision 60%é”æˆã®ãŸã‚ã®æœ€é©åŒ–çµæœ")
        print("="*80)
        
        # Precisionã§ã‚½ãƒ¼ãƒˆ
        results_sorted = sorted(results, key=lambda x: x['precision'], reverse=True)
        
        print("\nğŸ“Š ã€Top 10è¨­å®šã€‘")
        print(f"{'é †ä½':<4} {'ãƒ¢ãƒ‡ãƒ«':<20} {'ç‰¹å¾´é‡':<10} {'é–¾å€¤':<6} {'Precision':<10} {'1æ—¥å¹³å‡':<8}")
        print("-"*70)
        
        for i, result in enumerate(results_sorted[:10], 1):
            print(f"{i:<4} {result['model']:<20} {result['features']:<10} "
                  f"{result['threshold']:<6.2f} {result['precision']:<10.2%} "
                  f"{result['avg_daily_picks']:<8.1f}")
        
        if self.best_config:
            print("\nğŸ† ã€æœ€é©è¨­å®šã€‘")
            print(f"  ãƒ¢ãƒ‡ãƒ«: {self.best_config['model']}")
            print(f"  ç‰¹å¾´é‡æ•°: {self.best_config['n_features']}å€‹")
            print(f"  ä¿¡é ¼åº¦é–¾å€¤: {self.best_config['threshold']:.2f}")
            print(f"  é”æˆPrecision: {self.best_config['precision']:.2%}")
            print(f"  1æ—¥å¹³å‡é¸æŠæ•°: {self.best_config['avg_daily_picks']:.1f}éŠ˜æŸ„")
            print(f"  ãƒ†ã‚¹ãƒˆæ—¥æ•°: {self.best_config['test_days']}æ—¥")
            
            if self.best_config['precision'] >= 0.6:
                print("\nâœ… ç›®æ¨™ã®Precision 60%ã‚’é”æˆã—ã¾ã—ãŸï¼")
            else:
                print(f"\nâš ï¸ ç¾åœ¨ã®æœ€é«˜Precision: {self.best_config['precision']:.2%} (ç›®æ¨™ã¾ã§ã‚ã¨{0.6 - self.best_config['precision']:.2%})")
            
            print("\nğŸ“‹ ã€ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã€‘")
            for i, feature in enumerate(self.best_config['feature_list'][:10], 1):
                print(f"  {i:2d}. {feature}")
            
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            config = {
                'model': self.best_config['model'],
                'features': self.best_config['feature_list'],
                'threshold': float(self.best_config['threshold']),
                'achieved_precision': float(self.best_config['precision'])
            }
            
            with open('precision_60_config.yaml', 'w') as f:
                yaml.dump(config, f)
            
            print("\nğŸ’¾ æœ€é©è¨­å®šã‚’ precision_60_config.yaml ã«ä¿å­˜ã—ã¾ã—ãŸ")
        
        print("\n" + "="*80)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    optimizer = Precision60Optimizer()
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = optimizer.load_data()
    
    # é«˜åº¦ãªç‰¹å¾´é‡ç”Ÿæˆ
    df, feature_cols = optimizer.generate_advanced_features(df)
    
    # ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–
    results = optimizer.optimize_models(df, feature_cols)
    
    # çµæœè¡¨ç¤º
    optimizer.print_results(results)

if __name__ == "__main__":
    main()