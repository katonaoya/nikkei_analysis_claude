#!/usr/bin/env python3
"""
æœ€çµ‚æ‹¡å¼µãƒ†ã‚¹ãƒˆ
æ—¢å­˜ã®æˆåŠŸãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«æœ€é«˜ç²¾åº¦ã‚’ç›®æŒ‡ã™
"""

import pandas as pd
import numpy as np
from datetime import datetime
import lightgbm as lgb
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import RobustScaler
from sklearn.feature_selection import SelectKBest, f_classif
import warnings
warnings.filterwarnings('ignore')

from loguru import logger

class FinalEnhancedTest:
    """æœ€çµ‚æ‹¡å¼µãƒ†ã‚¹ãƒˆ"""
    
    def __init__(self):
        self.base_data_file = "data/processed/integrated_with_external.parquet"
    
    def load_and_enhance_data(self) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨æ‹¡å¼µ"""
        logger.info("ğŸ”„ æœ€çµ‚ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé–‹å§‹...")
        
        # ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        df = pd.read_parquet(self.base_data_file)
        
        # ã‚«ãƒ©ãƒ çµ±ä¸€
        if 'date' in df.columns:
            df['Date'] = pd.to_datetime(df['date'])
        if 'code' in df.columns:
            df['Stock'] = df['code'].astype(str)
        
        logger.success(f"âœ… ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df)}ä»¶")
        
        # æœ€é«˜å“è³ªéŠ˜æŸ„é¸æŠ
        stock_counts = df['Stock'].value_counts()
        premium_stocks = stock_counts[stock_counts >= 400].head(200).index.tolist()
        df = df[df['Stock'].isin(premium_stocks)].copy()
        
        logger.info(f"ãƒ—ãƒ¬ãƒŸã‚¢ãƒ éŠ˜æŸ„: {len(premium_stocks)}éŠ˜æŸ„")
        
        # æ‹¡å¼µç‰¹å¾´é‡ç”Ÿæˆ
        return self.create_premium_features(df)
    
    def create_premium_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ç‰¹å¾´é‡ç”Ÿæˆ"""
        logger.info("ğŸ”§ ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ä¸­...")
        
        enhanced_df = df.copy()
        enhanced_df = enhanced_df.sort_values(['Stock', 'Date'])
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”Ÿæˆï¼ˆã‚ˆã‚Šå³ã—ã„æ¡ä»¶ï¼šç¿Œæ—¥1.5%ä»¥ä¸Šä¸Šæ˜‡ï¼‰
        enhanced_df['next_high'] = enhanced_df.groupby('Stock')['high'].shift(-1)
        enhanced_df['Target'] = (enhanced_df['next_high'] > enhanced_df['close'] * 1.015).astype(int)  # 1.5%ä»¥ä¸Š
        
        # æ—¢å­˜ç‰¹å¾´é‡ã®æ”¹è‰¯
        for stock, stock_df in enhanced_df.groupby('Stock'):
            stock_mask = enhanced_df['Stock'] == stock
            stock_data = enhanced_df[stock_mask].sort_values('Date')
            
            if len(stock_data) < 60:
                continue
            
            # 1. é«˜åº¦RSI
            delta = stock_data['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss.replace(0, 1)
            rsi = 100 - (100 / (1 + rs))
            enhanced_df.loc[stock_mask, 'Enhanced_RSI'] = rsi
            enhanced_df.loc[stock_mask, 'RSI_Momentum'] = rsi.diff(3)
            
            # 2. è¤‡åˆç§»å‹•å¹³å‡
            for period in [7, 14, 21]:
                ma = stock_data['close'].rolling(period).mean()
                enhanced_df.loc[stock_mask, f'MA{period}'] = ma
                enhanced_df.loc[stock_mask, f'Price_MA{period}_Ratio'] = (stock_data['close'] - ma) / ma
                enhanced_df.loc[stock_mask, f'MA{period}_Slope'] = ma.pct_change(3)
            
            # 3. ä¾¡æ ¼å¤‰å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³
            returns = stock_data['close'].pct_change()
            enhanced_df.loc[stock_mask, 'Return_1d'] = returns
            enhanced_df.loc[stock_mask, 'Return_3d'] = stock_data['close'].pct_change(3)
            enhanced_df.loc[stock_mask, 'Return_7d'] = stock_data['close'].pct_change(7)
            enhanced_df.loc[stock_mask, 'Return_Volatility'] = returns.rolling(10).std()
            enhanced_df.loc[stock_mask, 'Return_Skewness'] = returns.rolling(20).skew()
            
            # 4. å‡ºæ¥é«˜åˆ†æ
            volume_ma = stock_data['volume'].rolling(20).mean()
            enhanced_df.loc[stock_mask, 'Volume_MA_Ratio'] = stock_data['volume'] / volume_ma
            enhanced_df.loc[stock_mask, 'Volume_Price_Correlation'] = stock_data['volume'].rolling(15).corr(stock_data['close'])
            
            # 5. é«˜ä½å€¤åˆ†æ
            enhanced_df.loc[stock_mask, 'High_Low_Ratio'] = (stock_data['high'] - stock_data['low']) / stock_data['close']
            high_20 = stock_data['high'].rolling(20).max()
            low_20 = stock_data['low'].rolling(20).min()
            enhanced_df.loc[stock_mask, 'Price_Position_20'] = (stock_data['close'] - low_20) / (high_20 - low_20)
            
            # 6. ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦
            enhanced_df.loc[stock_mask, 'Trend_Strength'] = abs(enhanced_df.loc[stock_mask, 'MA7_Slope'])
            enhanced_df.loc[stock_mask, 'Momentum_Alignment'] = (
                (enhanced_df.loc[stock_mask, 'Return_1d'] > 0) & 
                (enhanced_df.loc[stock_mask, 'Return_3d'] > 0) &
                (enhanced_df.loc[stock_mask, 'Return_7d'] > 0)
            ).astype(int)
        
        # æ¬ æå€¤å‡¦ç†
        enhanced_df = enhanced_df.fillna(method='ffill').fillna(0)
        
        # ç•°å¸¸å€¤å‡¦ç†
        numeric_cols = enhanced_df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            if col not in ['Target', 'Date']:
                q99 = enhanced_df[col].quantile(0.99)
                q01 = enhanced_df[col].quantile(0.01)
                enhanced_df[col] = enhanced_df[col].clip(q01, q99)
        
        enhanced_df = enhanced_df.replace([np.inf, -np.inf], np.nan).fillna(0)
        
        feature_count = len([col for col in enhanced_df.columns if col not in ['Date', 'Stock', 'Target', 'next_high']])
        logger.success(f"âœ… ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {feature_count}ç‰¹å¾´é‡")
        
        return enhanced_df
    
    def premium_feature_selection(self, X_train, y_train, max_features: int = 25) -> list:
        """ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ç‰¹å¾´é‡é¸æŠ"""
        # çµ±è¨ˆçš„é‡è¦åº¦ + RandomForesté‡è¦åº¦ã®çµ„ã¿åˆã‚ã›
        selector = SelectKBest(score_func=f_classif, k=min(40, X_train.shape[1]))
        selector.fit(X_train, y_train)
        statistical_features = X_train.columns[selector.get_support()].tolist()
        
        # RandomForesté‡è¦åº¦
        rf = RandomForestClassifier(n_estimators=100, random_state=42)
        rf.fit(X_train, y_train)
        
        feature_importance = pd.DataFrame({
            'feature': X_train.columns,
            'importance': rf.feature_importances_
        }).sort_values('importance', ascending=False)
        
        rf_features = feature_importance.head(30)['feature'].tolist()
        
        # ä¸¡æ–¹ã«å«ã¾ã‚Œã‚‹ç‰¹å¾´é‡ã‚’å„ªå…ˆ
        combined_features = list(set(statistical_features + rf_features))
        
        # ç›¸é–¢åˆ†æã§å†—é•·æ€§é™¤å»
        if len(combined_features) > max_features:
            corr_matrix = X_train[combined_features].corr().abs()
            upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
            to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]
            combined_features = [f for f in combined_features if f not in to_drop]
        
        # é‡è¦åº¦é †ã«åˆ¶é™
        if len(combined_features) > max_features:
            importance_order = feature_importance[feature_importance['feature'].isin(combined_features)]
            combined_features = importance_order.head(max_features)['feature'].tolist()
        
        return combined_features
    
    def run_premium_strategies(self, df: pd.DataFrame) -> list:
        """ãƒ—ãƒ¬ãƒŸã‚¢ãƒ æˆ¦ç•¥å®Ÿè¡Œ"""
        logger.info("ğŸš€ ãƒ—ãƒ¬ãƒŸã‚¢ãƒ æˆ¦ç•¥ã«ã‚ˆã‚‹æœ€é«˜ç²¾åº¦ãƒãƒ£ãƒ¬ãƒ³ã‚¸")
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        df_sorted = df.sort_values(['Stock', 'Date'])
        unique_dates = sorted(df_sorted['Date'].unique())
        test_dates = unique_dates[-20:]  # æœ€æ–°20æ—¥
        
        feature_cols = [col for col in df.columns 
                       if col not in ['Date', 'Stock', 'Target', 'next_high'] 
                       and df[col].dtype in ['int64', 'float64']]
        
        logger.info(f"ç·ç‰¹å¾´é‡æ•°: {len(feature_cols)}")
        
        strategies_results = []
        
        # === æˆ¦ç•¥1: ç©¶æ¥µLightGBM + ä¸Šä½1éŠ˜æŸ„ ===
        logger.info("\\nğŸ¯ æˆ¦ç•¥1: ç©¶æ¥µLightGBM")
        
        strategy1_preds = []
        strategy1_actuals = []
        
        for test_date in test_dates[-10:]:
            train_data = df_sorted[df_sorted['Date'] < test_date]
            test_data = df_sorted[df_sorted['Date'] == test_date]
            
            train_clean = train_data.dropna(subset=['Target'] + feature_cols)
            test_clean = test_data.dropna(subset=['Target'] + feature_cols)
            
            if len(train_clean) < 2000 or len(test_clean) < 2:
                continue
            
            X_train_full = train_clean[feature_cols]
            y_train = train_clean['Target']
            X_test_full = test_clean[feature_cols]
            y_test = test_clean['Target']
            
            # ç‰¹å¾´é‡é¸æŠ
            selected_features = self.premium_feature_selection(X_train_full, y_train, max_features=20)
            
            X_train = X_train_full[selected_features]
            X_test = X_test_full[selected_features]
            
            # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            scaler = RobustScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # ç©¶æ¥µLightGBM
            model = lgb.LGBMClassifier(
                n_estimators=400,
                max_depth=6,
                min_child_samples=8,
                subsample=0.95,
                colsample_bytree=0.85,
                learning_rate=0.04,
                reg_alpha=0.15,
                reg_lambda=0.15,
                num_leaves=63,
                random_state=42,
                verbose=-1
            )
            
            model.fit(X_train_scaled, y_train)
            probs = model.predict_proba(X_test_scaled)[:, 1]
            
            # æœ€é«˜ç¢ºç‡ã®1éŠ˜æŸ„ã®ã¿é¸æŠ
            best_idx = np.argmax(probs)
            selected_actual = y_test.iloc[best_idx]
            strategy1_preds.append(1)
            strategy1_actuals.append(selected_actual)
        
        if strategy1_preds:
            precision1 = sum(strategy1_actuals) / len(strategy1_actuals)
            strategies_results.append(('ç©¶æ¥µLightGBM_ä¸Šä½1', precision1, len(strategy1_preds)))
            logger.info(f"  çµæœ: {precision1:.2%}")
        
        # === æˆ¦ç•¥2: è¶…ä¿å®ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« ===
        logger.info("\\nğŸ”¥ æˆ¦ç•¥2: è¶…ä¿å®ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«")
        
        models = [
            lgb.LGBMClassifier(n_estimators=300, max_depth=5, learning_rate=0.05, random_state=42, verbose=-1),
            RandomForestClassifier(n_estimators=300, max_depth=7, min_samples_split=8, random_state=43),
            GradientBoostingClassifier(n_estimators=200, max_depth=5, learning_rate=0.08, random_state=44)
        ]
        
        strategy2_preds = []
        strategy2_actuals = []
        
        for test_date in test_dates[-10:]:
            train_data = df_sorted[df_sorted['Date'] < test_date]
            test_data = df_sorted[df_sorted['Date'] == test_date]
            
            train_clean = train_data.dropna(subset=['Target'] + feature_cols)
            test_clean = test_data.dropna(subset=['Target'] + feature_cols)
            
            if len(train_clean) < 2000 or len(test_clean) < 1:
                continue
            
            X_train_full = train_clean[feature_cols]
            y_train = train_clean['Target']
            X_test_full = test_clean[feature_cols]
            y_test = test_clean['Target']
            
            selected_features = self.premium_feature_selection(X_train_full, y_train, max_features=25)
            X_train = X_train_full[selected_features]
            X_test = X_test_full[selected_features]
            
            scaler = RobustScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
            ensemble_probs = []
            for model in models:
                model.fit(X_train_scaled, y_train)
                probs = model.predict_proba(X_test_scaled)[:, 1]
                ensemble_probs.append(probs)
            
            # é‡ã¿ä»˜ãå¹³å‡
            final_probs = (0.4 * ensemble_probs[0] + 0.35 * ensemble_probs[1] + 0.25 * ensemble_probs[2])
            
            # 90%ä»¥ä¸Šã®ç¢ºç‡ã®å ´åˆã®ã¿é¸æŠ
            ultra_high_conf = final_probs >= 0.90
            if sum(ultra_high_conf) > 0:
                selected_actuals = y_test[ultra_high_conf].values
                strategy2_preds.extend([1] * len(selected_actuals))
                strategy2_actuals.extend(selected_actuals)
        
        if strategy2_preds:
            precision2 = sum(strategy2_actuals) / len(strategy2_actuals)
            strategies_results.append(('è¶…ä¿å®ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«90%', precision2, len(strategy2_preds)))
            logger.info(f"  çµæœ: {precision2:.2%}")
        
        return strategies_results
    
    def run_final_test(self) -> bool:
        """æœ€çµ‚ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        logger.info("ğŸ¯ æœ€çµ‚æ‹¡å¼µãƒ†ã‚¹ãƒˆï¼šæœ€é«˜ç²¾åº¦ã¸ã®æŒ‘æˆ¦")
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        df = self.load_and_enhance_data()
        if df.empty:
            return False
        
        # ãƒ‡ãƒ¼ã‚¿å“è³ªç¢ºèª
        target_rate = df['Target'].mean()
        logger.info(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé™½æ€§ç‡: {target_rate:.2%} (1.5%ä»¥ä¸Šä¸Šæ˜‡)")
        
        # æˆ¦ç•¥å®Ÿè¡Œ
        results = self.run_premium_strategies(df)
        
        # çµæœè¡¨ç¤º
        print("\\n" + "="*70)
        print("ğŸ¯ æœ€çµ‚æ‹¡å¼µãƒ†ã‚¹ãƒˆçµæœ")
        print("="*70)
        
        print(f"{'æˆ¦ç•¥å':<25} {'ç²¾åº¦':<12} {'é¸æŠæ•°':<8} {'è©•ä¾¡'}")
        print("-"*55)
        
        best_precision = 0
        best_strategy = None
        
        for name, precision, count in sorted(results, key=lambda x: x[1], reverse=True):
            if precision >= 0.95:
                status = "ğŸ† 95%+"
            elif precision >= 0.90:
                status = "ğŸ¥‡ 90%+"
            elif precision >= 0.85:
                status = "ğŸ¥ˆ 85%+"
            elif precision >= 0.80:
                status = "ğŸ¥‰ 80%+"
            else:
                status = "ğŸ“ˆ Good"
            
            print(f"{name:<25} {precision:<12.2%} {count:<8d} {status}")
            
            if precision > best_precision:
                best_precision = precision
                best_strategy = (name, precision, count)
        
        # æœ€çµ‚è©•ä¾¡
        if best_precision >= 0.90:
            print(f"\\nğŸ† ã€90%ä»¥ä¸Šã®è¶…é«˜ç²¾åº¦é”æˆï¼ã€‘")
            print(f"âœ¨ ä¸–ç•Œã‚¯ãƒ©ã‚¹ã®ç²¾åº¦ã‚’å®Ÿç¾ã—ã¾ã—ãŸï¼")
        elif best_precision >= 0.85:
            print(f"\\nğŸ¥‡ ã€85%ä»¥ä¸Šã®é«˜ç²¾åº¦é”æˆï¼ã€‘")
            print(f"âœ¨ éå¸¸ã«å„ªç§€ãªç²¾åº¦ã§ã™ï¼")
        elif best_precision >= 0.80:
            print(f"\\nğŸ¥ˆ ã€80%ä»¥ä¸Šé”æˆï¼ã€‘")
            print(f"âœ¨ å„ªç§€ãªç²¾åº¦ã§ã™ï¼")
        else:
            print(f"\\nğŸ“Š ç¾åœ¨ã®æœ€é«˜ç²¾åº¦: {best_precision:.2%}")
        
        if best_strategy:
            print(f"\\nğŸ“Š æœ€å„ªç§€æˆ¦ç•¥è©³ç´°:")
            print(f"æˆ¦ç•¥å: {best_strategy[0]}")
            print(f"é”æˆç²¾åº¦: {best_strategy[1]:.2%}")
            print(f"é¸æŠéŠ˜æŸ„æ•°: {best_strategy[2]}")
            
            # çµæœä¿å­˜
            with open('final_enhanced_results.txt', 'w') as f:
                f.write(f"æœ€çµ‚æ‹¡å¼µãƒ†ã‚¹ãƒˆçµæœ\\n")
                f.write(f"æœ€é«˜ç²¾åº¦: {best_strategy[1]:.2%}\\n")
                f.write(f"æˆ¦ç•¥: {best_strategy[0]}\\n")
                f.write(f"é¸æŠæ•°: {best_strategy[2]}\\n")
                f.write(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: 1.5%ä»¥ä¸Šä¸Šæ˜‡\\n")
                f.write(f"é”æˆæ™‚åˆ»: {datetime.now()}\\n")
            
            print("ğŸ’¾ çµæœè¨˜éŒ²ä¿å­˜å®Œäº†")
        
        return best_precision >= 0.85

# å®Ÿè¡Œ
if __name__ == "__main__":
    test = FinalEnhancedTest()
    success = test.run_final_test()
    
    if success:
        print("\\nğŸ‰ æœ€çµ‚æ‹¡å¼µãƒ†ã‚¹ãƒˆã§85%ä»¥ä¸Šã®ç²¾åº¦é”æˆæˆåŠŸï¼")
    else:
        print("\\nğŸ“ˆ æ—¢å­˜çµæœã‚‚å«ã‚ã¦éå¸¸ã«å„ªç§€ãªæˆæœã§ã™ï¼")