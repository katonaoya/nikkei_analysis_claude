#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¥çµŒ225å…¨éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚·ã‚¹ãƒ†ãƒ 
J-Quants APIã‚’ä½¿ç”¨ã—ã¦æ—¥çµŒ225å…¨225éŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
"""

import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time
import os
import json
from pathlib import Path
import logging
from typing import List, Optional, Dict
from dotenv import load_dotenv

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

JQUANTS_BASE_URL = "https://api.jquants.com/v1"

class Nikkei225FullFetcher:
    """æ—¥çµŒ225å…¨éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.mail_address = os.getenv("JQUANTS_MAIL_ADDRESS")
        self.password = os.getenv("JQUANTS_PASSWORD")
        self.id_token: Optional[str] = None
        self.token_expires_at: Optional[datetime] = None
        
        if not self.mail_address or not self.password:
            raise ValueError("JQuantsã®èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ (.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„)")
        
        # æ—¥çµŒ225éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰èª­ã¿è¾¼ã¿
        self.nikkei225_codes = self._load_nikkei225_codes()
        logger.info(f"æ—¥çµŒ225éŠ˜æŸ„æ•°: {len(self.nikkei225_codes)}éŠ˜æŸ„")
    
    def _load_nikkei225_codes(self) -> List[str]:
        """æ—¥çµŒ225éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰èª­ã¿è¾¼ã¿"""
        try:
            df = pd.read_csv('data/nikkei225_codes.csv')
            # 4æ¡å½¢å¼ã§çµ±ä¸€ï¼ˆå…ˆé ­0åŸ‹ã‚ï¼‰
            codes = df['code'].astype(str).str.zfill(4).tolist()
            logger.info(f"æ—¥çµŒ225éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰èª­ã¿è¾¼ã¿å®Œäº†: {len(codes)}éŠ˜æŸ„")
            logger.info(f"ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰: {codes[:5]}")
            return codes
        except Exception as e:
            logger.error(f"æ—¥çµŒ225éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _get_id_token(self) -> str:
        """IDãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—"""
        if self.id_token and self.token_expires_at and datetime.now() < self.token_expires_at:
            return self.id_token
        
        logger.info("JQuantsèªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ä¸­...")
        time.sleep(3)
        
        try:
            # ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            auth_payload = {
                "mailaddress": self.mail_address,
                "password": self.password
            }
            
            resp = requests.post(
                f"{JQUANTS_BASE_URL}/token/auth_user",
                data=json.dumps(auth_payload),
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            
            if resp.status_code == 429:
                logger.warning("ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã‚ˆã‚Š2åˆ†å¾…æ©Ÿ...")
                time.sleep(120)
                return self._get_id_token()
                
            resp.raise_for_status()
            refresh_token = resp.json().get("refreshToken")
            
            if not refresh_token:
                raise RuntimeError("ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            time.sleep(1)
            resp = requests.post(
                f"{JQUANTS_BASE_URL}/token/auth_refresh?refreshtoken={refresh_token}",
                timeout=30
            )
            
            if resp.status_code == 429:
                logger.warning("ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã‚ˆã‚Š2åˆ†å¾…æ©Ÿ...")
                time.sleep(120)
                return self._get_id_token()
                
            resp.raise_for_status()
            self.id_token = resp.json().get("idToken")
            
            if not self.id_token:
                raise RuntimeError("IDãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            self.token_expires_at = datetime.now() + timedelta(hours=1)
            
            logger.info("èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—å®Œäº†")
            return self.id_token
            
        except Exception as e:
            logger.error(f"èªè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    def get_listed_companies(self) -> Dict[str, str]:
        """ä¸Šå ´éŠ˜æŸ„ä¸€è¦§ã‚’å–å¾—ã—ã¦æ­£ç¢ºãªéŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’ç‰¹å®š"""
        token = self._get_id_token()
        
        headers = {"Authorization": f"Bearer {token}"}
        url = f"{JQUANTS_BASE_URL}/listed/info"
        
        all_companies = {}
        pagination_key = None
        
        logger.info("ä¸Šå ´éŠ˜æŸ„ä¸€è¦§ã‚’å–å¾—ä¸­...")
        
        while True:
            params = {}
            if pagination_key:
                params["pagination_key"] = pagination_key
            
            try:
                time.sleep(2)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                response = requests.get(url, headers=headers, params=params, timeout=30)
                
                if response.status_code == 429:
                    logger.warning("ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã‚ˆã‚Š2åˆ†å¾…æ©Ÿ...")
                    time.sleep(120)
                    continue
                
                response.raise_for_status()
                data = response.json()
                
                if "info" in data:
                    for company in data["info"]:
                        code = company.get("Code", "")  # 5æ¡APIã‚³ãƒ¼ãƒ‰
                        name = company.get("CompanyName", "")
                        
                        # 5æ¡ã‚³ãƒ¼ãƒ‰ã‹ã‚‰4æ¡ã‚³ãƒ¼ãƒ‰ã‚’é€†ç®—ï¼ˆæœ€å¾Œã®0ã‚’é™¤å»ï¼‰
                        if code and len(str(code)) == 5 and str(code).endswith('0'):
                            code_4digit = str(code)[:-1]  # æœ€å¾Œã®0ã‚’é™¤å»
                        else:
                            continue
                        
                        # æ—¥çµŒ225éŠ˜æŸ„ã«å«ã¾ã‚Œã‚‹å ´åˆã®ã¿è¨˜éŒ²
                        if code_4digit in self.nikkei225_codes:
                            all_companies[code_4digit] = {
                                "api_code": code,  # 5æ¡APIã‚³ãƒ¼ãƒ‰
                                "name": name or f"éŠ˜æŸ„{code_4digit}",
                                "code_4digit": code_4digit
                            }
                            
                            if len(all_companies) <= 10:  # æœ€åˆã®10ä»¶ã‚’ãƒ­ã‚°å‡ºåŠ›
                                logger.info(f"ãƒãƒƒãƒ”ãƒ³ã‚°: {code_4digit} -> {code} ({name})")
                
                # æ¬¡ã®ãƒšãƒ¼ã‚¸ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                pagination_key = data.get("pagination_key")
                if not pagination_key:
                    break
                    
            except Exception as e:
                logger.error(f"ä¸Šå ´éŠ˜æŸ„ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(10)
                continue
        
        logger.info(f"æ—¥çµŒ225éŠ˜æŸ„ã®ãƒãƒƒãƒ”ãƒ³ã‚°å®Œäº†: {len(all_companies)}éŠ˜æŸ„")
        return all_companies
    
    def fetch_stock_data(self, api_code: str, from_date: str, to_date: str) -> Optional[pd.DataFrame]:
        """å€‹åˆ¥éŠ˜æŸ„ã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        token = self._get_id_token()
        headers = {"Authorization": f"Bearer {token}"}
        
        url = f"{JQUANTS_BASE_URL}/prices/daily_quotes"
        params = {
            "code": api_code,
            "from": from_date,
            "to": to_date
        }
        
        all_data = []
        pagination_key = None
        
        while True:
            if pagination_key:
                params["pagination_key"] = pagination_key
            
            try:
                time.sleep(2)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                response = requests.get(url, headers=headers, params=params, timeout=30)
                
                if response.status_code == 429:
                    logger.warning("ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã‚ˆã‚Š2åˆ†å¾…æ©Ÿ...")
                    time.sleep(120)
                    continue
                
                if response.status_code == 404:
                    logger.warning(f"éŠ˜æŸ„ {api_code} ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    return None
                
                response.raise_for_status()
                data = response.json()
                
                if "daily_quotes" in data:
                    all_data.extend(data["daily_quotes"])
                
                pagination_key = data.get("pagination_key")
                if not pagination_key:
                    break
                    
            except Exception as e:
                logger.error(f"éŠ˜æŸ„ {api_code} ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(5)
                return None
        
        if all_data:
            df = pd.DataFrame(all_data)
            logger.info(f"éŠ˜æŸ„ {api_code}: {len(df)}ä»¶å–å¾—")
            return df
        
        return None
    
    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™è¨ˆç®—"""
        if df.empty:
            return df
        
        df = df.copy()
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values(['Code', 'Date'])
        
        # ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«è¨ˆç®—
        result_dfs = []
        for code, group in df.groupby('Code'):
            group = group.sort_values('Date').copy()
            
            # ç§»å‹•å¹³å‡
            group['MA_5'] = group['Close'].rolling(window=5).mean()
            group['MA_20'] = group['Close'].rolling(window=20).mean()
            
            # ãƒªã‚¿ãƒ¼ãƒ³
            group['Returns'] = group['Close'].pct_change()
            
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆ20æ—¥é–“ï¼‰
            group['Volatility'] = group['Returns'].rolling(window=20).std()
            
            # RSIè¨ˆç®—
            delta = group['Close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            group['RSI'] = 100 - (100 / (1 + rs))
            
            result_dfs.append(group)
        
        result = pd.concat(result_dfs, ignore_index=True)
        logger.info(f"ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™è¨ˆç®—å®Œäº†: {len(result)}ä»¶")
        
        return result
    
    def fetch_all_nikkei225_data(self, years: int = 10) -> pd.DataFrame:
        """æ—¥çµŒ225å…¨éŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        # æœŸé–“è¨­å®š
        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=years * 365)
        
        from_date = start_date.strftime('%Y-%m-%d')
        to_date = end_date.strftime('%Y-%m-%d')
        
        logger.info(f"ãƒ‡ãƒ¼ã‚¿å–å¾—æœŸé–“: {from_date} ã€œ {to_date}")
        
        # ä¸Šå ´éŠ˜æŸ„ä¸€è¦§ã‹ã‚‰æ­£ç¢ºãªã‚³ãƒ¼ãƒ‰ã‚’å–å¾—
        companies_mapping = self.get_listed_companies()
        
        if not companies_mapping:
            logger.error("éŠ˜æŸ„ãƒãƒƒãƒ”ãƒ³ã‚°å–å¾—ã«å¤±æ•—")
            return pd.DataFrame()
        
        all_stock_data = []
        success_count = 0
        total_count = len(companies_mapping)
        
        logger.info(f"æ—¥çµŒ225å…¨éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹: {total_count}éŠ˜æŸ„")
        
        for i, (code_4digit, company_info) in enumerate(companies_mapping.items(), 1):
            api_code = company_info["api_code"]
            company_name = company_info["name"]
            
            logger.info(f"é€²æ— {i}/{total_count}: {code_4digit} ({company_name})")
            
            # æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—
            stock_df = self.fetch_stock_data(api_code, from_date, to_date)
            
            if stock_df is not None and not stock_df.empty:
                # 4æ¡ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ 
                stock_df['Code'] = code_4digit
                stock_df['CompanyName'] = company_name
                all_stock_data.append(stock_df)
                success_count += 1
                logger.info(f"âœ… {code_4digit}: {len(stock_df)}ä»¶å–å¾—")
            else:
                logger.warning(f"âŒ {code_4digit}: ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
            
            # 10éŠ˜æŸ„ã”ã¨ã«é•·ã‚ã®å¾…æ©Ÿ
            if i % 10 == 0:
                logger.info(f"10éŠ˜æŸ„å‡¦ç†å®Œäº†ã€15ç§’å¾…æ©Ÿ...")
                time.sleep(15)
        
        # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
        if all_stock_data:
            logger.info("ãƒ‡ãƒ¼ã‚¿çµ±åˆå‡¦ç†é–‹å§‹...")
            combined_df = pd.concat(all_stock_data, ignore_index=True)
            
            # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™è¨ˆç®—
            logger.info("ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™è¨ˆç®—é–‹å§‹...")
            final_df = self.calculate_technical_indicators(combined_df)
            
            # ä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"data/processed/nikkei225_full_data_{timestamp}.parquet"
            final_df.to_parquet(output_file, index=False)
            
            logger.info(f"ğŸ‰ æ—¥çµŒ225å…¨éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†!")
            logger.info(f"æˆåŠŸ: {success_count}/{total_count}éŠ˜æŸ„")
            logger.info(f"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(final_df):,}ä»¶")
            logger.info(f"ä¿å­˜å…ˆ: {output_file}")
            
            return final_df
        else:
            logger.error("ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return pd.DataFrame()

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    try:
        fetcher = Nikkei225FullFetcher()
        
        # æ—¥çµŒ225å…¨éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆ10å¹´é–“ï¼‰
        df = fetcher.fetch_all_nikkei225_data(years=10)
        
        if not df.empty:
            print(f"\nâœ… æ—¥çµŒ225å…¨éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†")
            print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:")
            print(f"  - ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df):,}")
            print(f"  - éŠ˜æŸ„æ•°: {df['Code'].nunique()}")
            print(f"  - æœŸé–“: {df['Date'].min()} ã€œ {df['Date'].max()}")
        else:
            print("\nâŒ ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
    except Exception as e:
        logger.error(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    main()