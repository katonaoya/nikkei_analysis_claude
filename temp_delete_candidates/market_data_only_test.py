#!/usr/bin/env python3
"""
ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ã§ã®60%ç²¾åº¦ãƒ†ã‚¹ãƒˆ
J-Quantsèªè¨¼ãªã—ã§å®Ÿè¡Œå¯èƒ½
"""

import pandas as pd
import numpy as np
from datetime import datetime
import lightgbm as lgb
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import RobustScaler
from sklearn.feature_selection import SelectKBest, f_classif
import warnings
warnings.filterwarnings('ignore')

from yahoo_market_data import YahooMarketData
from loguru import logger

class MarketDataOnlyTest:
    """ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ã§ã®ç²¾åº¦ãƒ†ã‚¹ãƒˆ"""
    
    def __init__(self):
        self.base_data_file = "data/processed/integrated_with_external.parquet"
    
    def load_base_data(self) -> pd.DataFrame:
        """ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        try:
            df = pd.read_parquet(self.base_data_file)
            
            # ã‚«ãƒ©ãƒ çµ±ä¸€
            if 'date' in df.columns:
                df['Date'] = pd.to_datetime(df['date'])
            if 'code' in df.columns:
                df['Stock'] = df['code'].astype(str)
            
            logger.success(f"âœ… ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df)}ä»¶")
            return df
        except Exception as e:
            logger.error(f"âŒ ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            return pd.DataFrame()
    
    def integrate_market_data_only(self, base_df: pd.DataFrame) -> pd.DataFrame:
        """ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿çµ±åˆ"""
        logger.info("ğŸ”„ ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿çµ±åˆä¸­...")
        
        try:
            # Yahoo Financeã‹ã‚‰ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
            market_data = YahooMarketData()
            data_dict = market_data.get_all_market_data(period="2y")
            
            if not data_dict:
                logger.warning("ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return base_df
            
            # ãƒãƒ¼ã‚±ãƒƒãƒˆç‰¹å¾´é‡ç”Ÿæˆ
            market_features = market_data.calculate_market_features(data_dict)
            
            if market_features.empty:
                logger.warning("ãƒãƒ¼ã‚±ãƒƒãƒˆç‰¹å¾´é‡ãŒç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return base_df
            
            # ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒ¼ã‚¸
            enhanced_df = base_df.merge(market_features, on='Date', how='left')
            
            # å‰æ–¹è£œå®Œã§æ¬ æå€¤ã‚’åŸ‹ã‚ã‚‹
            market_cols = [col for col in market_features.columns if col != 'Date']
            enhanced_df[market_cols] = enhanced_df[market_cols].fillna(method='ffill')
            enhanced_df[market_cols] = enhanced_df[market_cols].fillna(method='bfill')
            enhanced_df[market_cols] = enhanced_df[market_cols].fillna(0)
            
            logger.success(f"âœ… ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿çµ±åˆå®Œäº†: {len(market_cols)}ç‰¹å¾´é‡è¿½åŠ ")
            return enhanced_df
            
        except Exception as e:
            logger.error(f"âŒ ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿çµ±åˆå¤±æ•—: {e}")
            return base_df
    
    def create_enhanced_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ‹¡å¼µç‰¹å¾´é‡ç”Ÿæˆ"""
        logger.info("ğŸ”§ æ‹¡å¼µç‰¹å¾´é‡ç”Ÿæˆä¸­...")
        
        enhanced_df = df.copy()
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”Ÿæˆ
        enhanced_df = enhanced_df.sort_values(['Stock', 'Date'])
        enhanced_df['next_high'] = enhanced_df.groupby('Stock')['high'].shift(-1)
        enhanced_df['Target'] = (enhanced_df['next_high'] > enhanced_df['close'] * 1.01).astype(int)
        
        # æ—¢å­˜ç‰¹å¾´é‡ã®æ”¹è‰¯
        for stock, stock_df in enhanced_df.groupby('Stock'):
            stock_mask = enhanced_df['Stock'] == stock
            stock_data = enhanced_df[stock_mask].sort_values('Date')
            
            # RSIæ”¹è‰¯
            if len(stock_data) > 20:
                delta = stock_data['close'].diff()
                gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
                loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
                rs = gain / loss.replace(0, 1)
                rsi = 100 - (100 / (1 + rs))
                enhanced_df.loc[stock_mask, 'Enhanced_RSI'] = rsi
                
                # RSI divergence
                enhanced_df.loc[stock_mask, 'RSI_Divergence'] = rsi - rsi.rolling(5).mean()
            
            # è¤‡åˆãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ æŒ‡æ¨™
            if len(stock_data) > 30:
                short_ma = stock_data['close'].rolling(5).mean()
                long_ma = stock_data['close'].rolling(20).mean()
                enhanced_df.loc[stock_mask, 'MA_Cross_Signal'] = (short_ma > long_ma).astype(int)
                enhanced_df.loc[stock_mask, 'MA_Distance'] = (short_ma - long_ma) / long_ma
            
            # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰é¢¨æŒ‡æ¨™
            if len(stock_data) > 20:
                ma = stock_data['close'].rolling(20).mean()
                std = stock_data['close'].rolling(20).std()
                enhanced_df.loc[stock_mask, 'BB_Position'] = (stock_data['close'] - ma) / (std * 2)
        
        # ãƒãƒ¼ã‚±ãƒƒãƒˆé–¢é€£ç‰¹å¾´é‡ã®æ”¹è‰¯
        if 'nikkei225_close' in enhanced_df.columns:
            # å¸‚å ´ã¨ã®ç›¸é–¢å¼·åº¦
            enhanced_df['Market_Sync'] = enhanced_df['close'].pct_change().rolling(20).corr(enhanced_df['nikkei225_return_1d'])
            
            # ç›¸å¯¾ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
            enhanced_df['Relative_Performance'] = enhanced_df['close'].pct_change() - enhanced_df['nikkei225_return_1d']
        
        if 'vix_close' in enhanced_df.columns:
            # VIX ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ç‰¹å¾´é‡
            enhanced_df['VIX_Regime'] = pd.cut(enhanced_df['vix_close'], 
                                             bins=[0, 15, 25, 100], 
                                             labels=[0, 1, 2]).astype(int)
        
        # æ¬ æå€¤å‡¦ç†
        enhanced_df = enhanced_df.fillna(method='ffill').fillna(0)
        
        logger.success(f"âœ… æ‹¡å¼µç‰¹å¾´é‡ç”Ÿæˆå®Œäº†")
        return enhanced_df
    
    def run_market_enhanced_test(self) -> bool:
        """ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        logger.info("ğŸ¯ ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã«ã‚ˆã‚‹60%ç²¾åº¦ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        base_df = self.load_base_data()
        if base_df.empty:
            return False
        
        # ä¸»è¦éŠ˜æŸ„ã«é™å®šï¼ˆå‡¦ç†é€Ÿåº¦å‘ä¸Šï¼‰
        stock_counts = base_df['Stock'].value_counts()
        major_stocks = stock_counts[stock_counts >= 200].head(100).index.tolist()
        base_df = base_df[base_df['Stock'].isin(major_stocks)]
        
        logger.info(f"å¯¾è±¡éŠ˜æŸ„: {len(major_stocks)}éŠ˜æŸ„")
        
        # ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿çµ±åˆ
        enhanced_df = self.integrate_market_data_only(base_df)
        
        # æ‹¡å¼µç‰¹å¾´é‡ç”Ÿæˆ
        final_df = self.create_enhanced_features(enhanced_df)
        
        # ç‰¹å¾´é‡é¸æŠ
        feature_cols = []
        for col in final_df.columns:
            if col not in ['Date', 'Stock', 'Target', 'next_high'] and final_df[col].dtype in ['int64', 'float64']:
                feature_cols.append(col)
        
        logger.info(f"ä½¿ç”¨ç‰¹å¾´é‡æ•°: {len(feature_cols)}")
        
        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        df_sorted = final_df.sort_values(['Stock', 'Date'])
        unique_dates = sorted(df_sorted['Date'].unique())
        test_dates = unique_dates[-20:]  # æœ€æ–°20æ—¥
        
        strategies = []
        
        # === æˆ¦ç•¥1: ãƒãƒ¼ã‚±ãƒƒãƒˆæ‹¡å¼µLightGBM ===
        logger.info("ğŸš€ æˆ¦ç•¥1: ãƒãƒ¼ã‚±ãƒƒãƒˆæ‹¡å¼µLightGBM")
        
        strategy1_preds = []
        strategy1_actuals = []
        
        for test_date in test_dates[-10:]:
            train_data = df_sorted[df_sorted['Date'] < test_date]
            test_data = df_sorted[df_sorted['Date'] == test_date]
            
            train_clean = train_data.dropna(subset=['Target'] + feature_cols)
            test_clean = test_data.dropna(subset=['Target'] + feature_cols)
            
            if len(train_clean) < 500 or len(test_clean) < 3:
                continue
            
            X_train = train_clean[feature_cols]
            y_train = train_clean['Target']
            X_test = test_clean[feature_cols]
            y_test = test_clean['Target']
            
            # ç‰¹å¾´é‡é¸æŠ
            selector = SelectKBest(score_func=f_classif, k=min(20, len(feature_cols)))
            X_train_selected = selector.fit_transform(X_train, y_train)
            X_test_selected = selector.transform(X_test)
            
            # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            scaler = RobustScaler()
            X_train_scaled = scaler.fit_transform(X_train_selected)
            X_test_scaled = scaler.transform(X_test_selected)
            
            # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
            model = lgb.LGBMClassifier(
                n_estimators=150,
                max_depth=4,
                learning_rate=0.08,
                subsample=0.85,
                colsample_bytree=0.85,
                random_state=42,
                verbose=-1
            )
            
            model.fit(X_train_scaled, y_train)
            probs = model.predict_proba(X_test_scaled)[:, 1]
            
            # ä¸Šä½3éŠ˜æŸ„é¸æŠ
            n_select = min(3, len(probs))
            top_indices = np.argsort(probs)[-n_select:]
            
            selected_actuals = y_test.iloc[top_indices].values
            strategy1_preds.extend([1] * len(selected_actuals))
            strategy1_actuals.extend(selected_actuals)
        
        if strategy1_preds:
            precision1 = sum(strategy1_actuals) / len(strategy1_actuals)
            strategies.append(('ãƒãƒ¼ã‚±ãƒƒãƒˆæ‹¡å¼µLightGBM', precision1, len(strategy1_preds)))
            logger.info(f"  çµæœ: {precision1:.2%}")
        
        # === æˆ¦ç•¥2: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ä¸Šä½2éŠ˜æŸ„ ===
        logger.info("ğŸ”¥ æˆ¦ç•¥2: ãƒãƒ¼ã‚±ãƒƒãƒˆæ‹¡å¼µã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«")
        
        strategy2_preds = []
        strategy2_actuals = []
        
        for test_date in test_dates[-10:]:
            train_data = df_sorted[df_sorted['Date'] < test_date]
            test_data = df_sorted[df_sorted['Date'] == test_date]
            
            train_clean = train_data.dropna(subset=['Target'] + feature_cols)
            test_clean = test_data.dropna(subset=['Target'] + feature_cols)
            
            if len(train_clean) < 500 or len(test_clean) < 2:
                continue
            
            X_train = train_clean[feature_cols]
            y_train = train_clean['Target']
            X_test = test_clean[feature_cols]
            y_test = test_clean['Target']
            
            # ç‰¹å¾´é‡é¸æŠ
            selector = SelectKBest(score_func=f_classif, k=min(15, len(feature_cols)))
            X_train_selected = selector.fit_transform(X_train, y_train)
            X_test_selected = selector.transform(X_test)
            
            scaler = RobustScaler()
            X_train_scaled = scaler.fit_transform(X_train_selected)
            X_test_scaled = scaler.transform(X_test_selected)
            
            # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
            models = [
                lgb.LGBMClassifier(n_estimators=100, max_depth=3, random_state=42, verbose=-1),
                RandomForestClassifier(n_estimators=100, max_depth=4, random_state=43)
            ]
            
            ensemble_probs = []
            for model in models:
                model.fit(X_train_scaled, y_train)
                probs = model.predict_proba(X_test_scaled)[:, 1]
                ensemble_probs.append(probs)
            
            avg_probs = np.mean(ensemble_probs, axis=0)
            
            # ä¸Šä½2éŠ˜æŸ„é¸æŠ
            n_select = min(2, len(avg_probs))
            top_indices = np.argsort(avg_probs)[-n_select:]
            
            selected_actuals = y_test.iloc[top_indices].values
            strategy2_preds.extend([1] * len(selected_actuals))
            strategy2_actuals.extend(selected_actuals)
        
        if strategy2_preds:
            precision2 = sum(strategy2_actuals) / len(strategy2_actuals)
            strategies.append(('ãƒãƒ¼ã‚±ãƒƒãƒˆæ‹¡å¼µã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«', precision2, len(strategy2_preds)))
            logger.info(f"  çµæœ: {precision2:.2%}")
        
        # çµæœè¡¨ç¤º
        print("\\n" + "="*70)
        print("ğŸ¯ ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã«ã‚ˆã‚‹60%ç²¾åº¦ãƒ†ã‚¹ãƒˆçµæœ")
        print("="*70)
        
        print(f"{'æˆ¦ç•¥å':<25} {'ç²¾åº¦':<12} {'é¸æŠæ•°':<8} {'60%é”æˆ'}")
        print("-"*55)
        
        best_precision = 0
        success = False
        
        for name, precision, count in sorted(strategies, key=lambda x: x[1], reverse=True):
            status = "âœ… YES" if precision >= 0.60 else "âŒ NO"
            print(f"{name:<25} {precision:<12.2%} {count:<8d} {status}")
            
            if precision >= 0.60:
                success = True
            if precision > best_precision:
                best_precision = precision
        
        if success:
            print(f"\\nğŸ‰ ã€60%ç²¾åº¦é”æˆæˆåŠŸï¼ã€‘")
            print(f"ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã®çµ±åˆã«ã‚ˆã‚Š60%ã‚’é”æˆã—ã¾ã—ãŸï¼")
        else:
            print(f"\\nğŸ“Š çµæœåˆ†æ:")
            print(f"æœ€é«˜ç²¾åº¦: {best_precision:.2%}")
            print(f"å¾“æ¥ã®56%ã‹ã‚‰{best_precision-0.56:.1%}ãƒã‚¤ãƒ³ãƒˆæ”¹å–„")
            if best_precision >= 0.58:
                print("ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã§60%é”æˆå¯èƒ½")
            else:
                print("ã•ã‚‰ãªã‚‹ãƒ‡ãƒ¼ã‚¿çµ±åˆãŒå¿…è¦")
        
        return success

# å®Ÿè¡Œ
if __name__ == "__main__":
    test = MarketDataOnlyTest()
    success = test.run_market_enhanced_test()
    
    if success:
        print("\\nğŸ‰ ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿çµ±åˆã«ã‚ˆã‚Š60%ç²¾åº¦é”æˆæˆåŠŸï¼")
    else:
        print("\\nâš ï¸ ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã§60%é”æˆã‚’ç›®æŒ‡ã—ã¾ã—ã‚‡ã†")