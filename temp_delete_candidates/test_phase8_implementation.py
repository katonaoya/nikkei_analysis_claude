#!/usr/bin/env python3
"""
Phase 8: Model and Data Accuracy Improvement - Implementation with Test Data
Alternative approach using enhanced test data while J-Quants API issues are resolved
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Add project root to path
import sys
sys.path.append(str(Path(__file__).parent))

from src.features.feature_pipeline import FeaturePipeline, create_feature_pipeline
from src.data.label_creator import LabelCreator
from src.models.ensemble_model import EnsembleModel
from src.evaluation.metrics_calculator import MetricsCalculator
from src.evaluation.backtester import Backtester
from utils.logger import get_logger

def create_realistic_stock_data():
    """Create realistic Japanese stock data for Phase 8 testing"""
    
    print("ğŸ”„ Phase 8ç”¨ãƒªã‚¢ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
    
    # Extended date range for more robust testing (1 year)
    start_date = pd.Timestamp('2023-01-01')
    end_date = pd.Timestamp('2023-12-31')
    business_dates = pd.bdate_range(start=start_date, end=end_date, freq='B')
    
    # Realistic Nikkei 225 stock codes with different characteristics
    stocks = {
        '1301': {'name': 'æ¥µæ´‹', 'sector': 'Foods', 'volatility': 0.02, 'trend': 0.0001},
        '1332': {'name': 'æ—¥æ°´', 'sector': 'Foods', 'volatility': 0.025, 'trend': -0.0002},
        '1333': {'name': 'ãƒãƒ«ãƒãƒ‹ãƒãƒ­', 'sector': 'Foods', 'volatility': 0.02, 'trend': 0.0003},
        '4755': {'name': 'æ¥½å¤©G', 'sector': 'IT', 'volatility': 0.04, 'trend': 0.0005},
        '6758': {'name': 'ã‚½ãƒ‹ãƒ¼G', 'sector': 'Electronics', 'volatility': 0.03, 'trend': 0.0002},
        '7203': {'name': 'ãƒˆãƒ¨ã‚¿', 'sector': 'Auto', 'volatility': 0.025, 'trend': 0.0001},
        '8035': {'name': 'æ±äº¬ã‚¨ãƒ¬ã‚¯', 'sector': 'Semiconductors', 'volatility': 0.045, 'trend': 0.0004},
        '9432': {'name': 'NTT', 'sector': 'Telecom', 'volatility': 0.02, 'trend': 0.0001},
        '9984': {'name': 'ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯G', 'sector': 'IT', 'volatility': 0.05, 'trend': 0.0003}
    }
    
    stock_data = []
    np.random.seed(42)
    
    for code, info in stocks.items():
        # Starting price varies by company size
        base_price = np.random.uniform(800, 3000)  # Realistic price range
        current_price = base_price
        
        for i, date in enumerate(business_dates):
            # Market regime effects (simulate market cycles)
            market_cycle = np.sin(2 * np.pi * i / 60) * 0.002  # 60-day cycle
            volatility_regime = 1 + 0.3 * np.sin(2 * np.pi * i / 120)  # Volatility cycle
            
            # Daily return with realistic characteristics
            trend_component = info['trend']
            random_component = np.random.normal(0, info['volatility'] * volatility_regime)
            market_component = market_cycle
            
            daily_return = trend_component + random_component + market_component
            
            # Price bounds to prevent unrealistic values
            new_price = current_price * (1 + daily_return)
            new_price = max(new_price, base_price * 0.3)  # Floor
            new_price = min(new_price, base_price * 3.0)   # Ceiling
            
            # Generate OHLCV with realistic intraday patterns
            open_price = current_price
            close_price = new_price
            
            # High/Low with realistic spreads
            daily_range = abs(close_price - open_price) * np.random.uniform(1.2, 2.5)
            high_price = max(open_price, close_price) + daily_range * np.random.uniform(0, 0.5)
            low_price = min(open_price, close_price) - daily_range * np.random.uniform(0, 0.5)
            
            # Volume correlated with price movement and volatility
            volume_base = 1000000  # Base volume
            volume_multiplier = 1 + 2 * abs(daily_return) + 0.5 * np.random.exponential(0.5)
            volume = int(volume_base * volume_multiplier)
            
            stock_data.append({
                'Date': date,
                'Code': code,
                'Open': round(open_price, 2),
                'High': round(high_price, 2),
                'Low': round(low_price, 2),
                'Close': round(close_price, 2),
                'Volume': volume,
                'Sector': info['sector'],
                'Name': info['name']
            })
            
            current_price = close_price
    
    df = pd.DataFrame(stock_data)
    print(f"âœ… ç”Ÿæˆå®Œäº†: {len(df)}ãƒ¬ã‚³ãƒ¼ãƒ‰, {len(stocks)}éŠ˜æŸ„, {len(business_dates)}å–¶æ¥­æ—¥")
    return df

def create_realistic_external_data(business_dates):
    """Create realistic external market data (USD/JPY, VIX, etc.)"""
    
    print("ğŸ”„ å¤–éƒ¨æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
    
    external_data = []
    np.random.seed(43)
    
    # USD/JPY starting around 130
    usdjpy_price = 130.0
    
    # VIX starting around 20
    vix_level = 20.0
    
    for i, date in enumerate(business_dates):
        # USD/JPY movement
        usdjpy_return = np.random.normal(0.0001, 0.008)  # Realistic FX volatility
        usdjpy_price = usdjpy_price * (1 + usdjpy_return)
        usdjpy_price = max(120, min(usdjpy_price, 150))  # Reasonable bounds
        
        # VIX movement (mean-reverting)
        vix_return = -0.05 * (vix_level - 20) / 20 + np.random.normal(0, 0.15)
        vix_level = vix_level * (1 + vix_return)
        vix_level = max(10, min(vix_level, 80))  # VIX bounds
        
        external_data.append({
            'Date': date,
            'USDJPY': round(usdjpy_price, 4),
            'VIX': round(vix_level, 2),
            'NIKKEI_FUTURES': round(28000 + np.random.normal(0, 500), 2),  # Mock futures
            'TOPIX': round(2000 + np.random.normal(0, 50), 2)  # Mock TOPIX
        })
    
    df = pd.DataFrame(external_data)
    print(f"âœ… å¤–éƒ¨æŒ‡æ¨™ç”Ÿæˆå®Œäº†: {len(df)}ãƒ¬ã‚³ãƒ¼ãƒ‰")
    return df

def run_phase8_feature_importance_analysis():
    """Phase 8.1: Feature importance analysis and optimization"""
    
    print("\n" + "="*60)
    print("ğŸ¯ Phase 8.1: ç‰¹å¾´é‡é‡è¦åº¦åˆ†æãƒ»æœ€é©åŒ–")
    print("="*60)
    
    # Generate comprehensive dataset
    stock_data = create_realistic_stock_data()
    business_dates = stock_data['Date'].unique()
    external_data = create_realistic_external_data(business_dates)
    
    # Create features
    print("\nğŸ”„ ç‰¹å¾´é‡ç”Ÿæˆä¸­...")
    feature_pipeline = create_feature_pipeline()
    
    # Merge stock and external data
    merged_data = stock_data.merge(external_data, on='Date', how='left')
    
    # Generate features for each stock
    feature_data_list = []
    for code in stock_data['Code'].unique():
        code_data = merged_data[merged_data['Code'] == code].copy()
        code_features = feature_pipeline.create_basic_features(code_data)
        feature_data_list.append(code_features)
    
    all_features = pd.concat(feature_data_list, ignore_index=True)
    print(f"âœ… ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {len(all_features)}ãƒ¬ã‚³ãƒ¼ãƒ‰, {len(all_features.columns)}ç‰¹å¾´é‡")
    
    # Create labels
    print("\nğŸ”„ ãƒ©ãƒ™ãƒ«ä½œæˆä¸­...")
    label_creator = LabelCreator()
    labeled_data = label_creator.create_binary_labels(all_features)
    print(f"âœ… ãƒ©ãƒ™ãƒ«ä½œæˆå®Œäº†: {labeled_data['target'].sum()}ä»¶ã®Positiveä¾‹")
    
    # Feature importance analysis
    print("\nğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦åˆ†æå®Ÿè¡Œä¸­...")
    
    # Prepare data for modeling
    feature_columns = [col for col in labeled_data.columns if col.startswith(('MA_', 'RSI', 'MACD', 'BB_', 'Volume', 'Price', 'Return'))]
    X = labeled_data[feature_columns].fillna(0)
    y = labeled_data['target']
    
    if len(X) == 0 or X.shape[1] == 0:
        print("âŒ ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãŒä¸æ­£ã§ã™")
        return None
    
    # Split data for training
    split_idx = int(len(X) * 0.8)
    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]
    
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train)}ã‚µãƒ³ãƒ—ãƒ«, ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(X_test)}ã‚µãƒ³ãƒ—ãƒ«")
    print(f"Positiveç‡ - è¨“ç·´: {y_train.mean():.3f}, ãƒ†ã‚¹ãƒˆ: {y_test.mean():.3f}")
    
    return {
        'features': labeled_data,
        'feature_columns': feature_columns,
        'X_train': X_train, 'X_test': X_test,
        'y_train': y_train, 'y_test': y_test,
        'stock_data': stock_data,
        'external_data': external_data
    }

def run_phase8_baseline_evaluation(data_dict):
    """Phase 8.2: Baseline model evaluation"""
    
    print("\n" + "="*60)
    print("ğŸ¯ Phase 8.2: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç²¾åº¦æ¸¬å®š")
    print("="*60)
    
    X_train = data_dict['X_train']
    X_test = data_dict['X_test']
    y_train = data_dict['y_train']
    y_test = data_dict['y_test']
    
    # Train ensemble model
    print("ğŸ”„ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­...")
    ensemble_model = EnsembleModel()
    
    try:
        ensemble_model.fit(X_train, y_train)
        print("âœ… ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†")
        
        # Predictions
        y_pred_proba = ensemble_model.predict_proba(X_test)
        
        # Evaluation
        print("\nğŸ“Š ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç²¾åº¦è©•ä¾¡ä¸­...")
        metrics_calc = MetricsCalculator()
        
        # Basic metrics
        basic_metrics = metrics_calc.calculate_basic_metrics(y_test, y_pred_proba)
        
        print("\n" + "-"*30)
        print("ğŸ“ˆ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç²¾åº¦çµæœ:")
        print("-"*30)
        print(f"Precision: {basic_metrics['precision']:.3f}")
        print(f"Recall: {basic_metrics['recall']:.3f}")
        print(f"F1 Score: {basic_metrics['f1_score']:.3f}")
        print(f"ROC AUC: {basic_metrics['roc_auc']:.3f}")
        
        # Target achievement check
        target_precision = 0.75
        precision_gap = basic_metrics['precision'] - target_precision
        
        print(f"\nğŸ¯ ç›®æ¨™é”æˆçŠ¶æ³:")
        print(f"ç›®æ¨™Precision: {target_precision:.3f}")
        print(f"ç¾åœ¨Precision: {basic_metrics['precision']:.3f}")
        print(f"å·®åˆ†: {precision_gap:+.3f}")
        
        if precision_gap >= 0:
            print("âœ… ç›®æ¨™é”æˆ!")
        else:
            print(f"âš ï¸  ç›®æ¨™ã¾ã§ {abs(precision_gap):.3f} ã®æ”¹å–„ãŒå¿…è¦")
        
        return {
            'model': ensemble_model,
            'predictions': y_pred_proba,
            'metrics': basic_metrics,
            'precision_gap': precision_gap
        }
        
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

def run_phase8_optimization(data_dict, baseline_results):
    """Phase 8.3: Model optimization and improvement"""
    
    print("\n" + "="*60)
    print("ğŸ¯ Phase 8.3: ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–ãƒ»æ”¹å–„")
    print("="*60)
    
    precision_gap = baseline_results['precision_gap']
    
    if precision_gap >= 0:
        print("âœ… ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç²¾åº¦ãŒæ—¢ã«ç›®æ¨™ã‚’é”æˆã—ã¦ã„ã¾ã™")
        print("ã•ã‚‰ãªã‚‹æ”¹å–„ã‚’è©¦è¡Œã—ã¾ã™...")
    
    print("\nğŸ”§ æœ€é©åŒ–æˆ¦ç•¥:")
    print("1. ç‰¹å¾´é‡é‡è¦åº¦ã«åŸºã¥ãç‰¹å¾´é¸æŠ")
    print("2. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–")
    print("3. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿èª¿æ•´")
    print("4. é–¾å€¤æœ€é©åŒ–")
    
    # Feature importance analysis
    print("\nğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ...")
    model = baseline_results['model']
    feature_columns = data_dict['feature_columns']
    
    # Get feature importance from ensemble
    try:
        importances = model.get_feature_importance()
        if importances is not None:
            feature_importance = pd.DataFrame({
                'feature': feature_columns,
                'importance': importances
            }).sort_values('importance', ascending=False)
            
            print("\nTop 10 é‡è¦ç‰¹å¾´é‡:")
            print(feature_importance.head(10).to_string(index=False))
            
        else:
            print("âš ï¸  ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            
    except Exception as e:
        print(f"âš ï¸  ç‰¹å¾´é‡é‡è¦åº¦åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # Threshold optimization
    print("\nğŸ¯ æœ€é©é–¾å€¤æ¢ç´¢...")
    metrics_calc = MetricsCalculator()
    
    y_test = data_dict['y_test']
    y_pred_proba = baseline_results['predictions']
    
    try:
        optimal_threshold = metrics_calc.find_optimal_threshold(
            y_test, y_pred_proba, metric='f1_score'
        )
        
        print(f"æœ€é©é–¾å€¤ (F1): {optimal_threshold['threshold']:.3f}")
        print(f"æ”¹å–„å¾ŒPrecision: {optimal_threshold['metrics']['precision']:.3f}")
        print(f"æ”¹å–„å¾ŒF1 Score: {optimal_threshold['metrics']['f1_score']:.3f}")
        
        # Check if optimization helps achieve target
        optimized_precision = optimal_threshold['metrics']['precision']
        optimized_gap = optimized_precision - 0.75
        
        print(f"\nğŸ“ˆ æœ€é©åŒ–åŠ¹æœ:")
        print(f"Precisionæ”¹å–„: {optimized_precision - baseline_results['metrics']['precision']:+.3f}")
        print(f"ç›®æ¨™ã¨ã®å·®: {optimized_gap:+.3f}")
        
        return {
            'optimized_threshold': optimal_threshold['threshold'],
            'optimized_metrics': optimal_threshold['metrics'],
            'precision_improvement': optimized_precision - baseline_results['metrics']['precision']
        }
        
    except Exception as e:
        print(f"âŒ æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

def main():
    """Main Phase 8 implementation function"""
    
    print("ğŸš€ Phase 8: ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿ç²¾åº¦å‘ä¸Š - å®Ÿè£…é–‹å§‹")
    print("=" * 80)
    print("æ³¨: J-Quants APIå•é¡Œã«ã‚ˆã‚Šã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®å®Ÿè£…ã‚’å®Ÿè¡Œã—ã¾ã™")
    print("=" * 80)
    
    logger = get_logger("phase8_implementation")
    
    try:
        # Step 1: Feature importance analysis
        data_dict = run_phase8_feature_importance_analysis()
        if data_dict is None:
            return False
        
        # Step 2: Baseline evaluation
        baseline_results = run_phase8_baseline_evaluation(data_dict)
        if baseline_results is None:
            return False
        
        # Step 3: Model optimization
        optimization_results = run_phase8_optimization(data_dict, baseline_results)
        
        # Summary
        print("\n" + "="*80)
        print("ğŸ“‹ Phase 8 å®Ÿè£…ã‚µãƒãƒªãƒ¼")
        print("="*80)
        
        basic_metrics = baseline_results['metrics']
        print(f"âœ… ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç²¾åº¦æ¸¬å®šå®Œäº†")
        print(f"   - Precision: {basic_metrics['precision']:.3f}")
        print(f"   - F1 Score: {basic_metrics['f1_score']:.3f}")
        print(f"   - ROC AUC: {basic_metrics['roc_auc']:.3f}")
        
        if optimization_results:
            opt_metrics = optimization_results['optimized_metrics']
            print(f"âœ… ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–å®Œäº†")
            print(f"   - æœ€é©åŒ–å¾ŒPrecision: {opt_metrics['precision']:.3f}")
            print(f"   - æ”¹å–„å¹…: {optimization_results['precision_improvement']:+.3f}")
            
            final_precision = opt_metrics['precision']
        else:
            final_precision = basic_metrics['precision']
        
        # Target achievement
        target_precision = 0.75
        if final_precision >= target_precision:
            print(f"ğŸ‰ ç›®æ¨™é”æˆ! Precision {final_precision:.3f} â‰¥ {target_precision}")
        else:
            shortfall = target_precision - final_precision
            print(f"âš ï¸  ç›®æ¨™æœªé”æˆ: ã‚ã¨ {shortfall:.3f} ã®æ”¹å–„ãŒå¿…è¦")
            print("   â†’ å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®å†è©•ä¾¡ãƒ»ã•ã‚‰ãªã‚‹æ”¹å–„ãŒå¿…è¦")
        
        print(f"\nğŸ”„ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print(f"   1. J-Quants APIå•é¡Œè§£æ±ºå¾Œã®å®Ÿãƒ‡ãƒ¼ã‚¿è©•ä¾¡")
        print(f"   2. Phase 9: çµ±åˆã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…")
        
        logger.info("Phase 8 implementation completed", 
                   final_precision=final_precision,
                   target_achieved=final_precision >= target_precision)
        
        return True
        
    except Exception as e:
        print(f"âŒ Phase 8å®Ÿè£…ã‚¨ãƒ©ãƒ¼: {str(e)}")
        logger.error("Phase 8 implementation failed", error=str(e))
        return False

if __name__ == "__main__":
    main()