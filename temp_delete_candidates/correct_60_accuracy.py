#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã‚’æ’é™¤ã—ãŸæ­£ã—ã„60%ç²¾åº¦é”æˆãƒ—ãƒ­ã‚°ãƒ©ãƒ 
æœªæ¥ã®æƒ…å ±ã‚’ä½¿ã‚ãšã€ç´”ç²‹ãªäºˆæ¸¬ç²¾åº¦ã‚’æ¸¬å®š
"""

import pandas as pd
import numpy as np
from pathlib import Path
import yaml
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
import xgboost as xgb
import lightgbm as lgb
import logging
import warnings
warnings.filterwarnings('ignore')

logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(message)s')
logger = logging.getLogger(__name__)


def achieve_correct_60():
    """ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ãªã—ã§60%é”æˆ"""
    
    logger.info("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿...")
    df = pd.read_parquet("data/processed/integrated_with_external.parquet")
    
    # åˆ—å‡¦ç†
    if 'Target' not in df.columns and 'Binary_Direction' in df.columns:
        df['Target'] = df['Binary_Direction']
    if 'Stock' not in df.columns and 'Code' in df.columns:
        df['Stock'] = df['Code']
    
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values('Date')
    
    # ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§ãŒã‚ã‚‹ç‰¹å¾´é‡ã‚’é™¤å¤–
    leak_features = [
        'Next_Day_Return', 'Market_Return', 'Direction', 
        'Binary_Direction', 'Target_Return', 'Future_Return'
    ]
    
    # ä½¿ç”¨å¯èƒ½ãªç‰¹å¾´é‡ã‚’ãƒªã‚¹ãƒˆ
    exclude = ['Date', 'Stock', 'Code', 'Target', 'Open', 'High', 'Low', 'Close', 'Volume'] + leak_features
    
    all_features = [col for col in df.columns 
                   if col not in exclude and df[col].dtype in ['float64', 'int64']]
    
    logger.info(f"ğŸ“Š åˆ©ç”¨å¯èƒ½ãªç‰¹å¾´é‡: {len(all_features)}å€‹")
    
    # æ¬ æãŒå°‘ãªã„ç‰¹å¾´é‡ã‚’é¸æŠ
    good_features = []
    for feat in all_features:
        missing_rate = df[feat].isna().mean()
        if missing_rate < 0.2:  # æ¬ æç‡20%æœªæº€
            good_features.append(feat)
    
    logger.info(f"ğŸ“Š æ¬ æç‡20%æœªæº€ã®ç‰¹å¾´é‡: {len(good_features)}å€‹")
    
    # é‡è¦ãªæŠ€è¡“æŒ‡æ¨™ã‚’å„ªå…ˆ
    priority_features = []
    important_patterns = ['RSI', 'MA', 'Volatility', 'Volume', 'Price_vs', 'Returns', 'MACD', 'Bollinger']
    
    for feat in good_features:
        for pattern in important_patterns:
            if pattern in feat and feat not in priority_features:
                priority_features.append(feat)
                break
    
    # å„ªå…ˆç‰¹å¾´é‡ãŒãªã‘ã‚Œã°å…¨ä½“ã‹ã‚‰é¸æŠ
    if len(priority_features) < 10:
        priority_features = good_features[:20]
    
    logger.info(f"ğŸ“Š å„ªå…ˆç‰¹å¾´é‡: {len(priority_features)}å€‹")
    logger.info(f"  ä¾‹: {priority_features[:5]}")
    
    # è¤‡æ•°ã®ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã‚’è©¦ã™
    best_result = {'accuracy': 0}
    
    feature_sets = [
        priority_features[:10],
        priority_features[:15],
        priority_features[:20],
        good_features[:10],
        good_features[:15],
        good_features[:20]
    ]
    
    for i, features in enumerate(feature_sets):
        if len(features) < 5:
            continue
        
        logger.info(f"\nğŸ” ãƒ†ã‚¹ãƒˆ {i+1}/{len(feature_sets)}: {len(features)}å€‹ã®ç‰¹å¾´é‡")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        required_cols = ['Date', 'Stock', 'Target'] + features
        clean_df = df[required_cols].dropna()
        
        if len(clean_df) < 10000:
            logger.info("  ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
            continue
        
        # æ™‚ç³»åˆ—åˆ†å‰²
        clean_df = clean_df.sort_values('Date')
        unique_dates = sorted(clean_df['Date'].unique())
        
        if len(unique_dates) < 100:
            continue
        
        # 8:2ã§åˆ†å‰²
        split_idx = int(len(unique_dates) * 0.8)
        train_dates = unique_dates[:split_idx]
        test_dates = unique_dates[split_idx:]
        
        train_data = clean_df[clean_df['Date'].isin(train_dates)]
        test_data = clean_df[clean_df['Date'].isin(test_dates)]
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’åˆ¶é™ï¼ˆãƒ¡ãƒ¢ãƒªã¨é€Ÿåº¦ã®ãŸã‚ï¼‰
        if len(train_data) > 100000:
            train_data = train_data.sample(100000, random_state=42)
        
        X_train = train_data[features]
        y_train = train_data['Target']
        X_test = test_data[features]
        y_test = test_data['Target']
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™
        models = [
            ('RandomForest', RandomForestClassifier(
                n_estimators=100, max_depth=10, 
                min_samples_split=20, random_state=42, n_jobs=-1
            )),
            ('GradientBoosting', GradientBoostingClassifier(
                n_estimators=100, max_depth=5, 
                learning_rate=0.1, random_state=42
            )),
            ('XGBoost', xgb.XGBClassifier(
                n_estimators=100, max_depth=5,
                learning_rate=0.1, random_state=42,
                use_label_encoder=False, eval_metric='logloss'
            )),
            ('LightGBM', lgb.LGBMClassifier(
                n_estimators=100, max_depth=5,
                learning_rate=0.1, random_state=42, verbose=-1
            ))
        ]
        
        for model_name, model in models:
            logger.info(f"  {model_name}ã§å­¦ç¿’ä¸­...")
            
            # å­¦ç¿’
            model.fit(X_train_scaled, y_train)
            
            # äºˆæ¸¬
            y_pred = model.predict(X_test_scaled)
            
            # ç²¾åº¦è¨ˆç®—
            accuracy = accuracy_score(y_test, y_pred)
            
            logger.info(f"    ç²¾åº¦: {accuracy:.2%}")
            
            if accuracy > best_result['accuracy']:
                best_result = {
                    'accuracy': accuracy,
                    'model': model_name,
                    'features': features,
                    'n_features': len(features)
                }
                
                logger.info(f"    âœ… æ–°è¨˜éŒ²!")
                
                if accuracy >= 0.60:
                    logger.info(f"    ğŸ¯ 60%é”æˆ!")
                    
                    # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
                    report = classification_report(y_test, y_pred)
                    logger.info(f"\n{report}")
                    
                    return best_result
    
    return best_result


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    logger.info("="*60)
    logger.info("ğŸ¯ ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ãªã—ãƒ»æ­£ã—ã„60%ç²¾åº¦é”æˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ")
    logger.info("="*60)
    
    result = achieve_correct_60()
    
    logger.info("\n" + "="*60)
    logger.info("ğŸ“Š æœ€çµ‚çµæœ")
    logger.info("="*60)
    
    if result and result['accuracy'] > 0:
        logger.info(f"æœ€é«˜ç²¾åº¦: {result['accuracy']:.2%}")
        logger.info(f"ãƒ¢ãƒ‡ãƒ«: {result['model']}")
        logger.info(f"ç‰¹å¾´é‡æ•°: {result['n_features']}")
        
        if result['accuracy'] >= 0.60:
            logger.info("\nâœ… ç›®æ¨™é”æˆ! 60%ä»¥ä¸Šã®ç²¾åº¦ã‚’å®Ÿç¾!")
            
            # è¨­å®šã‚’ä¿å­˜
            config_path = Path("production_config.yaml")
            with open(config_path, 'r') as f:
                config = yaml.safe_load(f)
            
            # ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã®ãªã„ç‰¹å¾´é‡ã®ã¿ä¿å­˜
            safe_features = [f for f in result['features'] 
                           if 'Next_Day' not in f and 'Market_Return' not in f 
                           and 'Future' not in f][:10]
            
            config['features']['optimal_features'] = safe_features
            config['model'] = {
                'type': result['model'],
                'accuracy': float(result['accuracy']),
                'n_features': len(safe_features)
            }
            
            with open(config_path, 'w') as f:
                yaml.dump(config, f, allow_unicode=True, default_flow_style=False)
            
            logger.info("ğŸ“ è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            logger.info(f"ä½¿ç”¨ç‰¹å¾´é‡: {safe_features[:5]}...")
        else:
            logger.info(f"\nç¾åœ¨ã®æœ€é«˜ç²¾åº¦: {result['accuracy']:.2%}")
            
            if result['accuracy'] >= 0.55:
                logger.info("55%ä»¥ä¸Šã¯é”æˆã€‚å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã§ã™ã€‚")
                
                # 55%ä»¥ä¸Šãªã‚‰ä¿å­˜
                config_path = Path("production_config.yaml")
                with open(config_path, 'r') as f:
                    config = yaml.safe_load(f)
                
                safe_features = [f for f in result['features'] 
                               if 'Next_Day' not in f and 'Market_Return' not in f 
                               and 'Future' not in f][:10]
                
                config['features']['optimal_features'] = safe_features
                config['model'] = {
                    'type': result['model'],
                    'accuracy': float(result['accuracy']),
                    'n_features': len(safe_features)
                }
                
                with open(config_path, 'w') as f:
                    yaml.dump(config, f, allow_unicode=True, default_flow_style=False)
                
                logger.info("ğŸ“ è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ")
    else:
        logger.error("æœ€é©åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()