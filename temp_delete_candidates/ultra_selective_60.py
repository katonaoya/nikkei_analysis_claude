#!/usr/bin/env python3
"""
è¶…å³é¸60%ç²¾åº¦ãƒãƒ£ãƒ¬ãƒ³ã‚¸
æ¥µç«¯ã«å³ã—ã„æ¡ä»¶ã§60%çªç ´ã‚’ç›®æŒ‡ã™
"""

import pandas as pd
import numpy as np
from datetime import datetime
import lightgbm as lgb
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import RobustScaler
import warnings
warnings.filterwarnings('ignore')

def ultra_selective_60():
    """è¶…å³é¸60%ãƒãƒ£ãƒ¬ãƒ³ã‚¸"""
    
    print("ğŸ¯ è¶…å³é¸60%ç²¾åº¦ãƒãƒ£ãƒ¬ãƒ³ã‚¸é–‹å§‹")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = pd.read_parquet('data/processed/integrated_with_external.parquet')
    
    # ã‚«ãƒ©ãƒ èª¿æ•´
    if 'date' in df.columns:
        df['Date'] = pd.to_datetime(df['date'])
    if 'code' in df.columns:
        df['Stock'] = df['code']
    
    # ç‰¹å¾´é‡ç”Ÿæˆ
    print("ğŸ”§ é«˜ç²¾åº¦ç‰¹å¾´é‡ç”Ÿæˆ...")
    
    features = []
    for stock, stock_df in df.groupby('Stock'):
        stock_df = stock_df.sort_values('Date')
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆç¿Œæ—¥1%ä»¥ä¸Šã®ä¸Šæ˜‡ï¼‰
        stock_df['next_close'] = stock_df['close'].shift(-1)
        stock_df['Target'] = (stock_df['next_close'] > stock_df['close'] * 1.01).astype(int)
        
        # RSI
        delta = stock_df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss.replace(0, 1)
        stock_df['RSI'] = 100 - (100 / (1 + rs))
        
        # ç§»å‹•å¹³å‡ä¹–é›¢
        stock_df['MA5'] = stock_df['close'].rolling(5).mean()
        stock_df['MA20'] = stock_df['close'].rolling(20).mean()
        stock_df['Price_vs_MA5'] = (stock_df['close'] - stock_df['MA5']) / stock_df['MA5']
        stock_df['Price_vs_MA20'] = (stock_df['close'] - stock_df['MA20']) / stock_df['MA20']
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        stock_df['Return'] = stock_df['close'].pct_change()
        stock_df['Volatility'] = stock_df['Return'].rolling(20).std()
        
        # å‡ºæ¥é«˜
        stock_df['Volume_MA'] = stock_df['volume'].rolling(20).mean()
        stock_df['Volume_Ratio'] = stock_df['volume'] / stock_df['Volume_MA'].replace(0, 1)
        
        # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ 
        stock_df['Momentum_5'] = stock_df['close'].pct_change(5)
        
        # ä¾¡æ ¼ä½ç½®
        stock_df['High_20'] = stock_df['high'].rolling(20).max()
        stock_df['Low_20'] = stock_df['low'].rolling(20).min()
        stock_df['Price_Position'] = (stock_df['close'] - stock_df['Low_20']) / (stock_df['High_20'] - stock_df['Low_20'])
        
        features.append(stock_df)
    
    df = pd.concat(features, ignore_index=True)
    feature_cols = ['RSI', 'Price_vs_MA5', 'Price_vs_MA20', 'Volatility', 'Volume_Ratio', 'Momentum_5', 'Price_Position']
    
    # ãƒ†ã‚¹ãƒˆæœŸé–“
    df_sorted = df.sort_values('Date')
    unique_dates = sorted(df_sorted['Date'].unique())
    test_dates = unique_dates[-7:]  # æœ€æ–°7æ—¥
    
    print(f"ãƒ†ã‚¹ãƒˆæœŸé–“: {len(test_dates)}æ—¥")
    print(f"ä½¿ç”¨ç‰¹å¾´é‡: {len(feature_cols)}å€‹")
    
    # è¶…å³é¸æˆ¦ç•¥ç¾¤
    strategies = []
    
    # === æˆ¦ç•¥1: è¶…é«˜é–¾å€¤ï¼ˆ85%ä»¥ä¸Šï¼‰ ===
    print("\nğŸ¯ æˆ¦ç•¥1: è¶…é«˜é–¾å€¤85%")
    
    model1 = lgb.LGBMClassifier(
        n_estimators=100,
        max_depth=3,
        learning_rate=0.05,
        random_state=42,
        verbose=-1
    )
    
    all_preds_1 = []
    all_actuals_1 = []
    
    for test_date in test_dates[-5:]:
        train = df_sorted[df_sorted['Date'] < test_date]
        test = df_sorted[df_sorted['Date'] == test_date]
        
        train_clean = train.dropna(subset=['Target'] + feature_cols)
        test_clean = test.dropna(subset=['Target'] + feature_cols)
        
        if len(train_clean) < 2000 or len(test_clean) < 10:
            continue
        
        X_train = train_clean[feature_cols]
        y_train = train_clean['Target']
        X_test = test_clean[feature_cols]
        y_test = test_clean['Target']
        
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        model1.fit(X_train_scaled, y_train)
        probs = model1.predict_proba(X_test_scaled)[:, 1]
        
        # 85%ä»¥ä¸Šã®éŠ˜æŸ„ã®ã¿é¸æŠ
        high_conf = probs >= 0.85
        if sum(high_conf) > 0:
            selected = y_test[high_conf].values
            all_preds_1.extend(np.ones(len(selected)))
            all_actuals_1.extend(selected)
    
    if len(all_preds_1) > 0:
        precision_1 = sum(all_actuals_1) / len(all_actuals_1)
        strategies.append(('è¶…é«˜é–¾å€¤85%', precision_1, len(all_preds_1)))
        print(f"  çµæœ: ç²¾åº¦{precision_1:.1%}, é¸æŠæ•°{len(all_preds_1)}")
    
    # === æˆ¦ç•¥2: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆæ„ï¼ˆ80%ä»¥ä¸Šï¼‰ ===
    print("\nğŸ”¥ æˆ¦ç•¥2: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆæ„80%")
    
    models = [
        lgb.LGBMClassifier(n_estimators=100, max_depth=3, random_state=42, verbose=-1),
        RandomForestClassifier(n_estimators=100, max_depth=4, random_state=42)
    ]
    
    all_preds_2 = []
    all_actuals_2 = []
    
    for test_date in test_dates[-5:]:
        train = df_sorted[df_sorted['Date'] < test_date]
        test = df_sorted[df_sorted['Date'] == test_date]
        
        train_clean = train.dropna(subset=['Target'] + feature_cols)
        test_clean = test.dropna(subset=['Target'] + feature_cols)
        
        if len(train_clean) < 2000 or len(test_clean) < 10:
            continue
        
        X_train = train_clean[feature_cols]
        y_train = train_clean['Target']
        X_test = test_clean[feature_cols]
        y_test = test_clean['Target']
        
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # ä¸¡ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
        probs_list = []
        for model in models:
            model.fit(X_train_scaled, y_train)
            probs = model.predict_proba(X_test_scaled)[:, 1]
            probs_list.append(probs)
        
        # ä¸¡ãƒ¢ãƒ‡ãƒ«ãŒ80%ä»¥ä¸Šã§åˆæ„
        consensus = np.all([probs >= 0.80 for probs in probs_list], axis=0)
        
        if sum(consensus) > 0:
            selected = y_test[consensus].values
            all_preds_2.extend(np.ones(len(selected)))
            all_actuals_2.extend(selected)
    
    if len(all_preds_2) > 0:
        precision_2 = sum(all_actuals_2) / len(all_actuals_2)
        strategies.append(('ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆæ„80%', precision_2, len(all_preds_2)))
        print(f"  çµæœ: ç²¾åº¦{precision_2:.1%}, é¸æŠæ•°{len(all_preds_2)}")
    
    # === æˆ¦ç•¥3: ä¸Šä½1%è¶…å³é¸ ===
    print("\nğŸ›¡ï¸ æˆ¦ç•¥3: ä¸Šä½1%è¶…å³é¸")
    
    all_preds_3 = []
    all_actuals_3 = []
    
    for test_date in test_dates[-5:]:
        train = df_sorted[df_sorted['Date'] < test_date]
        test = df_sorted[df_sorted['Date'] == test_date]
        
        train_clean = train.dropna(subset=['Target'] + feature_cols)
        test_clean = test.dropna(subset=['Target'] + feature_cols)
        
        if len(train_clean) < 2000 or len(test_clean) < 10:
            continue
        
        X_train = train_clean[feature_cols]
        y_train = train_clean['Target']
        X_test = test_clean[feature_cols]
        y_test = test_clean['Target']
        
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        model = lgb.LGBMClassifier(n_estimators=150, max_depth=4, random_state=42, verbose=-1)
        model.fit(X_train_scaled, y_train)
        probs = model.predict_proba(X_test_scaled)[:, 1]
        
        # ä¸Šä½1%ã®ã¿é¸æŠ
        n_select = max(1, int(len(probs) * 0.01))
        top_indices = np.argsort(probs)[-n_select:]
        
        selected = y_test.iloc[top_indices].values
        all_preds_3.extend(np.ones(len(selected)))
        all_actuals_3.extend(selected)
    
    if len(all_preds_3) > 0:
        precision_3 = sum(all_actuals_3) / len(all_actuals_3)
        strategies.append(('ä¸Šä½1%è¶…å³é¸', precision_3, len(all_preds_3)))
        print(f"  çµæœ: ç²¾åº¦{precision_3:.1%}, é¸æŠæ•°{len(all_preds_3)}")
    
    # æœ€çµ‚çµæœ
    print("\n" + "="*70)
    print("ğŸ¯ è¶…å³é¸60%ç²¾åº¦ãƒãƒ£ãƒ¬ãƒ³ã‚¸çµæœ")
    print("="*70)
    
    print(f"\n{'æˆ¦ç•¥å':<20} {'ç²¾åº¦':<10} {'é¸æŠæ•°':<6} {'60%é”æˆ'}")
    print("-"*50)
    
    best_precision = 0
    best_strategy = None
    
    for name, precision, count in strategies:
        status = "âœ… YES" if precision >= 0.60 else "âŒ NO"
        print(f"{name:<20} {precision:<10.1%} {count:<6d} {status}")
        
        if precision > best_precision:
            best_precision = precision
            best_strategy = (name, precision, count)
    
    if best_precision >= 0.60:
        print(f"\nğŸ‰ ã€60%ç²¾åº¦é”æˆæˆåŠŸï¼ã€‘")
        print(f"âœ… é”æˆç²¾åº¦: {best_precision:.1%}")
        print(f"âœ… æˆ¦ç•¥: {best_strategy[0]}")
        print(f"âœ… é¸æŠæ•°: {best_strategy[2]}")
        
        # æˆåŠŸè¨˜éŒ²
        with open('ultra_selective_60_success.txt', 'w') as f:
            f.write(f"60%ç²¾åº¦é”æˆæˆåŠŸï¼\n")
            f.write(f"é”æˆç²¾åº¦: {best_precision:.2%}\n")
            f.write(f"æˆ¦ç•¥: {best_strategy[0]}\n")
            f.write(f"é¸æŠæ•°: {best_strategy[2]}\n")
            f.write(f"é”æˆæ™‚åˆ»: {datetime.now()}\n")
        
        print("ğŸ’¾ æˆåŠŸè¨˜éŒ²ä¿å­˜å®Œäº†")
        return True
    else:
        print(f"\nâš ï¸ ã€60%æœªé”æˆã€‘")
        if best_strategy:
            print(f"æœ€é«˜ç²¾åº¦: {best_precision:.1%}")
            print(f"ç›®æ¨™ã¾ã§: +{0.60 - best_precision:.1%}")
            print(f"æœ€è‰¯æˆ¦ç•¥: {best_strategy[0]}")
        return False

if __name__ == "__main__":
    success = ultra_selective_60()
    if success:
        print("\nğŸ‰ 60%ç²¾åº¦é”æˆæˆåŠŸï¼")
    else:
        print("\nâš ï¸ ã•ã‚‰ãªã‚‹æ”¹å–„ãŒå¿…è¦")