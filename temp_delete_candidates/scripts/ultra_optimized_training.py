#!/usr/bin/env python3
"""
è¶…æœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«è¨“ç·´ - 70%å°ã®ç²¾åº¦ã‚’ç›®æŒ‡ã™
XGBoostã€LightGBMã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’ä½¿ç”¨
"""

import pandas as pd
import numpy as np
from pathlib import Path
import joblib
import argparse
from datetime import datetime
from loguru import logger

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.feature_selection import SelectKBest, f_classif, RFE
import lightgbm as lgb
import warnings
warnings.filterwarnings('ignore')

class UltraOptimizedTrainer:
    """è¶…é«˜ç²¾åº¦ã‚’ç›®æŒ‡ã™ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
    
    def __init__(self, data_dir: Path = None):
        self.data_dir = data_dir or Path("data")
        self.processed_dir = self.data_dir / "processed"
        self.models_dir = self.data_dir / "models"
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        self.scaler = StandardScaler()
        
    def load_features(self, filename: str) -> pd.DataFrame:
        """ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
        file_path = self.processed_dir / filename
        
        if not file_path.exists():
            raise FileNotFoundError(f"Features file not found: {file_path}")
        
        df = pd.read_parquet(file_path)
        logger.info(f"Loaded features: {df.shape}")
        return df
    
    def prepare_data(self, df: pd.DataFrame, target_column: str, test_size: float = 0.2):
        """ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆè¶…æœ€é©åŒ–ç‰ˆï¼‰"""
        
        # ç‰¹å¾´é‡é¸æŠ
        exclude_cols = {
            'Date', 'Code', 'Open', 'High', 'Low', 'Close', 'Volume',
            'date', 'code', 'open', 'high', 'low', 'close', 'volume',
            'UpperLimit', 'LowerLimit', 'turnover_value', 'adjustment_factor',
            'adj_open', 'adj_high', 'adj_low', 'adj_close', 'adj_volume',
            target_column, 'Next_Day_Return', 'Return_Direction', 'Binary_Direction'
        }
        
        feature_cols = [col for col in df.columns if col not in exclude_cols]
        
        # æ¬ æå€¤å‡¦ç†
        clean_df = df[df[target_column].notna()].copy()
        
        # ç‰¹å¾´é‡å‰å‡¦ç†
        X = clean_df[feature_cols].copy()
        
        # é«˜åº¦ãªå‰å‡¦ç†
        # 1. å‰æ–¹è£œå®Œ + å¾Œæ–¹è£œå®Œ
        X = X.groupby(clean_df['Code']).fillna(method='ffill').fillna(method='bfill')
        X = X.fillna(0)
        
        # 2. å¤–ã‚Œå€¤å‡¦ç†ï¼ˆ5-95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã§ã‚¯ãƒªãƒƒãƒ—ï¼‰
        for col in X.columns:
            if X[col].dtype in ['float64', 'int64']:
                lower = X[col].quantile(0.05)
                upper = X[col].quantile(0.95)
                X[col] = X[col].clip(lower, upper)
        
        y = clean_df[target_column]
        
        logger.info(f"Features: {len(feature_cols)}, Samples: {len(X)}")
        logger.info(f"Target distribution: {y.value_counts().to_dict()}")
        
        # æ™‚ç³»åˆ—åˆ†å‰²ï¼ˆæœ€æ–°80%ã‚’è¨“ç·´ã€æœ€å¾Œ20%ã‚’ãƒ†ã‚¹ãƒˆï¼‰
        split_point = int(len(X) * (1 - test_size))
        X_train, X_test = X.iloc[:split_point], X.iloc[split_point:]
        y_train, y_test = y.iloc[:split_point], y.iloc[split_point:]
        
        return X_train, X_test, y_train, y_test, feature_cols
    
    def create_ultra_models(self):
        """è¶…æœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆ"""
        models = {
            'random_forest_ultra': RandomForestClassifier(
                n_estimators=1000,         # å¤§å¹…å¢—åŠ 
                max_depth=30,              # ã‚ˆã‚Šæ·±ã
                min_samples_split=2,
                min_samples_leaf=1,
                max_features=0.8,          # ã‚ˆã‚Šå¤šãã®ç‰¹å¾´é‡ã‚’ä½¿ç”¨
                bootstrap=True,
                oob_score=True,
                n_jobs=-1,
                random_state=42,
                class_weight='balanced',
                criterion='gini'           # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚‚è©¦ã™
            ),
            
            'extra_trees_ultra': ExtraTreesClassifier(
                n_estimators=800,
                max_depth=35,
                min_samples_split=2,
                min_samples_leaf=1,
                max_features=0.9,
                bootstrap=True,
                oob_score=True,
                n_jobs=-1,
                random_state=42,
                class_weight='balanced'
            ),
            
            'lightgbm': lgb.LGBMClassifier(
                n_estimators=500,
                learning_rate=0.05,
                max_depth=15,
                num_leaves=31,
                feature_fraction=0.8,
                bagging_fraction=0.8,
                bagging_freq=5,
                min_child_samples=20,
                random_state=42,
                class_weight='balanced',
                n_jobs=-1,
                verbosity=-1
            ),
            
            'logistic_ultra': LogisticRegression(
                C=0.1,                     # ã‚ˆã‚Šå¼·ã„æ­£å‰‡åŒ–
                solver='liblinear',
                max_iter=2000,
                random_state=42,
                class_weight='balanced',
                penalty='l1'               # L1æ­£å‰‡åŒ–
            )
        }
        
        return models
    
    def train_ultra_models(self, X_train, X_test, y_train, y_test):
        """è¶…æœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        models = self.create_ultra_models()
        results = {}
        
        # ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # ç‰¹å¾´é‡é¸æŠï¼ˆã‚ˆã‚Šå³æ ¼ï¼‰
        selector = SelectKBest(score_func=f_classif, k=min(15, X_train.shape[1]))
        X_train_selected = selector.fit_transform(X_train_scaled, y_train)
        X_test_selected = selector.transform(X_test_scaled)
        
        logger.info(f"Selected {X_train_selected.shape[1]} features from {X_train.shape[1]}")
        
        trained_models = {}
        
        for name, model in models.items():
            logger.info(f"Training {name}...")
            
            try:
                # ãƒ¢ãƒ‡ãƒ«åˆ¥ã®ç‰¹å¾´é‡é¸æŠ
                if name in ['logistic_ultra']:
                    # ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã¯ã‚¹ã‚±ãƒ¼ãƒ«æ¸ˆã¿+é¸æŠæ¸ˆã¿ç‰¹å¾´é‡
                    model.fit(X_train_selected, y_train)
                    y_pred = model.predict(X_test_selected)
                    y_pred_proba = model.predict_proba(X_test_selected)
                elif name == 'lightgbm':
                    # LightGBMã¯å…ƒã®ç‰¹å¾´é‡
                    model.fit(X_train, y_train, eval_set=(X_test, y_test), callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)])
                    y_pred = model.predict(X_test)
                    y_pred_proba = model.predict_proba(X_test)
                else:
                    # æœ¨ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    y_pred_proba = model.predict_proba(X_test)
                
                # è©•ä¾¡
                accuracy = accuracy_score(y_test, y_pred)
                
                results[name] = {
                    'model': model,
                    'accuracy': accuracy,
                    'predictions': y_pred,
                    'probabilities': y_pred_proba
                }
                
                trained_models[name] = model
                
                logger.info(f"{name} - Accuracy: {accuracy:.3f}")
                
                # ç‰¹å¾´é‡é‡è¦åº¦
                if hasattr(model, 'feature_importances_'):
                    importances = model.feature_importances_
                    if len(importances) == len(X_train.columns):
                        feature_importance = pd.DataFrame({
                            'feature': X_train.columns,
                            'importance': importances
                        }).sort_values('importance', ascending=False)
                        
                        logger.info(f"Top 3 features for {name}:")
                        for idx, row in feature_importance.head(3).iterrows():
                            logger.info(f"  {row['feature']}: {row['importance']:.4f}")
                
                # OOB Score
                if hasattr(model, 'oob_score_'):
                    logger.info(f"{name} - OOB Score: {model.oob_score_:.3f}")
                    
                # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæ™‚é–“ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
                if len(X_train) < 50000:  # ãƒ‡ãƒ¼ã‚¿ãŒå°ã•ã„å ´åˆã®ã¿
                    cv_scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy')
                    logger.info(f"{name} - CV Score: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
                    
            except Exception as e:
                logger.error(f"Error training {name}: {e}")
                continue
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«
        if len(trained_models) >= 2:
            logger.info("Creating ensemble model...")
            
            # ä¸Šä½3ãƒ¢ãƒ‡ãƒ«ã§ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
            sorted_models = sorted(results.items(), key=lambda x: x[1]['accuracy'], reverse=True)
            top_models = [(name, data['model']) for name, data in sorted_models[:3]]
            
            ensemble = VotingClassifier(
                estimators=top_models,
                voting='soft'  # ç¢ºç‡ãƒ™ãƒ¼ã‚¹ã®æŠ•ç¥¨
            )
            
            try:
                # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç”¨ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆæœ€ã‚‚è‰¯ã„ãƒ¢ãƒ‡ãƒ«ã®å‰å‡¦ç†ã«åˆã‚ã›ã‚‹ï¼‰
                best_model_name = sorted_models[0][0]
                if best_model_name in ['logistic_ultra']:
                    ensemble_X_train = X_train_selected
                    ensemble_X_test = X_test_selected
                else:
                    ensemble_X_train = X_train
                    ensemble_X_test = X_test
                
                ensemble.fit(ensemble_X_train, y_train)
                ensemble_pred = ensemble.predict(ensemble_X_test)
                ensemble_proba = ensemble.predict_proba(ensemble_X_test)
                ensemble_accuracy = accuracy_score(y_test, ensemble_pred)
                
                results['ensemble'] = {
                    'model': ensemble,
                    'accuracy': ensemble_accuracy,
                    'predictions': ensemble_pred,
                    'probabilities': ensemble_proba
                }
                
                logger.info(f"ensemble - Accuracy: {ensemble_accuracy:.3f}")
                
            except Exception as e:
                logger.error(f"Error creating ensemble: {e}")
        
        return results, selector
    
    def create_ultra_report(self, results: dict, y_test):
        """è¶…è©³ç´°æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆ"""
        
        print("\n" + "="*80)
        print("ğŸš€ ULTRA-OPTIMIZED MODEL PERFORMANCE REPORT")
        print("="*80)
        
        # ç²¾åº¦é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_results = sorted(results.items(), key=lambda x: x[1]['accuracy'], reverse=True)
        
        for i, (model_name, data) in enumerate(sorted_results):
            rank_emoji = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i] if i < 3 else f"{i+1:2d}."
            
            print(f"\n{rank_emoji} {model_name.upper().replace('_', ' ')}:")
            print(f"   ğŸ¯ Accuracy: {data['accuracy']:.1%}")
            
            # åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆã®è¦ç´„
            y_pred = data['predictions']
            report = classification_report(y_test, y_pred, output_dict=True)
            
            print(f"   ğŸ“Š Precision: {report['weighted avg']['precision']:.3f}")
            print(f"   ğŸ“Š Recall: {report['weighted avg']['recall']:.3f}")
            print(f"   ğŸ“Š F1-Score: {report['weighted avg']['f1-score']:.3f}")
            
            # ä¸Šæ˜‡äºˆæ¸¬ã®ç²¾åº¦
            if '1' in report:
                print(f"   ğŸ“ˆ Up Prediction Precision: {report['1']['precision']:.3f}")
                print(f"   ğŸ“ˆ Up Prediction Recall: {report['1']['recall']:.3f}")
        
        # æœ€é«˜æˆç¸¾
        best_model_name = sorted_results[0][0]
        best_accuracy = sorted_results[0][1]['accuracy']
        print(f"\nğŸ† BEST MODEL: {best_model_name.upper()} with {best_accuracy:.1%} accuracy")
        
        if best_accuracy > 0.7:
            print("ğŸ‰ TARGET ACHIEVED: 70%+ accuracy!")
        elif best_accuracy > 0.6:
            print("ğŸ‘ GOOD PERFORMANCE: 60%+ accuracy")
        else:
            print("ğŸ“ˆ ROOM FOR IMPROVEMENT")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    parser = argparse.ArgumentParser(description="Ultra-optimized training for maximum accuracy")
    parser.add_argument("--features-file", required=True, help="Features file name")
    parser.add_argument("--target", default="Binary_Direction", help="Target column")
    parser.add_argument("--test-size", type=float, default=0.2, help="Test data proportion")
    parser.add_argument("--save-models", action="store_true", help="Save trained models")
    
    args = parser.parse_args()
    
    try:
        trainer = UltraOptimizedTrainer()
        
        print("ğŸ“Š Loading features...")
        df = trainer.load_features(args.features_file)
        
        print("ğŸ”§ Preparing training data...")
        X_train, X_test, y_train, y_test, feature_cols = trainer.prepare_data(
            df, args.target, args.test_size
        )
        print(f"   Training samples: {len(X_train):,}")
        print(f"   Test samples: {len(X_test):,}")
        print(f"   Features: {len(feature_cols)}")
        
        print("\nğŸš€ Training ultra-optimized models...")
        results, selector = trainer.train_ultra_models(X_train, X_test, y_train, y_test)
        
        trainer.create_ultra_report(results, y_test)
        
        if args.save_models:
            print(f"\nğŸ’¾ Saving high-performance models...")
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            for model_name, model_data in results.items():
                if model_data['accuracy'] > 0.55:  # 55%ä»¥ä¸Šã®ã¿ä¿å­˜
                    filename = f"ultra_{model_name}_{args.target}_{timestamp}.joblib"
                    file_path = trainer.models_dir / filename
                    
                    model_package = {
                        'model': model_data['model'],
                        'scaler': trainer.scaler,
                        'selector': selector,
                        'target_column': args.target,
                        'timestamp': timestamp,
                        'accuracy': model_data['accuracy']
                    }
                    
                    joblib.dump(model_package, file_path)
                    logger.info(f"Saved {model_name} ({model_data['accuracy']:.1%}) to {file_path}")
        
        print("\nâœ… Ultra-optimized training completed!")
        
    except Exception as e:
        logger.error(f"Training failed: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())