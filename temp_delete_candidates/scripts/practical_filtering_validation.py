#!/usr/bin/env python3
"""
å®Ÿç”¨çš„ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•æ¤œè¨¼
é€£ç¶šçš„ãªã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰æ¤œè¨¼ã§å®Ÿè·µå€¤ã‚’æ¸¬å®š
"""

import pandas as pd
import numpy as np
from pathlib import Path
from loguru import logger
import sys
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# ãƒ­ã‚°è¨­å®š
logger.remove()
logger.add(sys.stderr, format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>", level="INFO")

class PracticalFilteringValidation:
    """å®Ÿç”¨çš„ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•æ¤œè¨¼"""
    
    def __init__(self):
        self.data_dir = Path("data")
        self.processed_dir = self.data_dir / "processed"
        
        # æœ€é©ç‰¹å¾´é‡
        self.optimal_features = [
            'Market_Breadth', 'Market_Return', 'Volatility_20', 'Price_vs_MA20',
            'sp500_change', 'vix_change', 'nikkei_change', 'us_10y_change', 'usd_jpy_change'
        ]
        
        # æ¤œè¨¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.confidence_threshold = 0.55
        self.target_candidates = 5
        self.min_training_days = 252  # 1å¹´åˆ†ã®æœ€å°å­¦ç¿’æœŸé–“
        
    def load_and_prepare_data(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨æº–å‚™"""
        logger.info("ğŸ“Š å®Ÿç”¨æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™...")
        
        integrated_file = self.processed_dir / "integrated_with_external.parquet"
        df = pd.read_parquet(integrated_file)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        clean_df = df[df['Binary_Direction'].notna()].copy()
        
        # é‡è¤‡é™¤å»
        clean_df = clean_df.groupby(['Date', 'Code']).last().reset_index()
        clean_df = clean_df.sort_values(['Date', 'Code']).reset_index(drop=True)
        
        # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæº–å‚™
        X = clean_df[self.optimal_features].fillna(0)
        y = clean_df['Binary_Direction'].astype(int)
        
        logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: {len(clean_df):,}ä»¶, {len(self.optimal_features)}ç‰¹å¾´é‡")
        
        return clean_df, X, y
    
    def walk_forward_validation(self, df, X, y):
        """ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰æ¤œè¨¼ï¼ˆé€£ç¶šçš„ãƒ»å®Ÿç”¨çš„ï¼‰"""
        logger.info("ğŸš€ ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰æ¤œè¨¼é–‹å§‹...")
        
        dates = sorted(df['Date'].unique())
        logger.info(f"å…¨æœŸé–“: {dates[0]} - {dates[-1]} ({len(dates)}æ—¥)")
        
        # å­¦ç¿’é–‹å§‹ç‚¹ã¨ãƒ†ã‚¹ãƒˆæœŸé–“ã‚’è¨­å®š
        start_train_idx = 0
        start_test_idx = self.min_training_days  # 1å¹´å¾Œã‹ã‚‰æ¤œè¨¼é–‹å§‹
        
        # æ¤œè¨¼çµæœæ ¼ç´
        results = {
            'Simple_Confidence': [],
            'Sector_Diversity': [],
            'Volatility_Adjusted': []
        }
        
        validation_dates = []
        
        # 3ãƒ¶æœˆã”ã¨ã«ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’ã—ã¦ãƒ†ã‚¹ãƒˆ
        step_size = 63  # ç´„3ãƒ¶æœˆï¼ˆå–¶æ¥­æ—¥ï¼‰
        
        for test_start in range(start_test_idx, len(dates) - 21, step_size):  # æœ€å¾Œ21æ—¥ã¯é™¤å¤–
            # å­¦ç¿’æœŸé–“ï¼šéå»1.5å¹´åˆ†
            train_start = max(0, test_start - 378)  # 1.5å¹´å‰ã‹ã‚‰
            train_end = test_start
            
            # ãƒ†ã‚¹ãƒˆæœŸé–“ï¼šæ¬¡ã®21å–¶æ¥­æ—¥ï¼ˆ1ãƒ¶æœˆï¼‰
            test_end = min(test_start + 21, len(dates))
            
            train_dates = dates[train_start:train_end]
            test_dates = dates[test_start:test_end]
            
            if len(train_dates) < self.min_training_days:
                continue
                
            logger.info(f"æ¤œè¨¼æœŸé–“: {test_dates[0]} - {test_dates[-1]} (å­¦ç¿’{len(train_dates)}æ—¥)")
            
            # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
            train_mask = df['Date'].isin(train_dates)
            X_train = X[train_mask]
            y_train = y[train_mask]
            
            scaler = StandardScaler()
            model = LogisticRegression(C=0.001, class_weight='balanced', random_state=42, max_iter=1000)
            
            X_train_scaled = scaler.fit_transform(X_train)
            model.fit(X_train_scaled, y_train)
            
            # å„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•ã§ãƒ†ã‚¹ãƒˆ
            period_results = self.evaluate_methods_for_period(
                df, X, model, scaler, test_dates
            )
            
            # çµæœè¨˜éŒ²
            for method, result in period_results.items():
                if result['total_predictions'] > 0:
                    results[method].append({
                        'period': f"{test_dates[0]}-{test_dates[-1]}",
                        'accuracy': result['accuracy'],
                        'predictions': result['total_predictions'],
                        'daily_avg': result['total_predictions'] / len(test_dates)
                    })
            
            validation_dates.extend(test_dates)
        
        return results, validation_dates
    
    def evaluate_methods_for_period(self, df, X, model, scaler, test_dates):
        """æœŸé–“å†…ã§ã®å„æ‰‹æ³•è©•ä¾¡"""
        methods = {
            'Simple_Confidence': self.method_simple_confidence,
            'Sector_Diversity': self.method_sector_diversity,
            'Volatility_Adjusted': self.method_volatility_adjusted
        }
        
        period_results = {}
        
        for method_name, method_func in methods.items():
            total_predictions = 0
            correct_predictions = 0
            
            for date in test_dates:
                day_data = df[df['Date'] == date].copy()
                if len(day_data) == 0:
                    continue
                
                # äºˆæ¸¬å®Ÿè¡Œ
                X_day = day_data[self.optimal_features].fillna(0)
                X_day_scaled = scaler.transform(X_day)
                pred_proba = model.predict_proba(X_day_scaled)[:, 1]
                day_data['pred_proba'] = pred_proba
                
                # çµã‚Šè¾¼ã¿å®Ÿè¡Œ
                selected = method_func(day_data)
                
                if len(selected) > 0:
                    total_predictions += len(selected)
                    correct_predictions += selected['Binary_Direction'].sum()
            
            accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0
            
            period_results[method_name] = {
                'accuracy': accuracy,
                'total_predictions': total_predictions,
                'correct_predictions': correct_predictions
            }
        
        return period_results
    
    def method_simple_confidence(self, day_data):
        """ã‚·ãƒ³ãƒ—ãƒ«ç¢ºä¿¡åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        high_conf = day_data[
            (day_data['pred_proba'] >= self.confidence_threshold) |
            (day_data['pred_proba'] <= (1 - self.confidence_threshold))
        ].copy()
        
        if len(high_conf) == 0:
            return pd.DataFrame()
        
        # ç¢ºä¿¡åº¦é †ã«ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½ã‚’é¸æŠ
        high_conf['confidence_score'] = np.maximum(
            high_conf['pred_proba'], 
            1 - high_conf['pred_proba']
        )
        
        return high_conf.nlargest(self.target_candidates, 'confidence_score')
    
    def method_sector_diversity(self, day_data):
        """ã‚»ã‚¯ã‚¿ãƒ¼å¤šæ§˜æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        high_conf = day_data[
            (day_data['pred_proba'] >= self.confidence_threshold) |
            (day_data['pred_proba'] <= (1 - self.confidence_threshold))
        ].copy()
        
        if len(high_conf) == 0:
            return pd.DataFrame()
        
        high_conf['confidence_score'] = np.maximum(
            high_conf['pred_proba'], 
            1 - high_conf['pred_proba']
        )
        
        # ã‚»ã‚¯ã‚¿ãƒ¼æƒ…å ±ãŒãªã„å ´åˆã¯ã‚·ãƒ³ãƒ—ãƒ«ç¢ºä¿¡åº¦ã¨åŒã˜
        return high_conf.nlargest(self.target_candidates, 'confidence_score')
    
    def method_volatility_adjusted(self, day_data):
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        high_conf = day_data[
            (day_data['pred_proba'] >= self.confidence_threshold) |
            (day_data['pred_proba'] <= (1 - self.confidence_threshold))
        ].copy()
        
        if len(high_conf) == 0:
            return pd.DataFrame()
        
        high_conf['confidence_score'] = np.maximum(
            high_conf['pred_proba'], 
            1 - high_conf['pred_proba']
        )
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã§èª¿æ•´
        if 'Volatility_20' in high_conf.columns:
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒä½ã„ã»ã©å®‰å®šæ€§ãŒé«˜ã„
            vol_factor = 1 / (1 + high_conf['Volatility_20'].fillna(0))
            high_conf['adjusted_score'] = high_conf['confidence_score'] * vol_factor
            return high_conf.nlargest(self.target_candidates, 'adjusted_score')
        else:
            return high_conf.nlargest(self.target_candidates, 'confidence_score')
    
    def display_practical_results(self, results):
        """å®Ÿç”¨çš„æ¤œè¨¼çµæœã®è¡¨ç¤º"""
        logger.info("\n" + "="*100)
        logger.info("ğŸ“Š å®Ÿç”¨çš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•æ¤œè¨¼çµæœ")
        logger.info("="*100)
        
        overall_stats = {}
        
        for method, method_results in results.items():
            if not method_results:
                continue
                
            accuracies = [r['accuracy'] for r in method_results]
            predictions = [r['predictions'] for r in method_results]
            daily_avgs = [r['daily_avg'] for r in method_results]
            
            overall_stats[method] = {
                'periods': len(method_results),
                'avg_accuracy': np.mean(accuracies),
                'std_accuracy': np.std(accuracies),
                'min_accuracy': np.min(accuracies),
                'max_accuracy': np.max(accuracies),
                'total_predictions': sum(predictions),
                'avg_daily_candidates': np.mean(daily_avgs)
            }
        
        # çµæœè¡¨ç¤º
        logger.info(f"\nğŸ“ˆ å„æ‰‹æ³•ã®å®Ÿç”¨æ€§èƒ½:")
        
        sorted_methods = sorted(overall_stats.items(), 
                              key=lambda x: x[1]['avg_accuracy'], reverse=True)
        
        for i, (method, stats) in enumerate(sorted_methods, 1):
            logger.info(f"\n{i}. {method}:")
            logger.info(f"   å¹³å‡ç²¾åº¦: {stats['avg_accuracy']:.1%} Â± {stats['std_accuracy']:.1%}")
            logger.info(f"   ç²¾åº¦ç¯„å›²: {stats['min_accuracy']:.1%} - {stats['max_accuracy']:.1%}")
            logger.info(f"   æ¤œè¨¼æœŸé–“: {stats['periods']}æœŸé–“")
            logger.info(f"   ç·äºˆæ¸¬æ•°: {stats['total_predictions']}ä»¶")
            logger.info(f"   æ—¥å¹³å‡å€™è£œ: {stats['avg_daily_candidates']:.1f}éŠ˜æŸ„")
        
        # æœ€å„ªç§€æ‰‹æ³•ã®æ¨å¥¨
        if overall_stats:
            best_method = sorted_methods[0][0]
            best_stats = sorted_methods[0][1]
            
            logger.info(f"\nğŸ† æ¨å¥¨æ‰‹æ³•: {best_method}")
            logger.info(f"   æœŸå¾…ç²¾åº¦: {best_stats['avg_accuracy']:.1%}")
            logger.info(f"   å®‰å®šæ€§: Â±{best_stats['std_accuracy']:.1%}")
            logger.info(f"   å®Ÿç”¨æ€§è©•ä¾¡: {'é«˜' if best_stats['avg_accuracy'] > 0.60 else 'ä¸­' if best_stats['avg_accuracy'] > 0.55 else 'ä½'}")
        
        logger.info("="*100)
        
        return overall_stats

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    logger.info("ğŸ”¬ å®Ÿç”¨çš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ")
    
    validator = PracticalFilteringValidation()
    
    try:
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        df, X, y = validator.load_and_prepare_data()
        
        # ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰æ¤œè¨¼
        results, validation_dates = validator.walk_forward_validation(df, X, y)
        
        # çµæœè¡¨ç¤º
        overall_stats = validator.display_practical_results(results)
        
        logger.info(f"\nâœ… å®Ÿç”¨æ¤œè¨¼å®Œäº† - {len(set(validation_dates))}æ—¥é–“ã§æ¤œè¨¼")
        
    except Exception as e:
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()