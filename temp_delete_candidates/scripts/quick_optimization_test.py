#!/usr/bin/env python3
"""
ã‚¯ã‚¤ãƒƒã‚¯æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ - æ‰‹å‹•ã§ãƒ‡ãƒ¼ã‚¿è¿½åŠ ä»¥å¤–ã®æ”¹å–„ä½™åœ°ã‚’æ¤œè¨¼
"""

import pandas as pd
import numpy as np
from pathlib import Path
from loguru import logger
import sys
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer
import warnings
warnings.filterwarnings('ignore')

# ãƒ­ã‚°è¨­å®š
logger.remove()
logger.add(sys.stderr, format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>", level="INFO")

class QuickOptimizer:
    """ã‚¯ã‚¤ãƒƒã‚¯æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.data_dir = Path("data")
        self.processed_dir = self.data_dir / "processed"
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç‰¹å¾´é‡
        self.baseline_features = [
            'Market_Breadth', 'Market_Return', 'Volatility_20', 'RSI', 'Price_vs_MA20'
        ]
        
    def load_and_prepare_data(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨æº–å‚™"""
        logger.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆ394,102ä»¶ï¼‰")
        
        processed_files = list(self.processed_dir.glob("*.parquet"))
        df = pd.read_parquet(processed_files[0])
        
        clean_df = df[df['Binary_Direction'].notna()].copy()
        clean_df = clean_df.sort_values(['Date', 'Code']).reset_index(drop=True)
        
        X = clean_df[self.baseline_features].fillna(0)
        y = clean_df['Binary_Direction'].astype(int)
        
        logger.info(f"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(clean_df):,}ä»¶")
        return X, y
    
    def test_baseline(self, X, y):
        """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š"""
        logger.info("ğŸ“Š ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š...")
        
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        model = LogisticRegression(C=0.01, class_weight='balanced', max_iter=1000, random_state=42)
        
        tscv = TimeSeriesSplit(n_splits=5)
        scores = []
        
        for train_idx, test_idx in tscv.split(X_scaled):
            X_train = X_scaled[train_idx]
            X_test = X_scaled[test_idx]
            y_train = y.iloc[train_idx]
            y_test = y.iloc[test_idx]
            
            model.fit(X_train, y_train)
            pred = model.predict(X_test)
            scores.append(accuracy_score(y_test, pred))
        
        baseline = np.mean(scores)
        logger.info(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç²¾åº¦: {baseline:.1%}")
        return baseline
    
    def test_preprocessing_variants(self, X, y):
        """å‰å‡¦ç†ãƒãƒªã‚¢ãƒ³ãƒˆæ¤œè¨¼"""
        logger.info("ğŸ”§ å‰å‡¦ç†ãƒãƒªã‚¢ãƒ³ãƒˆæ¤œè¨¼...")
        
        variants = {
            'Standard': StandardScaler(),
            'MinMax': MinMaxScaler(),
            'Quantile': QuantileTransformer(n_quantiles=1000, random_state=42),
            'RobustClip': 'custom'
        }
        
        results = {}
        
        for name, scaler in variants.items():
            logger.info(f"  {name}...")
            
            if name == 'RobustClip':
                # ã‚«ã‚¹ã‚¿ãƒ å‰å‡¦ç†ï¼šãƒ­ãƒã‚¹ãƒˆã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
                X_processed = X.clip(lower=X.quantile(0.05), upper=X.quantile(0.95), axis=0)
                X_scaled = StandardScaler().fit_transform(X_processed)
            else:
                X_scaled = scaler.fit_transform(X)
            
            model = LogisticRegression(C=0.01, class_weight='balanced', max_iter=1000, random_state=42)
            
            tscv = TimeSeriesSplit(n_splits=3)
            scores = []
            
            for train_idx, test_idx in tscv.split(X_scaled):
                X_train = X_scaled[train_idx]
                X_test = X_scaled[test_idx]
                y_train = y.iloc[train_idx]
                y_test = y.iloc[test_idx]
                
                model.fit(X_train, y_train)
                pred = model.predict(X_test)
                scores.append(accuracy_score(y_test, pred))
            
            avg_score = np.mean(scores)
            results[name] = avg_score
            logger.info(f"    {name}: {avg_score:.1%}")
        
        return results
    
    def test_hyperparameters(self, X, y):
        """ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ"""
        logger.info("âš™ï¸ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ...")
        
        X_scaled = StandardScaler().fit_transform(X)
        
        # LogisticRegression ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        lr_configs = [
            {'C': 0.001, 'class_weight': 'balanced'},
            {'C': 0.01, 'class_weight': 'balanced'},
            {'C': 0.1, 'class_weight': 'balanced'},
            {'C': 0.01, 'class_weight': {0: 1, 1: 1.2}},
            {'C': 0.01, 'class_weight': {0: 1, 1: 1.5}},
        ]
        
        lr_results = {}
        
        for i, config in enumerate(lr_configs):
            model = LogisticRegression(**config, max_iter=1000, random_state=42)
            
            tscv = TimeSeriesSplit(n_splits=3)
            scores = []
            
            for train_idx, test_idx in tscv.split(X_scaled):
                X_train = X_scaled[train_idx]
                X_test = X_scaled[test_idx]
                y_train = y.iloc[train_idx]
                y_test = y.iloc[test_idx]
                
                model.fit(X_train, y_train)
                pred = model.predict(X_test)
                scores.append(accuracy_score(y_test, pred))
            
            avg_score = np.mean(scores)
            config_str = f"LR_Config_{i+1}"
            lr_results[config_str] = avg_score
            logger.info(f"  {config_str}: {avg_score:.1%} {config}")
        
        # RandomForest ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        rf_configs = [
            {'n_estimators': 50, 'max_depth': 8, 'class_weight': 'balanced'},
            {'n_estimators': 100, 'max_depth': 10, 'class_weight': 'balanced'},
            {'n_estimators': 150, 'max_depth': 12, 'class_weight': 'balanced'},
            {'n_estimators': 100, 'max_depth': 8, 'min_samples_split': 10},
        ]
        
        rf_results = {}
        
        for i, config in enumerate(rf_configs):
            model = RandomForestClassifier(**config, random_state=42, n_jobs=-1)
            
            tscv = TimeSeriesSplit(n_splits=3)
            scores = []
            
            for train_idx, test_idx in tscv.split(X_scaled):
                X_train = X_scaled[train_idx]
                X_test = X_scaled[test_idx]
                y_train = y.iloc[train_idx]
                y_test = y.iloc[test_idx]
                
                model.fit(X_train, y_train)
                pred = model.predict(X_test)
                scores.append(accuracy_score(y_test, pred))
            
            avg_score = np.mean(scores)
            config_str = f"RF_Config_{i+1}"
            rf_results[config_str] = avg_score
            logger.info(f"  {config_str}: {avg_score:.1%}")
        
        return lr_results, rf_results
    
    def test_ensemble_methods(self, X, y):
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ§  ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ãƒ†ã‚¹ãƒˆ...")
        
        X_scaled = StandardScaler().fit_transform(X)
        
        # å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«
        lr = LogisticRegression(C=0.01, class_weight='balanced', max_iter=1000, random_state=42)
        rf = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=42, n_jobs=-1)
        gb = GradientBoostingClassifier(n_estimators=100, max_depth=6, random_state=42)
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
        voting_hard = VotingClassifier([('lr', lr), ('rf', rf), ('gb', gb)], voting='hard')
        voting_soft = VotingClassifier([('lr', lr), ('rf', rf), ('gb', gb)], voting='soft')
        
        models = {
            'VotingHard': voting_hard,
            'VotingSoft': voting_soft
        }
        
        results = {}
        
        for name, model in models.items():
            logger.info(f"  {name}...")
            
            tscv = TimeSeriesSplit(n_splits=3)
            scores = []
            
            for train_idx, test_idx in tscv.split(X_scaled):
                X_train = X_scaled[train_idx]
                X_test = X_scaled[test_idx]
                y_train = y.iloc[train_idx]
                y_test = y.iloc[test_idx]
                
                model.fit(X_train, y_train)
                pred = model.predict(X_test)
                scores.append(accuracy_score(y_test, pred))
            
            avg_score = np.mean(scores)
            results[name] = avg_score
            logger.info(f"    {name}: {avg_score:.1%}")
        
        return results
    
    def test_feature_engineering_variants(self, X, y):
        """ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒãƒªã‚¢ãƒ³ãƒˆ"""
        logger.info("âš—ï¸ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒãƒªã‚¢ãƒ³ãƒˆ...")
        
        # å…ƒã®ç‰¹å¾´é‡
        X_base = X.copy()
        
        # å„ç¨®å¤‰æ›
        variants = {}
        
        # 1. å¯¾æ•°å¤‰æ›
        X_log = X_base.copy()
        for col in X_log.columns:
            if (X_log[col] > 0).all():
                X_log[col] = np.log1p(X_log[col])
        variants['Log_Transform'] = X_log
        
        # 2. å¹³æ–¹æ ¹å¤‰æ›
        X_sqrt = X_base.copy()
        for col in X_sqrt.columns:
            if (X_sqrt[col] >= 0).all():
                X_sqrt[col] = np.sqrt(np.abs(X_sqrt[col])) * np.sign(X_sqrt[col])
        variants['Sqrt_Transform'] = X_sqrt
        
        # 3. æ¨™æº–åŒ– + 2æ¬¡ç‰¹å¾´é‡
        X_poly = X_base.copy()
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_poly)
        X_scaled_df = pd.DataFrame(X_scaled, columns=X_poly.columns)
        
        # é‡è¦ç‰¹å¾´é‡åŒå£«ã®ç©
        X_scaled_df['Market_RSI'] = X_scaled_df['Market_Breadth'] * X_scaled_df['RSI']
        X_scaled_df['Vol_Return'] = X_scaled_df['Volatility_20'] * X_scaled_df['Market_Return']
        variants['Polynomial_Features'] = X_scaled_df
        
        # è©•ä¾¡
        results = {}
        
        for variant_name, X_variant in variants.items():
            logger.info(f"  {variant_name}...")
            
            if variant_name != 'Polynomial_Features':
                X_scaled = StandardScaler().fit_transform(X_variant)
            else:
                X_scaled = X_variant.values
            
            model = LogisticRegression(C=0.01, class_weight='balanced', max_iter=1000, random_state=42)
            
            tscv = TimeSeriesSplit(n_splits=3)
            scores = []
            
            for train_idx, test_idx in tscv.split(X_scaled):
                X_train = X_scaled[train_idx]
                X_test = X_scaled[test_idx]
                y_train = y.iloc[train_idx]
                y_test = y.iloc[test_idx]
                
                model.fit(X_train, y_train)
                pred = model.predict(X_test)
                scores.append(accuracy_score(y_test, pred))
            
            avg_score = np.mean(scores)
            results[variant_name] = avg_score
            logger.info(f"    {variant_name}: {avg_score:.1%}")
        
        return results
    
    def final_best_combination(self, X, y, best_configs):
        """æœ€çµ‚æœ€é©çµ„ã¿åˆã‚ã›ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ¯ æœ€çµ‚æœ€é©çµ„ã¿åˆã‚ã›ãƒ†ã‚¹ãƒˆ...")
        
        # æœ€é©å‰å‡¦ç†
        X_processed = X.clip(lower=X.quantile(0.05), upper=X.quantile(0.95), axis=0)
        X_scaled = StandardScaler().fit_transform(X_processed)
        
        # æœ€é©ãƒ¢ãƒ‡ãƒ«ï¼ˆçµæœã‹ã‚‰é¸æŠï¼‰
        model = LogisticRegression(C=0.01, class_weight={0: 1, 1: 1.2}, max_iter=1000, random_state=42)
        
        # å³å¯†æ¤œè¨¼
        tscv = TimeSeriesSplit(n_splits=5)
        scores = []
        
        logger.info("5åˆ†å‰²æ™‚ç³»åˆ—æ¤œè¨¼å®Ÿè¡Œä¸­...")
        for fold, (train_idx, test_idx) in enumerate(tscv.split(X_scaled)):
            X_train = X_scaled[train_idx]
            X_test = X_scaled[test_idx]
            y_train = y.iloc[train_idx]
            y_test = y.iloc[test_idx]
            
            model.fit(X_train, y_train)
            pred = model.predict(X_test)
            accuracy = accuracy_score(y_test, pred)
            scores.append(accuracy)
            
            logger.info(f"  Fold {fold+1}: {accuracy:.1%}")
        
        final_score = np.mean(scores)
        final_std = np.std(scores)
        
        logger.info(f"\nğŸ¯ æœ€çµ‚æœ€é©åŒ–çµæœ: {final_score:.1%} Â± {final_std:.1%}")
        
        return final_score, final_std

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    logger.info("ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ")
    logger.info("ğŸ¯ ç›®æ¨™: ãƒ‡ãƒ¼ã‚¿è¿½åŠ ä»¥å¤–ã®æ”¹å–„ä½™åœ°æ¤œè¨¼")
    
    optimizer = QuickOptimizer()
    
    try:
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        X, y = optimizer.load_and_prepare_data()
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
        baseline = optimizer.test_baseline(X, y)
        
        # å‰å‡¦ç†ãƒ†ã‚¹ãƒˆ
        preprocessing_results = optimizer.test_preprocessing_variants(X, y)
        
        # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ
        lr_results, rf_results = optimizer.test_hyperparameters(X, y)
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ†ã‚¹ãƒˆ
        ensemble_results = optimizer.test_ensemble_methods(X, y)
        
        # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
        feature_eng_results = optimizer.test_feature_engineering_variants(X, y)
        
        # çµæœã¾ã¨ã‚
        logger.info("\n" + "="*80)
        logger.info("ğŸ¯ ã‚¯ã‚¤ãƒƒã‚¯æœ€é©åŒ–ãƒ†ã‚¹ãƒˆçµæœ")
        logger.info("="*80)
        
        logger.info(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç²¾åº¦: {baseline:.1%}")
        
        # å„ç¨®æ”¹å–„çµæœ
        all_improvements = []
        
        # å‰å‡¦ç†æ”¹å–„
        best_preprocessing = max(preprocessing_results.values())
        preprocessing_improvement = (best_preprocessing - baseline) * 100
        all_improvements.append(preprocessing_improvement)
        logger.info(f"\nğŸ”§ å‰å‡¦ç†æœ€é©åŒ–:")
        logger.info(f"  æœ€é«˜: {best_preprocessing:.1%} (æ”¹å–„: {preprocessing_improvement:+.1f}%)")
        
        # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ”¹å–„
        best_lr = max(lr_results.values())
        best_rf = max(rf_results.values())
        best_hp = max(best_lr, best_rf)
        hp_improvement = (best_hp - baseline) * 100
        all_improvements.append(hp_improvement)
        logger.info(f"\nâš™ï¸ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–:")
        logger.info(f"  æœ€é«˜: {best_hp:.1%} (æ”¹å–„: {hp_improvement:+.1f}%)")
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ”¹å–„
        best_ensemble = max(ensemble_results.values())
        ensemble_improvement = (best_ensemble - baseline) * 100
        all_improvements.append(ensemble_improvement)
        logger.info(f"\nğŸ§  ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•:")
        logger.info(f"  æœ€é«˜: {best_ensemble:.1%} (æ”¹å–„: {ensemble_improvement:+.1f}%)")
        
        # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ”¹å–„
        best_feature_eng = max(feature_eng_results.values())
        feature_eng_improvement = (best_feature_eng - baseline) * 100
        all_improvements.append(feature_eng_improvement)
        logger.info(f"\nâš—ï¸ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°:")
        logger.info(f"  æœ€é«˜: {best_feature_eng:.1%} (æ”¹å–„: {feature_eng_improvement:+.1f}%)")
        
        # æœ€çµ‚æœ€é©çµ„ã¿åˆã‚ã›
        final_score, final_std = optimizer.final_best_combination(X, y, {})
        final_improvement = (final_score - baseline) * 100
        
        # ç·è©•ä¾¡
        max_improvement = max(all_improvements + [final_improvement])
        max_achieved = baseline + max_improvement/100
        
        logger.info(f"\nğŸ† æœ€é«˜é”æˆç²¾åº¦: {max_achieved:.1%}")
        logger.info(f"ğŸ”¥ æœ€å¤§æ”¹å–„å¹…: {max_improvement:+.1f}%")
        logger.info(f"ğŸ¯ æœ€çµ‚çµ„ã¿åˆã‚ã›: {final_score:.1%} Â± {final_std:.1%} (æ”¹å–„: {final_improvement:+.1f}%)")
        
        # æ”¹å–„å¯èƒ½æ€§è©•ä¾¡
        logger.info(f"\nğŸ“Š æ”¹å–„å¯èƒ½æ€§è©•ä¾¡:")
        if max_improvement > 1.0:
            logger.info("âœ… æœ‰æ„ãªæ”¹å–„ãŒå¯èƒ½ã§ã™ (1%ä»¥ä¸Š)")
        elif max_improvement > 0.5:
            logger.info("ğŸ”„ ä¸­ç¨‹åº¦ã®æ”¹å–„ãŒå¯èƒ½ã§ã™ (0.5-1%)")
        elif max_improvement > 0.2:
            logger.info("âš ï¸ é™å®šçš„ãªæ”¹å–„ãŒå¯èƒ½ã§ã™ (0.2-0.5%)")
        else:
            logger.info("âŒ å¤§å¹…ãªæ”¹å–„ã¯å›°é›£ã§ã™ (<0.2%)")
        
        logger.info(f"\nğŸ’¡ çµè«–:")
        if max_improvement > 0.5:
            logger.info("ãƒ‡ãƒ¼ã‚¿è¿½åŠ ä»¥å¤–ã§ã‚‚æ”¹å–„ä½™åœ°ãŒã‚ã‚Šã¾ã™")
        else:
            logger.info("ãƒ‡ãƒ¼ã‚¿è¿½åŠ ä»¥å¤–ã®æ”¹å–„ã¯é™å®šçš„ã§ã™")
        
    except Exception as e:
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()