#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
J-Quants APIæ­£ç¢ºãªéŠ˜æŸ„å–å¾—ã‚·ã‚¹ãƒ†ãƒ 
ä¸Šå ´éŠ˜æŸ„ä¸€è¦§APIã‹ã‚‰æ­£ç¢ºãªéŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã¦ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’å®Ÿè¡Œ
"""

import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time
import os
import json
from pathlib import Path
import logging
from typing import List, Optional, Dict
from dotenv import load_dotenv

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

JQUANTS_BASE_URL = "https://api.jquants.com/v1"

class JQuantsCorrectFetcher:
    """J-Quants APIæ­£ç¢ºãªå½¢å¼ã§ã®æ—¥çµŒ225ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.mail_address = os.getenv("JQUANTS_MAIL_ADDRESS")
        self.password = os.getenv("JQUANTS_PASSWORD")
        self.id_token: Optional[str] = None
        self.token_expires_at: Optional[datetime] = None
        
        if not self.mail_address or not self.password:
            raise ValueError("JQuantsã®èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ (.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„)")
        
        logger.info("J-Quantsæ­£ç¢ºãªéŠ˜æŸ„å–å¾—ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def _get_id_token(self) -> str:
        """IDãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—"""
        if self.id_token and self.token_expires_at and datetime.now() < self.token_expires_at:
            return self.id_token
        
        logger.info("JQuantsèªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ä¸­...")
        time.sleep(3)
        
        try:
            # ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            auth_payload = {
                "mailaddress": self.mail_address,
                "password": self.password
            }
            
            resp = requests.post(
                f"{JQUANTS_BASE_URL}/token/auth_user",
                data=json.dumps(auth_payload),
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            
            if resp.status_code == 429:
                logger.warning("ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã‚ˆã‚Š2åˆ†å¾…æ©Ÿ...")
                time.sleep(120)
                return self._get_id_token()
                
            resp.raise_for_status()
            refresh_token = resp.json().get("refreshToken")
            
            if not refresh_token:
                raise RuntimeError("ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            time.sleep(1)
            resp = requests.post(
                f"{JQUANTS_BASE_URL}/token/auth_refresh?refreshtoken={refresh_token}",
                timeout=30
            )
            
            if resp.status_code == 429:
                logger.warning("ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã‚ˆã‚Š2åˆ†å¾…æ©Ÿ...")
                time.sleep(120)
                return self._get_id_token()
                
            resp.raise_for_status()
            self.id_token = resp.json().get("idToken")
            
            if not self.id_token:
                raise RuntimeError("IDãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            self.token_expires_at = datetime.now() + timedelta(hours=1)
            
            logger.info("èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—å®Œäº†")
            return self.id_token
            
        except Exception as e:
            logger.error(f"èªè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    def get_all_listed_companies(self) -> pd.DataFrame:
        """ä¸Šå ´éŠ˜æŸ„ä¸€è¦§ã‚’å–å¾—ï¼ˆJ-Quants APIã®æ­£ç¢ºãªå½¢å¼ï¼‰"""
        logger.info("ğŸ“‹ ä¸Šå ´éŠ˜æŸ„ä¸€è¦§å–å¾—é–‹å§‹...")
        
        try:
            headers = {"Authorization": f"Bearer {self._get_id_token()}"}
            
            logger.info("J-Quantsä¸Šå ´éŠ˜æŸ„ä¸€è¦§APIå‘¼ã³å‡ºã—ä¸­...")
            resp = requests.get(
                f"{JQUANTS_BASE_URL}/listed/info",
                headers=headers,
                timeout=60
            )
            
            if resp.status_code == 429:
                logger.warning("ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã€30ç§’å¾…æ©Ÿ...")
                time.sleep(30)
                return self.get_all_listed_companies()
            
            resp.raise_for_status()
            data = resp.json()
            
            companies_df = pd.DataFrame(data['info'])
            logger.info(f"âœ… ä¸Šå ´éŠ˜æŸ„ä¸€è¦§å–å¾—å®Œäº†: {len(companies_df)}ç¤¾")
            
            # éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰å½¢å¼ã‚’ç¢ºèª
            logger.info("ğŸ“Š éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰å½¢å¼ç¢ºèª:")
            sample_codes = companies_df['Code'].head(10).tolist()
            logger.info(f"éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ä¾‹: {sample_codes}")
            
            # ãƒ—ãƒ©ã‚¤ãƒ å¸‚å ´ã®å¤§å‹æ ªã‚’é¸æŠï¼ˆæ—¥çµŒ225ç›¸å½“ï¼‰
            prime_large_companies = companies_df[
                (companies_df['MarketCode'] == '0111') &  # ãƒ—ãƒ©ã‚¤ãƒ å¸‚å ´
                (companies_df['ScaleCategory'].isin(['TOPIX Large70', 'TOPIX Mid400']))
            ].copy()
            
            logger.info(f"ğŸ“Š ãƒ—ãƒ©ã‚¤ãƒ å¸‚å ´å¤§å‹æ ª: {len(prime_large_companies)}ç¤¾")
            
            # æœ‰åä¼æ¥­åã§ã®è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿
            major_companies = companies_df[
                companies_df['CompanyName'].str.contains(
                    'ãƒˆãƒ¨ã‚¿|ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯|ã‚½ãƒ‹ãƒ¼|æ—¥æœ¬é›»ä¿¡é›»è©±|ä¸‰è±UFJ|æ—¥ç«‹|ãƒ›ãƒ³ãƒ€|ä»»å¤©å ‚|ã‚­ãƒ¤ãƒãƒ³|ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯', 
                    na=False
                )
            ]
            
            # ãƒ—ãƒ©ã‚¤ãƒ å¤§å‹æ ªã¨æœ‰åä¼æ¥­ã‚’çµ±åˆ
            selected_companies = pd.concat([prime_large_companies, major_companies]).drop_duplicates()
            logger.info(f"ğŸ“ˆ é¸æŠã•ã‚ŒãŸéŠ˜æŸ„æ•°: {len(selected_companies)}ç¤¾")
            
            return selected_companies
            
        except Exception as e:
            logger.error(f"éŠ˜æŸ„ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return pd.DataFrame()
    
    def get_stock_data_by_correct_codes(self, companies_df: pd.DataFrame, years: int = 5) -> pd.DataFrame:
        """æ­£ç¢ºãªéŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã§æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        logger.info(f"ğŸ“ˆ æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹: {len(companies_df)}éŠ˜æŸ„, {years}å¹´é–“")
        
        # æœŸé–“è¨­å®š
        to_date = datetime.now().strftime('%Y-%m-%d')
        from_date = (datetime.now() - timedelta(days=365*years)).strftime('%Y-%m-%d')
        logger.info(f"ğŸ“… å–å¾—æœŸé–“: {from_date} ï½ {to_date}")
        
        all_stock_data = []
        successful_companies = []
        failed_companies = []
        
        # æœ€å¤§50éŠ˜æŸ„ã«åˆ¶é™ï¼ˆAPIåˆ¶é™ã¨å‡¦ç†æ™‚é–“è€ƒæ…®ï¼‰
        selected_companies = companies_df.head(50)
        
        for idx, (_, company) in enumerate(selected_companies.iterrows(), 1):
            code = company['Code']
            company_name = company['CompanyName']
            
            try:
                logger.info(f"éŠ˜æŸ„ {code} ({company_name}) ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­... ({idx}/{len(selected_companies)}) - {idx/len(selected_companies)*100:.1f}%å®Œäº†")
                
                headers = {"Authorization": f"Bearer {self._get_id_token()}"}
                params = {
                    "code": code,  # J-Quantsã®æ­£ç¢ºãª5æ¡ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
                    "from": from_date,
                    "to": to_date
                }
                
                resp = requests.get(
                    f"{JQUANTS_BASE_URL}/prices/daily_quotes",
                    headers=headers,
                    params=params,
                    timeout=120
                )
                
                if resp.status_code == 429:
                    logger.warning(f"éŠ˜æŸ„ {code}: ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã€30ç§’å¾…æ©Ÿ...")
                    time.sleep(30)
                    continue
                
                if resp.status_code != 200:
                    logger.warning(f"éŠ˜æŸ„ {code}: ã‚¨ãƒ©ãƒ¼ {resp.status_code}")
                    failed_companies.append(f"{code}({company_name})")
                    continue
                
                data = resp.json()
                daily_quotes = data.get("daily_quotes", [])
                
                if daily_quotes:
                    stock_df = pd.DataFrame(daily_quotes)
                    # ä¼æ¥­åã‚’è¿½åŠ 
                    stock_df['CompanyName'] = company_name
                    all_stock_data.append(stock_df)
                    successful_companies.append(f"{code}({company_name})")
                    logger.info(f"  âœ… éŠ˜æŸ„ {code}: {len(daily_quotes)}ä»¶å–å¾—æˆåŠŸ")
                else:
                    logger.warning(f"  âŒ éŠ˜æŸ„ {code}: ãƒ‡ãƒ¼ã‚¿ãªã—")
                    failed_companies.append(f"{code}({company_name})")
                
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                time.sleep(2)
                
                # 10éŠ˜æŸ„ã”ã¨ã«é•·ã„å¾…æ©Ÿ
                if idx % 10 == 0:
                    logger.info(f"  â¸ï¸  10éŠ˜æŸ„å‡¦ç†å®Œäº†ã€10ç§’å¾…æ©Ÿ...")
                    time.sleep(10)
                
            except Exception as e:
                logger.error(f"éŠ˜æŸ„ {code} å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
                failed_companies.append(f"{code}({company_name})")
                continue
        
        if not all_stock_data:
            logger.error("âŒ å…¨éŠ˜æŸ„ã§ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—")
            return pd.DataFrame()
        
        # ãƒ‡ãƒ¼ã‚¿çµ±åˆ
        logger.info("ğŸ”„ ãƒ‡ãƒ¼ã‚¿çµ±åˆä¸­...")
        combined_df = pd.concat(all_stock_data, ignore_index=True)
        
        logger.info("="*60)
        logger.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—çµæœ")
        logger.info("="*60)
        logger.info(f"âœ… æˆåŠŸéŠ˜æŸ„æ•°: {len(successful_companies)}éŠ˜æŸ„")
        logger.info(f"âŒ å¤±æ•—éŠ˜æŸ„æ•°: {len(failed_companies)}éŠ˜æŸ„")
        logger.info(f"ğŸ“Š ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(combined_df):,}ä»¶")
        logger.info(f"ğŸ“… æœŸé–“: {combined_df['Date'].min()} ï½ {combined_df['Date'].max()}")
        
        if successful_companies:
            logger.info("âœ… æˆåŠŸéŠ˜æŸ„:")
            for company in successful_companies[:10]:  # æœ€åˆã®10ç¤¾ã®ã¿è¡¨ç¤º
                logger.info(f"  {company}")
        
        if failed_companies:
            logger.info("âŒ å¤±æ•—éŠ˜æŸ„:")
            for company in failed_companies[:5]:  # æœ€åˆã®5ç¤¾ã®ã¿è¡¨ç¤º
                logger.info(f"  {company}")
        
        return combined_df
    
    def create_enhanced_dataset(self) -> pd.DataFrame:
        """æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
        logger.info("ğŸš€ J-Quantsæ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆé–‹å§‹")
        
        # 1. ä¸Šå ´éŠ˜æŸ„ä¸€è¦§å–å¾—
        companies_df = self.get_all_listed_companies()
        
        if companies_df.empty:
            logger.error("âŒ éŠ˜æŸ„ä¸€è¦§å–å¾—ã«å¤±æ•—")
            return pd.DataFrame()
        
        # 2. æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆ5å¹´é–“ï¼‰
        expanded_df = self.get_stock_data_by_correct_codes(companies_df, years=5)
        
        if expanded_df.empty:
            logger.error("âŒ æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—")
            return pd.DataFrame()
        
        # 3. æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨ã®çµ±åˆ
        existing_path = Path("data/processed/real_jquants_data.parquet")
        if existing_path.exists():
            existing_df = pd.read_parquet(existing_path)
            logger.info(f"ğŸ“ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿: {len(existing_df):,}ä»¶, {existing_df['Code'].nunique()}éŠ˜æŸ„")
            
            # ãƒ‡ãƒ¼ã‚¿çµ±åˆï¼ˆé‡è¤‡é™¤å»ï¼‰
            combined_df = pd.concat([existing_df, expanded_df], ignore_index=True)
            combined_df = combined_df.drop_duplicates(subset=['Date', 'Code']).sort_values(['Code', 'Date'])
            logger.info(f"ğŸ“Š çµ±åˆå¾Œãƒ‡ãƒ¼ã‚¿: {len(combined_df):,}ä»¶, {combined_df['Code'].nunique()}éŠ˜æŸ„")
        else:
            combined_df = expanded_df
            logger.info("ğŸ“Š æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨")
        
        # 4. ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        output_dir = Path("data/enhanced_jquants")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = output_dir / f"enhanced_jquants_{len(combined_df)}records_{timestamp}.parquet"
        
        combined_df.to_parquet(output_file, index=False)
        logger.info(f"ğŸ’¾ æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¿å­˜: {output_file}")
        
        logger.info("ğŸ‰ J-Quantsæ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†")
        return combined_df


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("ğŸš€ J-Quantsæ­£ç¢ºãªéŠ˜æŸ„å–å¾—ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
    
    try:
        fetcher = JQuantsCorrectFetcher()
        enhanced_df = fetcher.create_enhanced_dataset()
        
        if not enhanced_df.empty:
            logger.info("="*60)
            logger.info("ğŸ‰ æ‹¡å¼µãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†")
            logger.info("="*60)
            logger.info(f"ğŸ“Š ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(enhanced_df):,}ä»¶")
            logger.info(f"ğŸ“Š ç·éŠ˜æŸ„æ•°: {enhanced_df['Code'].nunique()}éŠ˜æŸ„")
            logger.info(f"ğŸ“… æœŸé–“: {enhanced_df['Date'].min()} ï½ {enhanced_df['Date'].max()}")
            
            # éŠ˜æŸ„åˆ¥çµ±è¨ˆ
            print("\nğŸ“ˆ éŠ˜æŸ„åˆ¥ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ï¼ˆä¸Šä½10éŠ˜æŸ„ï¼‰:")
            top_stocks = enhanced_df['Code'].value_counts().head(10)
            for code, count in top_stocks.items():
                company_name = enhanced_df[enhanced_df['Code'] == code]['CompanyName'].iloc[0] if 'CompanyName' in enhanced_df.columns else 'N/A'
                print(f"  {code} ({company_name}): {count:,}ä»¶")
            
            logger.info("ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: enhanced_precision_with_full_data.pyã§æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã®ç²¾åº¦ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
                
        else:
            logger.error("âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
    except Exception as e:
        logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise


if __name__ == "__main__":
    main()