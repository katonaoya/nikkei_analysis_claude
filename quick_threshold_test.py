#!/usr/bin/env python3
"""
ä¿¡é ¼åº¦é–¾å€¤åˆ¥ç²¾åº¦ãƒ†ã‚¹ãƒˆï¼ˆé«˜é€Ÿç‰ˆï¼‰
æ—¢å­˜ã®test_ai_accuracy.pyã‚’æ”¹è‰¯ã—ã¦5ã¤ã®é–¾å€¤ã§æ¯”è¼ƒ
"""

import pandas as pd
import numpy as np
import yaml
from datetime import datetime
from pathlib import Path
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import precision_score
from loguru import logger
import warnings
warnings.filterwarnings('ignore')

def quick_threshold_comparison():
    """é«˜é€Ÿé–¾å€¤æ¯”è¼ƒãƒ†ã‚¹ãƒˆ"""
    
    # è¨­å®šèª­ã¿è¾¼ã¿
    config_path = Path("production_config.yaml")
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    optimal_features = config['features']['optimal_features']
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    logger.info("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿...")
    data_dir = Path(config['data']['processed_dir'])
    integrated_file = data_dir / config['data']['integrated_file']
    df = pd.read_parquet(integrated_file)
    
    # ã‚«ãƒ©ãƒ èª¿æ•´
    if 'Target' not in df.columns and 'Binary_Direction' in df.columns:
        df['Target'] = df['Binary_Direction']
    if 'Stock' not in df.columns and 'Code' in df.columns:
        df['Stock'] = df['Code']
    
    logger.info(f"ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(df):,}ä»¶")
    
    # ãƒ†ã‚¹ãƒˆæœŸé–“ã®è¨­å®šï¼ˆç›´è¿‘15æ—¥ã§ãƒ†ã‚¹ãƒˆï¼‰
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values('Date')
    unique_dates = sorted(df['Date'].unique())
    test_dates = unique_dates[-15:]  # é«˜é€ŸåŒ–ã®ãŸã‚15æ—¥ã«çŸ­ç¸®
    
    # ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®é–¾å€¤
    thresholds = [0.50, 0.55, 0.60, 0.65, 0.70]
    
    logger.info("ğŸ¯ é–¾å€¤åˆ¥ãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    results = {}
    
    for threshold in thresholds:
        logger.info(f"  é–¾å€¤ {threshold:.0%} ãƒ†ã‚¹ãƒˆä¸­...")
        
        all_predictions = []
        all_actuals = []
        daily_counts = []
        
        for test_date in test_dates:
            # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
            train_data = df[df['Date'] < test_date]
            test_data = df[df['Date'] == test_date]
            
            if len(train_data) < 1000 or len(test_data) < 10:
                continue
            
            # ã‚¯ãƒªãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿
            train_clean = train_data[['Date', 'Stock', 'Target'] + optimal_features].dropna()
            test_clean = test_data[['Date', 'Stock', 'Target'] + optimal_features].dropna()
            
            if len(train_clean) == 0 or len(test_clean) == 0:
                continue
            
            X_train = train_clean[optimal_features]
            y_train = train_clean['Target']
            X_test = test_clean[optimal_features]
            y_test = test_clean['Target']
            
            # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # é«˜é€ŸãªLogisticRegressionã‚’ä½¿ç”¨
            model = LogisticRegression(random_state=42, max_iter=500)
            model.fit(X_train_scaled, y_train)
            
            # äºˆæ¸¬ç¢ºç‡
            y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
            
            # é–¾å€¤ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            high_conf_indices = y_pred_proba >= threshold
            
            if sum(high_conf_indices) > 0:
                # é–¾å€¤ä»¥ä¸Šã®éŠ˜æŸ„ã¯å…¨ã¦ã€Œä¸Šæ˜‡ã€äºˆæ¸¬
                selected_predictions = np.ones(sum(high_conf_indices))
                selected_actuals = y_test[high_conf_indices]
                
                all_predictions.extend(selected_predictions)
                all_actuals.extend(selected_actuals)
                daily_counts.append(sum(high_conf_indices))
        
        # çµæœè¨ˆç®—
        if len(all_predictions) > 0:
            precision = sum([a for a, p in zip(all_actuals, all_predictions) if a == 1 and p == 1]) / len(all_predictions)
            avg_daily = np.mean(daily_counts) if daily_counts else 0
            
            results[threshold] = {
                'precision': precision,
                'total_selected': len(all_predictions),
                'total_correct': sum(all_actuals),
                'avg_daily_picks': avg_daily,
                'test_days': len([d for d in daily_counts if d > 0])
            }
        else:
            results[threshold] = {
                'precision': 0,
                'total_selected': 0,
                'total_correct': 0,
                'avg_daily_picks': 0,
                'test_days': 0
            }
    
    # çµæœè¡¨ç¤º
    print("\n" + "="*80)
    print("ğŸ“Š ä¿¡é ¼åº¦é–¾å€¤åˆ¥ç²¾åº¦æ¯”è¼ƒãƒ†ã‚¹ãƒˆçµæœï¼ˆç›´è¿‘15æ—¥é–“ï¼‰")
    print("="*80)
    
    print(f"\n{'é–¾å€¤':<8} {'ç²¾åº¦':<10} {'ç·é¸æŠ':<8} {'çš„ä¸­æ•°':<8} {'1æ—¥å¹³å‡':<10} {'å–å¼•æ—¥æ•°':<8}")
    print("-"*65)
    
    for threshold in thresholds:
        r = results[threshold]
        print(f"{threshold:.0%}      {r['precision']:<10.2%} "
              f"{r['total_selected']:<8d} {r['total_correct']:<8d} "
              f"{r['avg_daily_picks']:<10.1f} {r['test_days']:<8d}")
    
    print("\nğŸ“ˆ ã€è©³ç´°åˆ†æã€‘")
    
    for threshold in thresholds:
        r = results[threshold]
        if r['total_selected'] > 0:
            print(f"\nğŸ¯ é–¾å€¤ {threshold:.0%}:")
            print(f"  â€¢ ç²¾åº¦: {r['precision']:.2%}")
            print(f"  â€¢ ç·é¸æŠæ•°: {r['total_selected']}éŠ˜æŸ„")
            print(f"  â€¢ çš„ä¸­æ•°: {r['total_correct']}éŠ˜æŸ„")
            print(f"  â€¢ 1æ—¥å¹³å‡é¸æŠæ•°: {r['avg_daily_picks']:.1f}éŠ˜æŸ„")
            print(f"  â€¢ å–å¼•ãŒç™ºç”Ÿã—ãŸæ—¥æ•°: {r['test_days']}/15æ—¥")
            
            if r['test_days'] > 0:
                frequency = r['test_days'] / 15 * 100
                print(f"  â€¢ å–å¼•é »åº¦: {frequency:.1f}%")
        else:
            print(f"\nğŸ¯ é–¾å€¤ {threshold:.0%}: é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ãªã—")
    
    # æ¨å¥¨äº‹é …
    print(f"\nğŸ’¡ ã€æ¨å¥¨äº‹é …ã€‘")
    
    # 60%ä»¥ä¸Šã®ç²¾åº¦ã‚’é”æˆã—ãŸé–¾å€¤
    good_results = [(t, r) for t, r in results.items() 
                   if r['precision'] >= 0.60 and r['total_selected'] > 5]
    
    if good_results:
        best_threshold, best_result = max(good_results, key=lambda x: x[1]['precision'])
        print(f"âœ… 60%ä»¥ä¸Šé”æˆ: é–¾å€¤ {best_threshold:.0%}")
        print(f"   â†’ ç²¾åº¦: {best_result['precision']:.2%}")
        print(f"   â†’ 1æ—¥å¹³å‡: {best_result['avg_daily_picks']:.1f}éŠ˜æŸ„")
        print(f"   â†’ ã“ã®è¨­å®šã‚’æ¨å¥¨ã—ã¾ã™")
        
        # è¨­å®šæ›´æ–°ã®ææ¡ˆ
        if abs(best_threshold - config['system']['confidence_threshold']) > 0.01:
            print(f"\nğŸ”§ è¨­å®šæ›´æ–°ææ¡ˆ:")
            print(f"   ç¾åœ¨: {config['system']['confidence_threshold']:.0%}")
            print(f"   æ¨å¥¨: {best_threshold:.0%}")
    else:
        # æœ€ã‚‚ç²¾åº¦ã®é«˜ã„é–¾å€¤ã‚’æ¨å¥¨
        best_threshold = max(thresholds, key=lambda t: results[t]['precision'])
        best_result = results[best_threshold]
        print(f"ğŸ“ ç¾çŠ¶æœ€è‰¯: é–¾å€¤ {best_threshold:.0%}")
        print(f"   â†’ ç²¾åº¦: {best_result['precision']:.2%}")
        print(f"   â†’ 1æ—¥å¹³å‡: {best_result['avg_daily_picks']:.1f}éŠ˜æŸ„")
        
        if best_result['precision'] < 0.60:
            print(f"   â†’ 60%ç›®æ¨™ã¾ã§: +{0.60 - best_result['precision']:.2%}")
    
    print(f"\nğŸ“‹ ã€é‹ç”¨ã‚¬ã‚¤ãƒ‰ã€‘")
    print("â€¢ é«˜ç²¾åº¦é‡è¦–: 65-70%é–¾å€¤ï¼ˆé€±1-2å›ã®å³é¸å–å¼•ï¼‰")
    print("â€¢ ãƒãƒ©ãƒ³ã‚¹å‹: 55-60%é–¾å€¤ï¼ˆé€±2-3å›ã®å®‰å®šå–å¼•ï¼‰")
    print("â€¢ é »åº¦é‡è¦–: 50-55%é–¾å€¤ï¼ˆã»ã¼æ¯æ—¥ã ãŒç²¾åº¦ã¯æ§ãˆã‚ï¼‰")
    
    print("\n" + "="*80)

if __name__ == "__main__":
    quick_threshold_comparison()