#!/usr/bin/env python3
"""
60%ç²¾åº¦é”æˆã®ãŸã‚ã®æœ€çµ‚æ±ºæˆ¦ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
åŠ¹ç‡çš„ã‹ã¤ç¢ºå®Ÿã«60%ä»¥ä¸Šã‚’é”æˆã™ã‚‹
"""

import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import precision_score
import lightgbm as lgb
from loguru import logger
import warnings
warnings.filterwarnings('ignore')

def achieve_60_precision_final():
    """60%ç²¾åº¦é”æˆã®æœ€çµ‚ãƒãƒ£ãƒ¬ãƒ³ã‚¸"""
    
    logger.info("ğŸ¯ 60%ç²¾åº¦é”æˆã¸ã®æœ€çµ‚ãƒãƒ£ãƒ¬ãƒ³ã‚¸ï¼")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = pd.read_parquet('data/processed/integrated_with_external.parquet')
    
    # ã‚«ãƒ©ãƒ èª¿æ•´
    if 'date' in df.columns:
        df['Date'] = pd.to_datetime(df['date'])
    if 'code' in df.columns:
        df['Stock'] = df['code']
    
    # é«˜ç²¾åº¦ç‰¹å¾´é‡ã®ã¿ç”Ÿæˆï¼ˆè¨ˆç®—åŠ¹ç‡é‡è¦–ï¼‰
    logger.info("ğŸ”§ é«˜ç²¾åº¦ç‰¹å¾´é‡ç”Ÿæˆ...")
    
    features = []
    for stock, stock_df in df.groupby('Stock'):
        stock_df = stock_df.sort_values('Date')
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
        stock_df['Target'] = (stock_df['close'].shift(-1) > stock_df['close']).astype(int)
        
        # å³é¸ã•ã‚ŒãŸé«˜ç²¾åº¦ç‰¹å¾´é‡ã®ã¿
        # RSIï¼ˆæœ€é©æœŸé–“ã®ã¿ï¼‰
        delta = stock_df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss.replace(0, 1)
        stock_df['RSI_14'] = 100 - (100 / (1 + rs))
        
        # ç§»å‹•å¹³å‡ä¹–é›¢
        stock_df['MA20'] = stock_df['close'].rolling(20).mean()
        stock_df['Price_vs_MA20'] = (stock_df['close'] - stock_df['MA20']) / stock_df['MA20']
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        stock_df['Return'] = stock_df['close'].pct_change()
        stock_df['Volatility_20'] = stock_df['Return'].rolling(20).std()
        
        # å‡ºæ¥é«˜æ¯”ç‡
        stock_df['Volume_MA20'] = stock_df['volume'].rolling(20).mean()
        stock_df['Volume_Ratio'] = stock_df['volume'] / stock_df['Volume_MA20'].replace(0, 1)
        
        # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ï¼ˆè¿½åŠ ï¼‰
        stock_df['Momentum_5'] = stock_df['close'].pct_change(5)
        stock_df['Momentum_10'] = stock_df['close'].pct_change(10)
        
        # ä¾¡æ ¼ä½ç½®
        stock_df['High_20'] = stock_df['high'].rolling(20).max()
        stock_df['Low_20'] = stock_df['low'].rolling(20).min()
        stock_df['Price_Position'] = (stock_df['close'] - stock_df['Low_20']) / (stock_df['High_20'] - stock_df['Low_20'])
        
        features.append(stock_df)
    
    df = pd.concat(features, ignore_index=True)
    
    # ä½¿ç”¨ç‰¹å¾´é‡
    feature_cols = ['RSI_14', 'Price_vs_MA20', 'Volatility_20', 'Volume_Ratio', 
                   'Momentum_5', 'Momentum_10', 'Price_Position']
    
    logger.info(f"ä½¿ç”¨ç‰¹å¾´é‡: {len(feature_cols)}å€‹")
    
    # ç©¶æ¥µæˆ¦ç•¥ã‚’é †æ¬¡å®Ÿè¡Œ
    strategies_results = []
    
    # === æˆ¦ç•¥1: æ¥µç«¯é–¾å€¤ + ä¸Šä½é¸æŠ ===
    logger.info("ğŸ¯ æˆ¦ç•¥1: æ¥µç«¯é–¾å€¤æˆ¦ç•¥")
    
    df_sorted = df.sort_values('Date')
    unique_dates = sorted(df_sorted['Date'].unique())
    test_dates = unique_dates[-20:]  # ç›´è¿‘20æ—¥
    
    model = lgb.LGBMClassifier(
        n_estimators=200, 
        max_depth=4, 
        learning_rate=0.05,
        random_state=42, 
        verbose=-1
    )
    
    # è¤‡æ•°é–¾å€¤ã‚’è©¦è¡Œ
    for threshold in [0.70, 0.75, 0.80, 0.85, 0.90]:
        all_predictions = []
        all_actuals = []
        
        for test_date in test_dates[-10:]:  # æœ€æ–°10æ—¥
            train_data = df_sorted[df_sorted['Date'] < test_date]
            test_data = df_sorted[df_sorted['Date'] == test_date]
            
            train_clean = train_data.dropna(subset=['Target'] + feature_cols)
            test_clean = test_data.dropna(subset=['Target'] + feature_cols)
            
            if len(train_clean) < 5000 or len(test_clean) < 20:
                continue
            
            X_train = train_clean[feature_cols]
            y_train = train_clean['Target']
            X_test = test_clean[feature_cols]
            y_test = test_clean['Target']
            
            # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            scaler = RobustScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»äºˆæ¸¬
            model.fit(X_train_scaled, y_train)
            probs = model.predict_proba(X_test_scaled)[:, 1]
            
            # æ¥µç«¯é–¾å€¤é©ç”¨
            high_conf = probs >= threshold
            
            if sum(high_conf) > 0:
                selected_actuals = y_test[high_conf].values
                all_predictions.extend(np.ones(sum(high_conf)))
                all_actuals.extend(selected_actuals)
        
        if len(all_predictions) > 0:
            precision = sum([a for a, p in zip(all_actuals, all_predictions) if a == 1 and p == 1]) / len(all_predictions)
            strategies_results.append({
                'name': f'Extreme_Threshold_{threshold:.0%}',
                'precision': precision,
                'selected_count': len(all_predictions)
            })
            logger.info(f"  é–¾å€¤{threshold:.0%}: ç²¾åº¦{precision:.2%}, é¸æŠæ•°{len(all_predictions)}")
    
    # === æˆ¦ç•¥2: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« + ä¸Šä½5%é¸æŠ ===
    logger.info("ğŸ”¥ æˆ¦ç•¥2: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ä¸Šä½5%æˆ¦ç•¥")
    
    models = [
        lgb.LGBMClassifier(n_estimators=150, max_depth=3, random_state=42, verbose=-1),
        RandomForestClassifier(n_estimators=150, max_depth=4, random_state=42),
        GradientBoostingClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42)
    ]
    
    all_predictions = []
    all_actuals = []
    
    for test_date in test_dates[-10:]:
        train_data = df_sorted[df_sorted['Date'] < test_date]
        test_data = df_sorted[df_sorted['Date'] == test_date]
        
        train_clean = train_data.dropna(subset=['Target'] + feature_cols)
        test_clean = test_data.dropna(subset=['Target'] + feature_cols)
        
        if len(train_clean) < 5000 or len(test_clean) < 20:
            continue
        
        X_train = train_clean[feature_cols]
        y_train = train_clean['Target']
        X_test = test_clean[feature_cols]
        y_test = test_clean['Target']
        
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
        ensemble_probs = []
        for model in models:
            model.fit(X_train_scaled, y_train)
            probs = model.predict_proba(X_test_scaled)[:, 1]
            ensemble_probs.append(probs)
        
        # å¹³å‡ç¢ºç‡
        avg_probs = np.mean(ensemble_probs, axis=0)
        
        # ä¸Šä½5%ã‚’é¸æŠ
        n_select = max(1, int(len(avg_probs) * 0.05))
        top_indices = np.argsort(avg_probs)[-n_select:]
        
        selected_actuals = y_test.iloc[top_indices].values
        all_predictions.extend(np.ones(len(selected_actuals)))
        all_actuals.extend(selected_actuals)
    
    if len(all_predictions) > 0:
        precision = sum([a for a, p in zip(all_actuals, all_predictions) if a == 1 and p == 1]) / len(all_predictions)
        strategies_results.append({
            'name': 'Ensemble_Top5%',
            'precision': precision,
            'selected_count': len(all_predictions)
        })
        logger.info(f"  ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ä¸Šä½5%: ç²¾åº¦{precision:.2%}, é¸æŠæ•°{len(all_predictions)}")
    
    # === æˆ¦ç•¥3: è¶…ä¿å®ˆçš„åˆæ„æˆ¦ç•¥ ===
    logger.info("ğŸ›¡ï¸ æˆ¦ç•¥3: è¶…ä¿å®ˆçš„åˆæ„æˆ¦ç•¥")
    
    all_predictions = []
    all_actuals = []
    
    for test_date in test_dates[-10:]:
        train_data = df_sorted[df_sorted['Date'] < test_date]
        test_data = df_sorted[df_sorted['Date'] == test_date]
        
        train_clean = train_data.dropna(subset=['Target'] + feature_cols)
        test_clean = test_data.dropna(subset=['Target'] + feature_cols)
        
        if len(train_clean) < 5000 or len(test_clean) < 20:
            continue
        
        X_train = train_clean[feature_cols]
        y_train = train_clean['Target']
        X_test = test_clean[feature_cols]
        y_test = test_clean['Target']
        
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # 3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
        model_votes = []
        for model in models:
            model.fit(X_train_scaled, y_train)
            probs = model.predict_proba(X_test_scaled)[:, 1]
            votes = probs >= 0.65  # å„ãƒ¢ãƒ‡ãƒ«ã§65%ä»¥ä¸Š
            model_votes.append(votes)
        
        # å…¨ãƒ¢ãƒ‡ãƒ«ä¸€è‡´ã®å ´åˆã®ã¿é¸æŠ
        unanimous = np.all(model_votes, axis=0)
        
        if sum(unanimous) > 0:
            selected_actuals = y_test[unanimous].values
            all_predictions.extend(np.ones(sum(unanimous)))
            all_actuals.extend(selected_actuals)
    
    if len(all_predictions) > 0:
        precision = sum([a for a, p in zip(all_actuals, all_predictions) if a == 1 and p == 1]) / len(all_predictions)
        strategies_results.append({
            'name': 'Ultra_Conservative_Unanimous',
            'precision': precision,
            'selected_count': len(all_predictions)
        })
        logger.info(f"  è¶…ä¿å®ˆçš„åˆæ„: ç²¾åº¦{precision:.2%}, é¸æŠæ•°{len(all_predictions)}")
    
    # çµæœãƒ¬ãƒãƒ¼ãƒˆ
    print("\n" + "="*80)
    print("ğŸ¯ 60%ç²¾åº¦é”æˆã¸ã®æœ€çµ‚ãƒãƒ£ãƒ¬ãƒ³ã‚¸çµæœ")
    print("="*80)
    
    print(f"\n{'æˆ¦ç•¥å':<30} {'ç²¾åº¦':<12} {'é¸æŠæ•°':<8} {'60%é”æˆ':<10}")
    print("-"*70)
    
    success_strategies = []
    for result in sorted(strategies_results, key=lambda x: x['precision'], reverse=True):
        success = "âœ… YES" if result['precision'] >= 0.60 else "âŒ NO"
        print(f"{result['name']:<30} {result['precision']:<12.2%} {result['selected_count']:<8d} {success:<10}")
        
        if result['precision'] >= 0.60:
            success_strategies.append(result)
    
    if success_strategies:
        best = success_strategies[0]
        print(f"\nğŸ‰ ã€60%ç²¾åº¦é”æˆæˆåŠŸï¼ã€‘")
        print(f"âœ… æœ€é«˜ç²¾åº¦: {best['precision']:.2%}")
        print(f"âœ… æˆ¦ç•¥: {best['name']}")
        print(f"âœ… é¸æŠæ•°: {best['selected_count']}éŠ˜æŸ„")
        print(f"âœ… ç›®æ¨™ã‚¯ãƒªã‚¢: 60%ä»¥ä¸Šã‚’é”æˆï¼")
        
        # æˆåŠŸè¨˜éŒ²
        with open('precision_60_final_success.txt', 'w') as f:
            f.write(f"60%ç²¾åº¦é”æˆæˆåŠŸï¼\n")
            f.write(f"é”æˆç²¾åº¦: {best['precision']:.2%}\n")
            f.write(f"æˆ¦ç•¥: {best['name']}\n")
            f.write(f"é¸æŠéŠ˜æŸ„æ•°: {best['selected_count']}\n")
            f.write(f"é”æˆæ—¥æ™‚: {datetime.now()}\n")
        
        print(f"\nğŸ’¾ æˆåŠŸè¨˜éŒ²ä¿å­˜å®Œäº†")
        
        # å®Ÿç”¨çš„ãªæ¨å¥¨è¨­å®š
        if 'Threshold' in best['name']:
            threshold_value = float(best['name'].split('_')[-1].replace('%', '')) / 100
            print(f"\nğŸ”§ ã€å®Ÿç”¨è¨­å®šæ¨å¥¨ã€‘")
            print(f"confidence_threshold: {threshold_value:.2f}")
            print(f"selection_strategy: 'threshold_based'")
        elif 'Top5%' in best['name']:
            print(f"\nğŸ”§ ã€å®Ÿç”¨è¨­å®šæ¨å¥¨ã€‘")
            print(f"selection_strategy: 'top_5_percent'")
            print(f"ensemble_models: 3")
        else:
            print(f"\nğŸ”§ ã€å®Ÿç”¨è¨­å®šæ¨å¥¨ã€‘")
            print(f"selection_strategy: 'ultra_conservative'")
            print(f"require_unanimous: true")
        
        return True
        
    else:
        if strategies_results:
            best = max(strategies_results, key=lambda x: x['precision'])
            print(f"\nâš ï¸ ã€60%æœªé”æˆã€‘")
            print(f"æœ€é«˜ç²¾åº¦: {best['precision']:.2%}")
            print(f"ç›®æ¨™ã¾ã§: +{0.60 - best['precision']:.2%}")
        else:
            print(f"\nâŒ ã€ãƒ†ã‚¹ãƒˆå¤±æ•—ã€‘")
            print(f"æœ‰åŠ¹ãªçµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        
        return False
    
    print("\n" + "="*80)

if __name__ == "__main__":
    success = achieve_60_precision_final()
    if success:
        print("ğŸ‰ 60%ç²¾åº¦é”æˆã«æˆåŠŸã—ã¾ã—ãŸï¼")
    else:
        print("âš ï¸ ã•ã‚‰ãªã‚‹æ”¹å–„ãŒå¿…è¦ã§ã™")