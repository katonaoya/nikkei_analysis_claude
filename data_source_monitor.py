#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã‚’å®šæœŸçš„ã«ç›£è¦–ã—ã€ç•°å¸¸ãŒã‚ã‚Œã°å³åº§ã«é€šçŸ¥
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import logging
import hashlib
import json

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DataSourceMonitor:
    """ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.data_dir = Path("./data")
        self.monitor_dir = Path("./data_monitoring")
        self.monitor_dir.mkdir(exist_ok=True)
        
    def get_data_fingerprint(self, df):
        """ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ³ã‚¬ãƒ¼ãƒ—ãƒªãƒ³ãƒˆã‚’ç”Ÿæˆ"""
        # ä¸»è¦çµ±è¨ˆå€¤ã‹ã‚‰ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆ
        stats = {
            'record_count': len(df),
            'stock_count': df['Code'].nunique(),
            'price_mean': float(df['Close'].mean()),
            'price_std': float(df['Close'].std()),
            'date_range': f"{df['Date'].min()}_{df['Date'].max()}"
        }
        
        stats_str = json.dumps(stats, sort_keys=True)
        fingerprint = hashlib.md5(stats_str.encode()).hexdigest()
        return fingerprint, stats
    
    def check_data_consistency(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é–“ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        logger.info("ğŸ” ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯é–‹å§‹")
        
        # real_jquants_data.parquetã‚’ãƒã‚§ãƒƒã‚¯
        real_path = self.data_dir / "processed" / "real_jquants_data.parquet"
        enhanced_path = self.data_dir / "processed" / "enhanced_jquants_data.parquet"
        
        issues = []
        
        if real_path.exists():
            real_df = pd.read_parquet(real_path)
            real_df['Date'] = pd.to_datetime(real_df['Date']).dt.date
            real_fingerprint, real_stats = self.get_data_fingerprint(real_df)
            
            logger.info(f"ğŸ“Š real_jquants_data: {real_stats['record_count']:,}ä»¶, {real_stats['stock_count']}éŠ˜æŸ„")
            logger.info(f"   ä¾¡æ ¼ç¯„å›²: {real_df['Close'].min():.0f} ~ {real_df['Close'].max():.0f}å††")
            
            # ç•°å¸¸ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚§ãƒƒã‚¯
            if real_df['Close'].min() < 10 or real_df['Close'].max() > 100000:
                issues.append({
                    'type': 'price_range_anomaly',
                    'source': 'real_jquants_data',
                    'details': f"ä¾¡æ ¼ç¯„å›²ç•°å¸¸: {real_df['Close'].min():.0f} ~ {real_df['Close'].max():.0f}å††"
                })
        
        if enhanced_path.exists():
            enhanced_df = pd.read_parquet(enhanced_path)
            enhanced_df['Date'] = pd.to_datetime(enhanced_df['Date']).dt.date
            enhanced_fingerprint, enhanced_stats = self.get_data_fingerprint(enhanced_df)
            
            logger.info(f"ğŸ“Š enhanced_jquants_data: {enhanced_stats['record_count']:,}ä»¶, {enhanced_stats['stock_count']}éŠ˜æŸ„")
            logger.info(f"   ä¾¡æ ¼ç¯„å›²: {enhanced_df['Close'].min():.0f} ~ {enhanced_df['Close'].max():.0f}å††")
            
            # ä¸¡æ–¹ã®ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€ä¾¡æ ¼ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯
            if real_path.exists():
                # å…±é€šéŠ˜æŸ„ãƒ»å…±é€šæ—¥ä»˜ã§ä¾¡æ ¼æ¯”è¼ƒ
                common_codes = set(real_df['Code'].unique()) & set(enhanced_df['Code'].unique())
                logger.info(f"ğŸ” å…±é€šéŠ˜æŸ„æ•°: {len(common_codes)}")
                
                for code in list(common_codes)[:5]:  # ã‚µãƒ³ãƒ—ãƒ«5éŠ˜æŸ„
                    real_sample = real_df[real_df['Code'] == code].tail(5)
                    enhanced_sample = enhanced_df[enhanced_df['Code'] == code].tail(5)
                    
                    for _, real_row in real_sample.iterrows():
                        enhanced_match = enhanced_sample[enhanced_sample['Date'] == real_row['Date']]
                        if not enhanced_match.empty:
                            real_price = real_row['Close']
                            enhanced_price = enhanced_match.iloc[0]['Close']
                            
                            if abs(real_price - enhanced_price) > 0.01:
                                issues.append({
                                    'type': 'price_mismatch',
                                    'stock_code': code,
                                    'date': real_row['Date'],
                                    'real_price': real_price,
                                    'enhanced_price': enhanced_price,
                                    'details': f"ä¾¡æ ¼ä¸ä¸€è‡´: {real_price} vs {enhanced_price}"
                                })
        
        return issues
    
    def save_monitoring_report(self, issues):
        """ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_path = self.monitor_dir / f"data_monitoring_report_{timestamp}.json"
        
        monitoring_data = {
            'timestamp': timestamp,
            'issues_found': len(issues),
            'issues': issues,
            'status': 'clean' if len(issues) == 0 else 'issues_detected'
        }
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(monitoring_data, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"ğŸ“‹ ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
        return report_path
    
    def run_monitoring(self):
        """ç›£è¦–å®Ÿè¡Œ"""
        logger.info("ğŸš€ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ç›£è¦–é–‹å§‹")
        
        issues = self.check_data_consistency()
        report_path = self.save_monitoring_report(issues)
        
        if issues:
            logger.error(f"ğŸš¨ {len(issues)}ä»¶ã®å•é¡Œã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
            for issue in issues:
                logger.error(f"   {issue['type']}: {issue['details']}")
        else:
            logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æ•´åˆæ€§OK")
        
        return len(issues) == 0

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    monitor = DataSourceMonitor()
    monitor.run_monitoring()

if __name__ == "__main__":
    main()